uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC24MLRandomForestClassifierV_Tt1g503_s8b4ML24fgh80V12handleResult33_4BA12AD8C244BA9B40BDFBE3C2FF9674LL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC04TreeH23TrainingSessionDelegateCTf1nc_nTY2_()
{
  v1 = v0[4];
  v2 = v0[6];
  *v2 = v0[8];
  swift_storeEnumTagMultiPayload(v2, v1, 1);
  v3 = v0;
  v4 = v0[6];
  v5 = v3[5];
  v6 = v3[3];
  v7 = v3;
  outlined init with take of DataFrame?(v4, v3[2], &demangling cache variable for type metadata for Result<MLRandomForestClassifier, Error>);

  v4;
  v5;
  return (v7[1])();
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC22MLBoostedTreeRegressorV_Tt1g503_s8b4ML22fgh80V12handleResult33_53F1D2839F479D9B4239C31BB67470FBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_n(uint64_t a1, uint64_t a2)
{
  v2[3] = a2;
  v2[2] = a1;
  v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLBoostedTreeRegressor, Error>);
  v2[4] = v3;
  v4 = (*(*(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);

  v6 = swift_task_alloc(400);
  v2[7] = v6;
  *v6 = v2;
  v6[1] = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC22MLBoostedTreeRegressorV_Tt1g503_s8b4ML22fgh80V12handleResult33_53F1D2839F479D9B4239C31BB67470FBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_nTQ0_;
  return MLBoostedTreeRegressor.init(delegate:)(v5, a2);
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC22MLBoostedTreeRegressorV_Tt1g503_s8b4ML22fgh80V12handleResult33_53F1D2839F479D9B4239C31BB67470FBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_nTQ0_()
{
  v2 = *(*v1 + 56);
  *(*v1 + 64) = v0;
  v2;
  if (v0)
  {
    v3 = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC22MLBoostedTreeRegressorV_Tt1g503_s8b4ML22fgh80V12handleResult33_53F1D2839F479D9B4239C31BB67470FBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_nTY2_;
  }

  else
  {
    v3 = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC22MLBoostedTreeRegressorV_Tt1g503_s8b4ML22fgh80V12handleResult33_53F1D2839F479D9B4239C31BB67470FBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_nTY1_;
  }

  return swift_task_switch(v3, 0, 0);
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC22MLBoostedTreeRegressorV_Tt1g503_s8b4ML22fgh80V12handleResult33_53F1D2839F479D9B4239C31BB67470FBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_nTY1_()
{
  v1 = v0[6];
  v2 = v0[5];
  swift_storeEnumTagMultiPayload(v2, v0[4], 0);
  outlined init with take of DataFrame?(v2, v1, &demangling cache variable for type metadata for Result<MLBoostedTreeRegressor, Error>);
  v3 = v0;
  v4 = v0[6];
  v5 = v3[5];
  v6 = v3[3];
  v7 = v3;
  outlined init with take of DataFrame?(v4, v3[2], &demangling cache variable for type metadata for Result<MLBoostedTreeRegressor, Error>);

  v4;
  v5;
  return (v7[1])();
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC22MLBoostedTreeRegressorV_Tt1g503_s8b4ML22fgh80V12handleResult33_53F1D2839F479D9B4239C31BB67470FBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_nTY2_()
{
  v1 = v0[4];
  v2 = v0[6];
  *v2 = v0[8];
  swift_storeEnumTagMultiPayload(v2, v1, 1);
  v3 = v0;
  v4 = v0[6];
  v5 = v3[5];
  v6 = v3[3];
  v7 = v3;
  outlined init with take of DataFrame?(v4, v3[2], &demangling cache variable for type metadata for Result<MLBoostedTreeRegressor, Error>);

  v4;
  v5;
  return (v7[1])();
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC24MLDecisionTreeClassifierV_Tt1g503_s8b4ML24fgh80V12handleResult33_7E17D1DEF38C9D8FEB24863D1630C03BLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gH23TrainingSessionDelegateCTf1nc_n(uint64_t a1, uint64_t a2)
{
  v2[3] = a2;
  v2[2] = a1;
  v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLDecisionTreeClassifier, Error>);
  v2[4] = v3;
  v4 = (*(*(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);

  v6 = swift_task_alloc(400);
  v2[7] = v6;
  *v6 = v2;
  v6[1] = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC24MLDecisionTreeClassifierV_Tt1g503_s8b4ML24fgh80V12handleResult33_7E17D1DEF38C9D8FEB24863D1630C03BLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gH23TrainingSessionDelegateCTf1nc_nTQ0_;
  return MLDecisionTreeClassifier.init(delegate:)(v5, a2);
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC24MLDecisionTreeClassifierV_Tt1g503_s8b4ML24fgh80V12handleResult33_7E17D1DEF38C9D8FEB24863D1630C03BLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gH23TrainingSessionDelegateCTf1nc_nTQ0_()
{
  v2 = *(*v1 + 56);
  *(*v1 + 64) = v0;
  v2;
  if (v0)
  {
    v3 = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC24MLDecisionTreeClassifierV_Tt1g503_s8b4ML24fgh80V12handleResult33_7E17D1DEF38C9D8FEB24863D1630C03BLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gH23TrainingSessionDelegateCTf1nc_nTY2_;
  }

  else
  {
    v3 = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC24MLDecisionTreeClassifierV_Tt1g503_s8b4ML24fgh80V12handleResult33_7E17D1DEF38C9D8FEB24863D1630C03BLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gH23TrainingSessionDelegateCTf1nc_nTY1_;
  }

  return swift_task_switch(v3, 0, 0);
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC24MLDecisionTreeClassifierV_Tt1g503_s8b4ML24fgh80V12handleResult33_7E17D1DEF38C9D8FEB24863D1630C03BLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gH23TrainingSessionDelegateCTf1nc_nTY1_()
{
  v1 = v0[6];
  v2 = v0[5];
  swift_storeEnumTagMultiPayload(v2, v0[4], 0);
  outlined init with take of DataFrame?(v2, v1, &demangling cache variable for type metadata for Result<MLDecisionTreeClassifier, Error>);
  v3 = v0;
  v4 = v0[6];
  v5 = v3[5];
  v6 = v3[3];
  v7 = v3;
  outlined init with take of DataFrame?(v4, v3[2], &demangling cache variable for type metadata for Result<MLDecisionTreeClassifier, Error>);

  v4;
  v5;
  return (v7[1])();
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC24MLDecisionTreeClassifierV_Tt1g503_s8b4ML24fgh80V12handleResult33_7E17D1DEF38C9D8FEB24863D1630C03BLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gH23TrainingSessionDelegateCTf1nc_nTY2_()
{
  v1 = v0[4];
  v2 = v0[6];
  *v2 = v0[8];
  swift_storeEnumTagMultiPayload(v2, v1, 1);
  v3 = v0;
  v4 = v0[6];
  v5 = v3[5];
  v6 = v3[3];
  v7 = v3;
  outlined init with take of DataFrame?(v4, v3[2], &demangling cache variable for type metadata for Result<MLDecisionTreeClassifier, Error>);

  v4;
  v5;
  return (v7[1])();
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLSoundClassifierV_Tt1g503_s8b4ML17fg80V12handleResult33_0936EF001B4864F81C630288B6304A87LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC05Soundg8TrainingX8DelegateCTf1nc_n(uint64_t a1, uint64_t a2)
{
  v2[3] = a2;
  v2[2] = a1;
  v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLSoundClassifier, Error>);
  v2[4] = v3;
  v4 = (*(*(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);

  v6 = swift_task_alloc(288);
  v2[7] = v6;
  *v6 = v2;
  v6[1] = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLSoundClassifierV_Tt1g503_s8b4ML17fg80V12handleResult33_0936EF001B4864F81C630288B6304A87LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC05Soundg8TrainingX8DelegateCTf1nc_nTQ0_;
  return MLSoundClassifier.init(delegate:)(v5, a2);
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLSoundClassifierV_Tt1g503_s8b4ML17fg80V12handleResult33_0936EF001B4864F81C630288B6304A87LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC05Soundg8TrainingX8DelegateCTf1nc_nTQ0_()
{
  v2 = *(*v1 + 56);
  *(*v1 + 64) = v0;
  v2;
  if (v0)
  {
    v3 = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLSoundClassifierV_Tt1g503_s8b4ML17fg80V12handleResult33_0936EF001B4864F81C630288B6304A87LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC05Soundg8TrainingX8DelegateCTf1nc_nTY2_;
  }

  else
  {
    v3 = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLSoundClassifierV_Tt1g503_s8b4ML17fg80V12handleResult33_0936EF001B4864F81C630288B6304A87LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC05Soundg8TrainingX8DelegateCTf1nc_nTY1_;
  }

  return swift_task_switch(v3, 0, 0);
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLSoundClassifierV_Tt1g503_s8b4ML17fg80V12handleResult33_0936EF001B4864F81C630288B6304A87LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC05Soundg8TrainingX8DelegateCTf1nc_nTY1_()
{
  v1 = v0[6];
  v2 = v0[5];
  swift_storeEnumTagMultiPayload(v2, v0[4], 0);
  outlined init with take of DataFrame?(v2, v1, &demangling cache variable for type metadata for Result<MLSoundClassifier, Error>);
  v3 = v0;
  v4 = v0[6];
  v5 = v3[5];
  v6 = v3[3];
  v7 = v3;
  outlined init with take of DataFrame?(v4, v3[2], &demangling cache variable for type metadata for Result<MLSoundClassifier, Error>);

  v4;
  v5;
  return (v7[1])();
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLSoundClassifierV_Tt1g503_s8b4ML17fg80V12handleResult33_0936EF001B4864F81C630288B6304A87LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC05Soundg8TrainingX8DelegateCTf1nc_nTY2_()
{
  v1 = v0[4];
  v2 = v0[6];
  *v2 = v0[8];
  swift_storeEnumTagMultiPayload(v2, v1, 1);
  v3 = v0;
  v4 = v0[6];
  v5 = v3[5];
  v6 = v3[3];
  v7 = v3;
  outlined init with take of DataFrame?(v4, v3[2], &demangling cache variable for type metadata for Result<MLSoundClassifier, Error>);

  v4;
  v5;
  return (v7[1])();
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC23MLBoostedTreeClassifierV_Tt1g503_s8b4ML23fgh80V12handleResult33_CD9A6EBB503908D6C1216C5F49822BDBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_n(uint64_t a1, uint64_t a2)
{
  v2[3] = a2;
  v2[2] = a1;
  v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLBoostedTreeClassifier, Error>);
  v2[4] = v3;
  v4 = (*(*(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);

  v6 = swift_task_alloc(496);
  v2[7] = v6;
  *v6 = v2;
  v6[1] = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC23MLBoostedTreeClassifierV_Tt1g503_s8b4ML23fgh80V12handleResult33_CD9A6EBB503908D6C1216C5F49822BDBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_nTQ0_;
  return MLBoostedTreeClassifier.init(delegate:)(v5, a2);
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC23MLBoostedTreeClassifierV_Tt1g503_s8b4ML23fgh80V12handleResult33_CD9A6EBB503908D6C1216C5F49822BDBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_nTQ0_()
{
  v2 = *(*v1 + 56);
  *(*v1 + 64) = v0;
  v2;
  if (v0)
  {
    v3 = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC23MLBoostedTreeClassifierV_Tt1g503_s8b4ML23fgh80V12handleResult33_CD9A6EBB503908D6C1216C5F49822BDBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_nTY2_;
  }

  else
  {
    v3 = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC23MLBoostedTreeClassifierV_Tt1g503_s8b4ML23fgh80V12handleResult33_CD9A6EBB503908D6C1216C5F49822BDBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_nTY1_;
  }

  return swift_task_switch(v3, 0, 0);
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC23MLBoostedTreeClassifierV_Tt1g503_s8b4ML23fgh80V12handleResult33_CD9A6EBB503908D6C1216C5F49822BDBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_nTY1_()
{
  v1 = v0[6];
  v2 = v0[5];
  swift_storeEnumTagMultiPayload(v2, v0[4], 0);
  outlined init with take of DataFrame?(v2, v1, &demangling cache variable for type metadata for Result<MLBoostedTreeClassifier, Error>);
  v3 = v0;
  v4 = v0[6];
  v5 = v3[5];
  v6 = v3[3];
  v7 = v3;
  outlined init with take of DataFrame?(v4, v3[2], &demangling cache variable for type metadata for Result<MLBoostedTreeClassifier, Error>);

  v4;
  v5;
  return (v7[1])();
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC23MLBoostedTreeClassifierV_Tt1g503_s8b4ML23fgh80V12handleResult33_CD9A6EBB503908D6C1216C5F49822BDBLL_7session7fulfillys0G0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC0gh8TrainingZ8DelegateCTf1nc_nTY2_()
{
  v1 = v0[4];
  v2 = v0[6];
  *v2 = v0[8];
  swift_storeEnumTagMultiPayload(v2, v1, 1);
  v3 = v0;
  v4 = v0[6];
  v5 = v3[5];
  v6 = v3[3];
  v7 = v3;
  outlined init with take of DataFrame?(v4, v3[2], &demangling cache variable for type metadata for Result<MLBoostedTreeClassifier, Error>);

  v4;
  v5;
  return (v7[1])();
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLLinearRegressorV_Tt1g503_s8b4ML17fg80V12handleResult33_002D25F40C350B487B72244DB0D467A6LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC06Linearg8TrainingZ8DelegateCTf1nc_n(uint64_t a1, uint64_t a2)
{
  v2[3] = a2;
  v2[2] = a1;
  v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLLinearRegressor, Error>);
  v2[4] = v3;
  v4 = (*(*(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);

  v6 = swift_task_alloc(304);
  v2[7] = v6;
  *v6 = v2;
  v6[1] = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLLinearRegressorV_Tt1g503_s8b4ML17fg80V12handleResult33_002D25F40C350B487B72244DB0D467A6LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC06Linearg8TrainingZ8DelegateCTf1nc_nTQ0_;
  return MLLinearRegressor.init(delegate:)(v5, a2);
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLLinearRegressorV_Tt1g503_s8b4ML17fg80V12handleResult33_002D25F40C350B487B72244DB0D467A6LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC06Linearg8TrainingZ8DelegateCTf1nc_nTQ0_()
{
  v2 = *(*v1 + 56);
  *(*v1 + 64) = v0;
  v2;
  if (v0)
  {
    v3 = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLLinearRegressorV_Tt1g503_s8b4ML17fg80V12handleResult33_002D25F40C350B487B72244DB0D467A6LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC06Linearg8TrainingZ8DelegateCTf1nc_nTY2_;
  }

  else
  {
    v3 = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLLinearRegressorV_Tt1g503_s8b4ML17fg80V12handleResult33_002D25F40C350B487B72244DB0D467A6LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC06Linearg8TrainingZ8DelegateCTf1nc_nTY1_;
  }

  return swift_task_switch(v3, 0, 0);
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLLinearRegressorV_Tt1g503_s8b4ML17fg80V12handleResult33_002D25F40C350B487B72244DB0D467A6LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC06Linearg8TrainingZ8DelegateCTf1nc_nTY1_()
{
  v1 = v0[6];
  v2 = v0[5];
  swift_storeEnumTagMultiPayload(v2, v0[4], 0);
  outlined init with take of DataFrame?(v2, v1, &demangling cache variable for type metadata for Result<MLLinearRegressor, Error>);
  v3 = v0;
  v4 = v0[6];
  v5 = v3[5];
  v6 = v3[3];
  v7 = v3;
  outlined init with take of DataFrame?(v4, v3[2], &demangling cache variable for type metadata for Result<MLLinearRegressor, Error>);

  v4;
  v5;
  return (v7[1])();
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLLinearRegressorV_Tt1g503_s8b4ML17fg80V12handleResult33_002D25F40C350B487B72244DB0D467A6LL_7session7fulfillys0F0Oyyts5D65_pG_AA17MLTrainingSessionCyACGyAIyACsAJ_pGctFZyyYacfU_ACyYaKXEfU_AC06Linearg8TrainingZ8DelegateCTf1nc_nTY2_()
{
  v1 = v0[4];
  v2 = v0[6];
  *v2 = v0[8];
  swift_storeEnumTagMultiPayload(v2, v1, 1);
  v3 = v0;
  v4 = v0[6];
  v5 = v3[5];
  v6 = v3[3];
  v7 = v3;
  outlined init with take of DataFrame?(v4, v3[2], &demangling cache variable for type metadata for Result<MLLinearRegressor, Error>);

  v4;
  v5;
  return (v7[1])();
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLImageClassifierV_Tt1g503_s8b4ML17fg43V6resumeyAA5MLJobCyACGAA17MLTrainingSessionm13ACGKFZyAG_ys6a6OyACs5D45_pGctXEfU_yALyytsAM_pGcfU_yyYacfU_ACyYaKXEfU_AC05Imageg8TrainingP8DelegateCTf1nc_n(uint64_t a1, uint64_t a2)
{
  v2[3] = a2;
  v2[2] = a1;
  v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<MLImageClassifier, Error>);
  v2[4] = v3;
  v4 = (*(*(v3 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  v5 = swift_task_alloc(v4);
  v2[5] = v5;
  v2[6] = swift_task_alloc(v4);

  v6 = swift_task_alloc(496);
  v2[7] = v6;
  *v6 = v2;
  v6[1] = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLImageClassifierV_Tt1g503_s8b4ML17fg43V6resumeyAA5MLJobCyACGAA17MLTrainingSessionm13ACGKFZyAG_ys6a6OyACs5D45_pGctXEfU_yALyytsAM_pGcfU_yyYacfU_ACyYaKXEfU_AC05Imageg8TrainingP8DelegateCTf1nc_nTQ0_;
  return MLImageClassifier.init(delegate:)(v5, a2);
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLImageClassifierV_Tt1g503_s8b4ML17fg43V6resumeyAA5MLJobCyACGAA17MLTrainingSessionm13ACGKFZyAG_ys6a6OyACs5D45_pGctXEfU_yALyytsAM_pGcfU_yyYacfU_ACyYaKXEfU_AC05Imageg8TrainingP8DelegateCTf1nc_nTQ0_()
{
  v2 = *(*v1 + 56);
  *(*v1 + 64) = v0;
  v2;
  if (v0)
  {
    v3 = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLImageClassifierV_Tt1g503_s8b4ML17fg43V6resumeyAA5MLJobCyACGAA17MLTrainingSessionm13ACGKFZyAG_ys6a6OyACs5D45_pGctXEfU_yALyytsAM_pGcfU_yyYacfU_ACyYaKXEfU_AC05Imageg8TrainingP8DelegateCTf1nc_nTY2_;
  }

  else
  {
    v3 = _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLImageClassifierV_Tt1g503_s8b4ML17fg43V6resumeyAA5MLJobCyACGAA17MLTrainingSessionm13ACGKFZyAG_ys6a6OyACs5D45_pGctXEfU_yALyytsAM_pGcfU_yyYacfU_ACyYaKXEfU_AC05Imageg8TrainingP8DelegateCTf1nc_nTY1_;
  }

  return swift_task_switch(v3, 0, 0);
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLImageClassifierV_Tt1g503_s8b4ML17fg43V6resumeyAA5MLJobCyACGAA17MLTrainingSessionm13ACGKFZyAG_ys6a6OyACs5D45_pGctXEfU_yALyytsAM_pGcfU_yyYacfU_ACyYaKXEfU_AC05Imageg8TrainingP8DelegateCTf1nc_nTY1_()
{
  v1 = v0[6];
  v2 = v0[5];
  swift_storeEnumTagMultiPayload(v2, v0[4], 0);
  outlined init with take of DataFrame?(v2, v1, &demangling cache variable for type metadata for Result<MLImageClassifier, Error>);
  v3 = v0;
  v4 = v0[6];
  v5 = v3[5];
  v6 = v3[3];
  v7 = v3;
  outlined init with take of DataFrame?(v4, v3[2], &demangling cache variable for type metadata for Result<MLImageClassifier, Error>);

  v4;
  v5;
  return (v7[1])();
}

uint64_t _ss6ResultO8CreateMLs5Error_pRs_rlE8catchingAByxsAD_pGxyYaKXE_tYacfCAC17MLImageClassifierV_Tt1g503_s8b4ML17fg43V6resumeyAA5MLJobCyACGAA17MLTrainingSessionm13ACGKFZyAG_ys6a6OyACs5D45_pGctXEfU_yALyytsAM_pGcfU_yyYacfU_ACyYaKXEfU_AC05Imageg8TrainingP8DelegateCTf1nc_nTY2_()
{
  v1 = v0[4];
  v2 = v0[6];
  *v2 = v0[8];
  swift_storeEnumTagMultiPayload(v2, v1, 1);
  v3 = v0;
  v4 = v0[6];
  v5 = v3[5];
  v6 = v3[3];
  v7 = v3;
  outlined init with take of DataFrame?(v4, v3[2], &demangling cache variable for type metadata for Result<MLImageClassifier, Error>);

  v4;
  v5;
  return (v7[1])();
}

uint64_t outlined destroy of Result<Any, Error>?(uint64_t a1)
{
  v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Result<Any, Error>?);
  (*(*(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t static MLHandPoseClassifier.FeatureExtractor.extractFeatures(from:startingSessionId:)(uint64_t a1, uint64_t a2)
{
  v10 = a2;
  v11 = v2;
  v5 = *a1;
  v6 = *(a1 + 8);
  inited = swift_initStackObject(v4, v9);
  *(inited + 32) = _swiftEmptyArrayStorage;
  *(inited + 40) = _swiftEmptyArrayStorage;
  *(inited + 48) = _swiftEmptyArrayStorage;
  *(inited + 56) = _swiftEmptyArrayStorage;
  *(inited + 16) = v5;
  *(inited + 24) = v6;
  if (v3)
  {
    return outlined copy of Result<_DataTable, Error>(v5, v6);
  }

  outlined copy of Result<_DataTable, Error>(v5, v6);
  MLHandPoseClassifier.FeatureExtractor.extractFeaturesFromFileTable(startingSessionId:)(v10);
}

uint64_t static MLHandPoseClassifier.FeatureExtractor.extractFeatures(from:startingSessionId:)(uint64_t a1, uint64_t a2, __m128 a3)
{
  v9[0] = a2;
  v9[1] = v3;
  v5 = *(*(type metadata accessor for MLHandPoseClassifier.DataSource(0) - 8) + 64);
  v6 = alloca(v5);
  v7 = alloca(v5);
  outlined init with copy of MLHandPoseClassifier.DataSource(a1, v9);
  result = MLHandPoseClassifier.FeatureExtractor.__allocating_init(source:)(v9, a3);
  if (!v4)
  {
    MLHandPoseClassifier.FeatureExtractor.extractFeaturesFromFileTable(startingSessionId:)(v9[0]);
  }

  return result;
}

uint64_t MLHandPoseClassifier.FeatureExtractor.__allocating_init(source:)(uint64_t a1, __m128 a2)
{
  MLHandPoseClassifier.DataSource.imagesWithAnnotations()(a2);
  result = outlined destroy of MLActivityClassifier.ModelParameters(a1, type metadata accessor for MLHandPoseClassifier.DataSource);
  if (!v2)
  {
    result = swift_allocObject(v3, 64, 7);
    *(result + 32) = _swiftEmptyArrayStorage;
    *(result + 40) = _swiftEmptyArrayStorage;
    *(result + 48) = _swiftEmptyArrayStorage;
    *(result + 56) = _swiftEmptyArrayStorage;
    *(result + 16) = v5;
    *(result + 24) = v6;
  }

  return result;
}

uint64_t MLHandPoseClassifier.FeatureExtractor.extractFeaturesFromFileTable(startingSessionId:)(uint64_t a1)
{
  v141._countAndFlagsBits = v2;
  v116 = a1;
  v122 = v1;
  v126 = type metadata accessor for URL(0);
  v127 = *(v126 - 8);
  v4 = *(v127 + 64);
  v5 = alloca(v4);
  v6 = alloca(v4);
  v128 = &v113;
  v145 = type metadata accessor for Date(0);
  v142 = *(v145 - 8);
  v7 = *(v142 + 64);
  v8 = alloca(v7);
  v9 = alloca(v7);
  v137 = &v113;
  currentFileIndex = type metadata accessor for _TablePrinter(0);
  v10 = *(*(currentFileIndex - 8) + 64);
  v11 = alloca(v10);
  v12 = alloca(v10);
  v144 = &v113;
  v136 = v3;
  v13 = *(v3 + 16);
  v14 = *(v3 + 24);
  v131 = v13;
  LOBYTE(v132) = v14;
  outlined copy of Result<_DataTable, Error>(v13, v14);
  outlined copy of Result<_DataTable, Error>(v13, v14);
  v15 = MLDataTable.size.getter();
  outlined consume of Result<_DataTable, Error>(v131, v132);
  v16 = specialized RandomAccessCollection<>.distance(from:to:)(0, v15, v13, v14);
  outlined consume of Result<_DataTable, Error>(v13, v14);
  v131 = 0;
  v132 = 0xE000000000000000;
  _StringGuts.grow(_:)(30);
  v132;
  v131 = 0x69737365636F7250;
  v132 = 0xEB0000000020676ELL;
  *&_ = v16;
  v17._countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  object = v17._object;
  String.append(_:)(v17);
  object;
  v19._object = "ractor" + 0x8000000000000000;
  v19._countAndFlagsBits = 0xD000000000000011;
  String.append(_:)(v19);
  v20 = v131;
  v21 = v132;
  v22 = static os_log_type_t.info.getter();
  v19._countAndFlagsBits = v20;
  v19._object = v21;
  log(_:type:)(v19, v22);
  v19._countAndFlagsBits = v21;
  v21;
  v143 = "ml.handPoseClassifier" + 0x8000000000000000;
  v23 = v144;
  v24 = v144 + *(currentFileIndex + 20);
  Date.init()(v19._countAndFlagsBits);
  v119 = v16;
  *v23 = v16;
  type metadata accessor for OS_os_log();
  v25 = OS_os_log.init(subsystem:category:)(0xD000000000000025, " annotated images" + 0x8000000000000000, 0x72705F656C626174, 0xED00007265746E69);
  v26 = currentFileIndex;
  v27 = *(currentFileIndex + 24);
  v121 = v25;
  v28 = v144;
  *(v144 + v27) = v25;
  v29 = *(v26 + 28);
  *(v28 + v29) = 0xD000000000000010;
  *(v28 + v29 + 8) = v143;
  v30 = v137;
  Date.init()(0xD000000000000025);
  v117 = v24;
  (*(v142 + 40))(v24, v30, v145);
  _TablePrinter.beginTable()();
  _TablePrinter.printRow(currentFileIndex:)(0);
  LOBYTE(v19._object) = *(v136 + 24);
  v131 = *(v136 + 16);
  LOBYTE(v132) = v19._object;
  v123 = (v136 + 32);
  v124 = (v136 + 48);
  v125 = (v136 + 40);
  v136 += 56;
  v31 = 0;
  v133 = 0;
  outlined copy of Result<_DataTable, Error>(v131, v19._object);
  v118 = "h or label string at row " + 0x8000000000000000;
  v120 = "Extracted features from " + 0x8000000000000000;
  while (1)
  {
    specialized EnumeratedSequence.Iterator.next()();
    if (!*(&_ + 1))
    {
      break;
    }

    currentFileIndex = _;
    v32 = v139;
    v33 = v140;
    v34 = *(v139 + 16) == 0;
    v142 = v140;
    v145 = *(&_ + 1);
    v137 = v139;
    if (v34)
    {
      goto LABEL_24;
    }

    v32;

    v35 = specialized __RawDictionaryStorage.find<A>(_:)(0x7461506567616D69, 0xE900000000000068);
    if ((v36 & 1) == 0)
    {
      outlined consume of (offset: Int, element: MLDataTable.Row)?(currentFileIndex, v145, v32, v33);
      goto LABEL_24;
    }

    v37 = *(*(v32 + 56) + 8 * v35);

    countAndFlagsBits = v141._countAndFlagsBits;
    v39 = CMLSequence.value(at:)(v37);
    if (countAndFlagsBits)
    {
      swift_unexpectedError(countAndFlagsBits, "CreateML/MLDataTable.Row.swift", 30, 1, 85);
      BUG();
    }

    MLDataValue.init(_:)(v39, *v31.i64);

    outlined consume of (offset: Int, element: MLDataTable.Row)?(currentFileIndex, v145, v32, v33);
    v40 = *(&_ + 1);
    v141._countAndFlagsBits = _;
    if (v139 != 2)
    {
      v100 = v139;
      v101 = v141._countAndFlagsBits;
      goto LABEL_23;
    }

    v143 = *(&_ + 1);
    if (!*(v32 + 16))
    {
      goto LABEL_20;
    }

    v32;

    v41 = specialized __RawDictionaryStorage.find<A>(_:)(0x6C6562616CLL, 0xE500000000000000);
    if ((v42 & 1) == 0)
    {
      outlined consume of (offset: Int, element: MLDataTable.Row)?(currentFileIndex, v145, v32, v33);
LABEL_20:
      v100 = 2;
      v101 = v141._countAndFlagsBits;
LABEL_22:
      v40 = v143;
LABEL_23:
      outlined consume of MLDataValue(v101, v40, v100);
LABEL_24:
      *&_ = 0;
      *(&_ + 1) = 0xE000000000000000;
      _StringGuts.grow(_:)(52);
      v102._object = "Annotated images" + 0x8000000000000000;
      v102._countAndFlagsBits = 0xD000000000000029;
      String.append(_:)(v102);
      v103 = currentFileIndex;
      v134 = currentFileIndex;
      v104 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
      v106 = v105;
      v102._countAndFlagsBits = v104;
      v102._object = v105;
      String.append(_:)(v102);
      v106;
      v102._object = 0xE900000000000065;
      v102._countAndFlagsBits = 0x6C626174206E6920;
      String.append(_:)(v102);
      v141 = _;
      v102._object = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v102._object, 0, 0);
      *v107 = v141;
      *(v107 + 16) = 0;
      *(v107 + 32) = 0;
      *(v107 + 48) = 0;
      swift_willThrow(&type metadata for MLCreateError, v102._object);
      v108 = v103;
      goto LABEL_25;
    }

    v43 = *(*(v32 + 56) + 8 * v41);

    v44 = v43;
    v45 = v142;
    v46 = CMLSequence.value(at:)(v44);
    v135 = 0;
    MLDataValue.init(_:)(v46, *v31.i64);

    outlined consume of (offset: Int, element: MLDataTable.Row)?(currentFileIndex, v145, v32, v45);
    v47 = v141._countAndFlagsBits;
    if (v139 != 2)
    {
      outlined consume of MLDataValue(_, *(&_ + 1), v139);
      v100 = 2;
      v101 = v47;
      goto LABEL_22;
    }

    v129 = *(&_ + 1);
    v130 = _;
    v48 = objc_opt_self(NSFileManager);
    v49 = [v48 defaultManager];
    v50 = v49;
    v51 = v143;
    v52 = String._bridgeToObjectiveC()();
    v53 = [v50 fileExistsAtPath:v52];

    if (!v53)
    {
      outlined consume of MLDataValue(v130, v129, 2);
      *&_ = 0;
      *(&_ + 1) = 0xE000000000000000;
      _StringGuts.grow(_:)(26);
      *(&_ + 1);
      *&_ = 0xD000000000000018;
      *(&_ + 1) = "s, elapsed time: " + 0x8000000000000000;
      v110 = v141._countAndFlagsBits;
      v111._countAndFlagsBits = v141._countAndFlagsBits;
      v111._object = v51;
      String.append(_:)(v111);
      outlined consume of MLDataValue(v110, v51, 2);
      v141 = _;
      v111._object = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v111._object, 0, 0);
      *v112 = v141;
      *(v112 + 16) = 0;
      *(v112 + 32) = 0;
      *(v112 + 48) = 0;
      swift_willThrow(&type metadata for MLCreateError, v111._object);
      v108 = currentFileIndex;
LABEL_25:
      outlined consume of (offset: Int, element: MLDataTable.Row)?(v108, v145, v137, v142);
LABEL_26:
      outlined consume of Result<_DataTable, Error>(v131, v132);
      return outlined destroy of MLActivityClassifier.ModelParameters(v144, type metadata accessor for _TablePrinter);
    }

    v54 = v128;
    v55 = v141._countAndFlagsBits;
    URL.init(fileURLWithPath:)(v141._countAndFlagsBits, v51);
    outlined consume of MLDataValue(v55, v51, 2);
    v56 = URL.lastPathComponent.getter();
    v58 = v57;
    v59 = v135;
    v60 = static _VideoUtilities.getHandKeyPointsFromImageUrl(url:)(v54);
    if (v59)
    {
      outlined consume of MLDataValue(v130, v129, 2);
      v58;
      outlined consume of (offset: Int, element: MLDataTable.Row)?(currentFileIndex, v145, v137, v142);
      (*(v127 + 8))(v128, v126);
      goto LABEL_26;
    }

    if (__OFADD__(v116, currentFileIndex))
    {
      BUG();
    }

    v61 = v60;
    v141._countAndFlagsBits = 0;
    v62 = v60[2];
    v143 = _sSa9repeating5countSayxGx_SitcfCSi_Tt1g5(v116 + currentFileIndex, v62);
    v135 = _sSa9repeating5countSayxGx_SitcfCSS_Tt1g5(v130, v129, v62);
    v63 = _sSa9repeating5countSayxGx_SitcfCSS_Tt1g5(v56, v58, v62);
    specialized Array.append<A>(contentsOf:)(v61);
    specialized Array.append<A>(contentsOf:)(v143);
    specialized Array.append<A>(contentsOf:)(v135);
    specialized Array.append<A>(contentsOf:)(v63);
    v64 = currentFileIndex;
    _TablePrinter.printRow(currentFileIndex:)(currentFileIndex);
    v65 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
    v66 = swift_allocObject(v65, 72, 7);
    *(v66 + 16) = 1;
    *(v66 + 24) = 2;
    *v31.i64 = Date.timeIntervalSinceNow.getter();
    *(v66 + 56) = &type metadata for Double;
    *(v66 + 64) = &protocol witness table for Double;
    _mm_storel_ps((v66 + 32), _mm_xor_ps(v31, xmmword_33DFE0));
    v67 = String.init(format:_:)(1714826789, 0xE400000000000000, v66);
    v69 = v68;
    *&_ = 0;
    *(&_ + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(71);
    v31 = _;
    v70._countAndFlagsBits = 0xD000000000000018;
    v70._object = v118;
    String.append(_:)(v70);
    v71 = __OFADD__(1, v64);
    v72 = v64 + 1;
    if (v71)
    {
      BUG();
    }

    v134 = v72;
    v73._countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    v74 = v73._object;
    String.append(_:)(v73);
    v74;
    v75._countAndFlagsBits = 0x20666F2074756F20;
    v75._object = 0xE800000000000000;
    String.append(_:)(v75);
    v134 = v119;
    v76._countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    v77 = v76._object;
    String.append(_:)(v76);
    v77;
    v75._countAndFlagsBits = 0xD000000000000021;
    v75._object = v120;
    String.append(_:)(v75);
    v75._countAndFlagsBits = v67;
    v75._object = v69;
    String.append(_:)(v75);
    v69;
    v78 = _;
    v79 = static os_log_type_t.default.getter(v69);
    log(_:type:)(v78, v79);
    v78._object;
    outlined consume of (offset: Int, element: MLDataTable.Row)?(currentFileIndex, v145, v137, v142);
    (*(v127 + 8))(v128, v126);
  }

  outlined consume of Result<_DataTable, Error>(v131, v132);
  static os_log_type_t.info.getter();
  v80 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  v81 = swift_allocObject(v80, 72, 7);
  v81[2] = 1;
  v81[3] = 2;
  v81[7] = &type metadata for Int;
  v81[8] = &protocol witness table for Int;
  v81[4] = 3;
  os_log(_:dso:log:type:_:)("event: %lu", 10);
  v81;
  v82 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MLUntypedColumn)>);
  inited = swift_initStackObject(v82, v114);
  *(inited + 16) = 4;
  *(inited + 24) = 8;
  *(inited + 32) = 0x6C6562616CLL;
  *(inited + 40) = 0xE500000000000000;
  v131 = *v125;
  v84 = alloca(24);
  v85 = alloca(32);
  v115 = &v131;
  v131;
  *(inited + 48) = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTt1g5(partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
  *(inited + 56) = v86 & 1;
  v131;
  *(inited + 64) = 0x5F6E6F6973736573;
  *(inited + 72) = 0xEA00000000006469;
  v131 = *v124;
  v87 = alloca(24);
  v88 = alloca(24);
  v115 = &v131;
  v131;
  *(inited + 80) = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTt1g5(partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
  *(inited + 88) = v89 & 1;
  v131;
  *(inited + 96) = 0x746E696F7079656BLL;
  *(inited + 104) = 0xE900000000000073;
  v131 = *v123;
  v90 = alloca(24);
  v91 = alloca(32);
  v115 = &v131;
  v131;
  *(inited + 112) = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTt1g5(partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
  *(inited + 120) = v92 & 1;
  v131;
  *(inited + 128) = 0x7461506567616D69;
  *(inited + 136) = 0xE900000000000068;
  v131 = *v136;
  v93 = alloca(24);
  v94 = alloca(32);
  v115 = &v131;
  v131;
  *(inited + 144) = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTt1g5(closure #1 in MLUntypedColumn.init<A>(_:)specialized partial apply);
  *(inited + 152) = v95 & 1;
  v131;
  v96 = Dictionary.init(dictionaryLiteral:)(inited, &type metadata for String, &type metadata for MLUntypedColumn, &protocol witness table for String);
  v97 = v141._countAndFlagsBits;
  _s8CreateML11MLDataTableV20uniqueKeysWithValuesACx_tKcSTRzSS3key_AA15MLUntypedColumnV5valuet7ElementRtzlufCSDySSAGG_Tt1g5(v96);
  if (!v97)
  {
    v98 = v132;
    v99 = v122;
    *v122 = v131;
    *(v99 + 8) = v98;
  }

  return outlined destroy of MLActivityClassifier.ModelParameters(v144, type metadata accessor for _TablePrinter);
}

uint64_t outlined consume of (offset: Int, element: MLDataTable.Row)?(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  if (a2)
  {
    a2;
    a3;
    return a4;
  }

  return result;
}

uint64_t static MLActivityClassifier.validateAndConvertParameters(_:featureColumns:labelColumn:recordingFileColumn:table:)(uint64_t a1, uint64_t a2, void *a3, uint64_t *a4, void *a5, void *a6, __m128 a7, uint64_t *a8)
{
  v10 = *(a8 + 8);
  v14 = *a8;
  v15 = v10;
  MLActivityClassifier.ModelParameters.generateTables(trainingData:featureColumns:labelColumn:recordingFileColumn:)(&v16, &v18, &v14, a2, a3, a4, a7, a5, a6);
  result = v13;
  if (!v8)
  {
    v20 = v16;
    v12 = v18;
    v22 = v19;
    v21 = v17;
    static MLActivityClassifier.validateAndConvertParameters(parameters:featureColumns:trainingTable:validationTable:)(a1, a2, &v16, &v18);
    outlined consume of MLDataTable?(v12, v22);
    return outlined consume of Result<_DataTable, Error>(v20, v21);
  }

  return result;
}

uint64_t static MLActivityClassifier.validateAndConvertParameters(parameters:featureColumns:trainingTable:validationTable:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v7 = v4;
  v48 = a2;
  v47 = a1;
  v8 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?) - 8) + 64);
  v9 = alloca(v8);
  v10 = alloca(v8);
  v44 = &v31;
  v11 = *a3;
  LODWORD(a3) = *(a3 + 8);
  v39 = *a4;
  LOBYTE(v46) = *(a4 + 8);
  v38 = type metadata accessor for MLActivityClassifier.Configuration(0);
  v12 = v7 + *(v38 + 44);
  *&v42 = v11;
  v49 = a3 & 1;
  BYTE8(v42) = a3 & 1;
  v48;
  v41 = v11;
  outlined copy of Result<_DataTable, Error>(v11, a3);
  DataFrame.init(_:)(&v42);
  v13 = type metadata accessor for DataFrame(0);
  v40 = v12;
  __swift_storeEnumTagSinglePayload(v12, 0, 1, v13);
  v14 = v7 + *(v38 + 48);
  __swift_storeEnumTagSinglePayload(v14, 1, 1, v13);
  *v7 = 10;
  *(v7 + 8) = 0;
  *(v7 + 16) = 0;
  *(v7 + 24) = 32;
  *(v7 + 32) = 100;
  *(v7 + 40) = v48;
  *(v7 + 48) = 0x6C6562616CLL;
  *(v7 + 56) = 0xE500000000000000;
  *(v7 + 64) = 0x5F6E6F6973736573;
  *(v7 + 72) = 0xEA00000000006469;
  v15 = type metadata accessor for MLActivityClassifier.ModelParameters(0);
  v16 = v47;
  v17 = v15[6];
  if (!*(v47 + v17 + 8))
  {
    *v7 = *(v47 + v17);
  }

  v18 = v15[7];
  if (!*(v16 + v18 + 8))
  {
    *(v7 + 24) = *(v16 + v18);
  }

  v19 = v15[8];
  if (!*(v16 + v19 + 8))
  {
    *(v7 + 32) = *(v16 + v19);
  }

  v45 = v13;
  if (v46 == 0xFF)
  {
    v46 = v14;
    v36 = v41;
    v37 = v49;
    v42 = 0;
    v43 = 256;
    MLDataTable.randomSplitBySequence(strategy:by:on:)(&v32, &v34, &v42, 0x5F6E6F6973736573, 0xEA00000000006469, 0x6C6562616CLL, 0xE500000000000000);
    v47 = v32;
    v24 = v33;
    v25 = v35;
    *&v42 = v34;
    BYTE8(v42) = v35 & 1;
    v48 = v34;
    outlined copy of Result<_DataTable, Error>(v34, v35);
    v26 = v44;
    DataFrame.init(_:)(&v42);
    __swift_storeEnumTagSinglePayload(v26, 0, 1, v45);
    outlined assign with take of DataFrame?(v26, v40);
    if (v24 == -1)
    {
      return outlined consume of Result<_DataTable, Error>(v48, v25);
    }

    v27 = v47;
    *&v42 = v47;
    v28 = v24;
    BYTE8(v42) = v24 & 1;
    outlined copy of Result<_DataTable, Error>(v47, v24);
    v29 = v44;
    DataFrame.init(_:)(&v42);
    outlined consume of Result<_DataTable, Error>(v48, v25);
    outlined consume of MLDataTable?(v27, v28);
    __swift_storeEnumTagSinglePayload(v29, 0, 1, v45);
    v22 = v29;
    v23 = v46;
  }

  else
  {
    *&v42 = v39;
    BYTE8(v42) = v46 & 1;
    outlined copy of Result<_DataTable, Error>(v39, v46);
    v20 = v14;
    v21 = v44;
    DataFrame.init(_:)(&v42);
    __swift_storeEnumTagSinglePayload(v21, 0, 1, v45);
    v22 = v21;
    v23 = v20;
  }

  return outlined assign with take of DataFrame?(v22, v23);
}

uint64_t MLActivityClassifier.write(to:metadata:)(uint64_t a1, const void *a2, double a3, double a4)
{
  v77 = v4;
  v5 = *(*(type metadata accessor for MLActivityClassifier.Model(0) - 8) + 64);
  v6 = alloca(v5);
  v7 = alloca(v5);
  v74 = v71;
  v8 = alloca(v5);
  v9 = alloca(v5);
  v73 = v71;
  v10 = alloca(v5);
  v11 = alloca(v5);
  v78 = v71;
  v12 = type metadata accessor for URL(0);
  v13 = *(v12 - 8);
  v14 = *(v13 + 64);
  v15 = alloca(v14);
  v16 = alloca(v14);
  qmemcpy(v75, a2, sizeof(v75));
  v76 = a1;
  v80 = v12;
  v79 = v13;
  (*(v13 + 16))(v71, a1);
  v81 = v71;
  if (URL.hasDirectoryPath.getter())
  {
    v17._countAndFlagsBits = 0xD00000000000001CLL;
    v17._object = "l, appending that to file name." + 0x8000000000000000;
    URL.appendPathComponent(_:)(v17);
    *v72 = 0;
    *&v72[8] = 0xE000000000000000;
    _StringGuts.grow(_:)(69);
    v17._object = " be an empty string." + 0x8000000000000000;
    v17._countAndFlagsBits = 0xD000000000000041;
    String.append(_:)(v17);
    v17._countAndFlagsBits = 0xD00000000000001CLL;
    v17._object = "l, appending that to file name." + 0x8000000000000000;
    String.append(_:)(v17);
    v17._object = 0xE200000000000000;
    v17._countAndFlagsBits = 11815;
    String.append(_:)(v17);
    v18 = *v72;
    v19 = *&v72[8];
    v20 = static os_log_type_t.info.getter();
    v17._countAndFlagsBits = v18;
    v17._object = v19;
    log(_:type:)(v17, v20);
    v19;
  }

  v22 = URL.pathExtension.getter();
  v23 = v21;
  if (!(v22 ^ 0x67616B6361706C6DLL | v21 ^ 0xE900000000000065) || (_stringCompareWithSmolCheck(_:_:expecting:)(0x67616B6361706C6DLL, 0xE900000000000065, v22, v21, 0) & 1) != 0)
  {
    v23;
    v24 = v78;
    outlined init with copy of MLActivityClassifier.Model(v77, v78);
    v25 = *&v75[8];
    if (*&v75[8])
    {
      v26 = *v75;
      v27 = *&v75[16];
      v28 = *&v75[24];
      v29 = *&v75[32];
      v30 = *&v75[48];
      v31 = *&v75[56];
      v32 = *&v75[64];
    }

    else
    {
      v33 = NSFullUserName();
      v34 = v33;
      v35 = static String._unconditionallyBridgeFromObjectiveC(_:)(v34);
      v25 = v36;

      v28 = "RandomForestRegressor" + 0x8000000000000000;
      v37 = v35;
      v77 = v35;
      *v71 = v35;
      *&v71[8] = v25;
      *&v71[16] = 0xD000000000000033;
      *&v71[24] = "RandomForestRegressor" + 0x8000000000000000;
      *&v71[32] = 0;
      *&v71[48] = 49;
      v31 = 0xE100000000000000;
      *&v71[56] = 0xE100000000000000;
      *&v71[64] = 0;
      *v72 = v37;
      *&v72[8] = v25;
      *&v72[16] = 0xD000000000000033;
      *&v72[24] = "RandomForestRegressor" + 0x8000000000000000;
      *&v72[32] = 0;
      *&v72[48] = 49;
      *&v72[56] = 0xE100000000000000;
      *&v72[64] = 0;
      outlined retain of MLModelMetadata(v71);
      outlined release of MLModelMetadata(v72, v24);
      v30 = 49;
      v29 = 0;
      v27 = 0xD000000000000033;
      v26 = v77;
      v32 = 0;
    }

    *v72 = v26;
    *&v72[8] = v25;
    *&v72[16] = v27;
    *&v72[24] = v28;
    *&v72[32] = v29;
    *&v72[48] = v30;
    *&v72[56] = v31;
    *&v72[64] = v32;
    outlined retain of MLModelMetadata?(v75);
    v38 = v76;
    v39 = v78;
LABEL_9:
    MLActivityClassifier.Model.writeMLPackage(to:metadata:)(v38, v72, *&v29, a4);
    goto LABEL_10;
  }

  if (v22 ^ 0x6C65646F6D6C6DLL | v23 ^ 0xE700000000000000)
  {
    v41 = _stringCompareWithSmolCheck(_:_:expecting:)(0x6C65646F6D6C6DLL, 0xE700000000000000, v22, v23, 0);
    v23;
    if ((v41 & 1) == 0)
    {
      v56 = static os_log_type_t.info.getter();
      v57._countAndFlagsBits = 0xD00000000000004FLL;
      v57._object = "Image does not exist at " + 0x8000000000000000;
      log(_:type:)(v57, v56);
      v57._countAndFlagsBits = 0x67616B6361706C6DLL;
      v57._object = 0xE900000000000065;
      URL.appendPathExtension(_:)(v57);
      v58 = v74;
      outlined init with copy of MLActivityClassifier.Model(v77, v74);
      v59 = *&v75[8];
      if (*&v75[8])
      {
        v60 = *v75;
        v61 = *&v75[16];
        v62 = *&v75[24];
        v29 = *&v75[32];
        v63 = *&v75[48];
        v64 = *&v75[56];
        v65 = *&v75[64];
      }

      else
      {
        v66 = NSFullUserName();
        v67 = v66;
        v68 = static String._unconditionallyBridgeFromObjectiveC(_:)(v67);
        v59 = v69;

        v62 = "RandomForestRegressor" + 0x8000000000000000;
        v70 = v68;
        v78 = v68;
        *v71 = v68;
        *&v71[8] = v59;
        *&v71[16] = 0xD000000000000033;
        *&v71[24] = "RandomForestRegressor" + 0x8000000000000000;
        *&v71[32] = 0;
        *&v71[48] = 49;
        v64 = 0xE100000000000000;
        *&v71[56] = 0xE100000000000000;
        *&v71[64] = 0;
        *v72 = v70;
        *&v72[8] = v59;
        *&v72[16] = 0xD000000000000033;
        *&v72[24] = "RandomForestRegressor" + 0x8000000000000000;
        *&v72[32] = 0;
        *&v72[48] = 49;
        *&v72[56] = 0xE100000000000000;
        *&v72[64] = 0;
        outlined retain of MLModelMetadata(v71);
        outlined release of MLModelMetadata(v72, v58);
        v63 = 49;
        v29 = 0;
        v60 = v78;
        v61 = 0xD000000000000033;
        v65 = 0;
      }

      *v72 = v60;
      *&v72[8] = v59;
      *&v72[16] = v61;
      *&v72[24] = v62;
      *&v72[32] = v29;
      *&v72[48] = v63;
      *&v72[56] = v64;
      *&v72[64] = v65;
      outlined retain of MLModelMetadata?(v75);
      v38 = v76;
      v39 = v74;
      goto LABEL_9;
    }
  }

  else
  {
    v23;
  }

  v42 = v73;
  outlined init with copy of MLActivityClassifier.Model(v77, v73);
  v43 = *&v75[8];
  if (*&v75[8])
  {
    v44 = *v75;
    v45 = *&v75[16];
    v46 = *&v75[24];
    v47 = *&v75[32];
    v48 = *&v75[48];
    v49 = *&v75[56];
    v50 = *&v75[64];
  }

  else
  {
    v51 = NSFullUserName();
    v52 = v51;
    v53 = static String._unconditionallyBridgeFromObjectiveC(_:)(v52);
    v43 = v54;

    v46 = "RandomForestRegressor" + 0x8000000000000000;
    v55 = v53;
    v78 = v53;
    *v71 = v53;
    *&v71[8] = v43;
    *&v71[16] = 0xD000000000000033;
    *&v71[24] = "RandomForestRegressor" + 0x8000000000000000;
    *&v71[32] = 0;
    *&v71[48] = 49;
    v49 = 0xE100000000000000;
    *&v71[56] = 0xE100000000000000;
    *&v71[64] = 0;
    *v72 = v55;
    *&v72[8] = v43;
    *&v72[16] = 0xD000000000000033;
    *&v72[24] = "RandomForestRegressor" + 0x8000000000000000;
    *&v72[32] = 0;
    *&v72[48] = 49;
    *&v72[56] = 0xE100000000000000;
    *&v72[64] = 0;
    outlined retain of MLModelMetadata(v71);
    outlined release of MLModelMetadata(v72, v42);
    v48 = 49;
    v47 = 0;
    v45 = 0xD000000000000033;
    v44 = v78;
    v50 = 0;
  }

  *v72 = v44;
  *&v72[8] = v43;
  *&v72[16] = v45;
  *&v72[24] = v46;
  *&v72[32] = v47;
  *&v72[48] = v48;
  *&v72[56] = v49;
  *&v72[64] = v50;
  outlined retain of MLModelMetadata?(v75);
  v39 = v73;
  MLActivityClassifier.Model.writeMLModel(to:metadata:)(v76, v72);
LABEL_10:
  qmemcpy(v71, v72, sizeof(v71));
  outlined release of MLModelMetadata(v71, &v73);
  outlined destroy of MLActivityClassifier.Model(v39);
  return (*(v79 + 8))(v81, v80);
}

uint64_t outlined init with copy of MLActivityClassifier.Model(uint64_t a1, uint64_t a2)
{
  v2 = type metadata accessor for MLActivityClassifier.Model(0);
  (*(*(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t outlined destroy of MLActivityClassifier.Model(uint64_t a1)
{
  v1 = type metadata accessor for MLActivityClassifier.Model(0);
  (*(*(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t MLActivityClassifier.write(toFile:metadata:)(uint64_t a1, uint64_t a2, const void *a3, double a4, double a5)
{
  v11[1] = v5;
  v12 = a3;
  v6 = type metadata accessor for URL(0);
  v13 = *(v6 - 8);
  v7 = *(v13 + 64);
  v8 = alloca(v7);
  v9 = alloca(v7);
  URL.init(fileURLWithPath:)(a1, a2);
  MLActivityClassifier.write(to:metadata:)(v11, v12, a4, a5);
  return (*(v13 + 8))(v11, v6);
}

uint64_t outlined assign with take of DataFrame?(uint64_t a1, uint64_t a2)
{
  v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?);
  (*(*(v2 - 8) + 40))(a2, a1, v2);
  return a2;
}

void *_sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVy11TabularData6ColumnVySSGAKG_SS4text_SS5labelts5NeverOTg5043_sSSSgAAS2SIgggoo_AA_AAtSS4text_SS5labelts5k106OIegnrzr_TR143_s8CreateML16MLTextClassifierV10evaluation2on10textColumn05labelH0AA19MLClassifierMetricsV11f31Data0M5FrameV_S2StFSS0G0_SS0I0tM19_AOtXEfU_Tf3nnnpf_nTf1cn_n(uint64_t a1)
{
  v1 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  i = *(v1 - 8);
  v2 = *(i + 64);
  v3 = alloca(v2);
  v4 = alloca(v2);
  v72 = &v57;
  v68 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>);
  v5 = *(*(v68 - 8) + 64);
  v6 = alloca(v5);
  v7 = alloca(v5);
  v70 = &v57;
  v59 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>.Iterator);
  v8 = *(*(v59 - 8) + 64);
  v9 = alloca(v8);
  v10 = alloca(v8);
  v63 = &v57;
  v11 = lazy protocol witness table accessor for type Column<String> and conformance Column<A>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &protocol conformance descriptor for Column<A>);
  v67 = v11;
  v66 = dispatch thunk of Sequence.underestimatedCount.getter(v1, v11);
  v12 = a1 + *(v68 + 52);
  v13 = dispatch thunk of Sequence.underestimatedCount.getter(v1, v11);
  v14 = v66;
  if (v13 < v66)
  {
    v14 = v13;
  }

  v66 = v14;
  v65 = _swiftEmptyArrayStorage;
  v15 = 0;
  if (v14 > 0)
  {
    v15 = v14;
  }

  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v15, 0);
  v69 = v65;
  v16 = v70;
  outlined init with copy of Zip2Sequence<Column<String>, Column<String>>(a1, v70);
  i = *(i + 32);
  (i)(v72, v16, v1);
  v17 = v63;
  v18 = v67;
  dispatch thunk of Sequence.makeIterator()(v1, v67);
  (i)(v72, v70 + *(v68 + 52), v1);
  v68 = v17 + *(v59 + 52);
  dispatch thunk of Sequence.makeIterator()(v1, v18);
  if (v66 < 0)
  {
    BUG();
  }

  v19 = v1;
  v62 = v1;
  v20 = v17;
  if (v66)
  {
    v21 = *(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<Column<String>>) + 36);
    v70 = (v17 + v21);
    i = v68 + v21;
    v72 = lazy protocol witness table accessor for type Column<String> and conformance Column<A>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &protocol conformance descriptor for Column<A>);
    do
    {
      dispatch thunk of Collection.endIndex.getter(v19, v72);
      if (*v70 == v58[0])
      {
        BUG();
      }

      v22 = v62;
      v23 = dispatch thunk of Collection.subscript.read(v58, v70, v62, v72);
      v64 = *v24;
      v67 = v24[1];
      v67;
      v23(v58, 0);
      v25 = v72;
      dispatch thunk of Collection.formIndex(after:)(v70, v22, v72);
      dispatch thunk of Collection.endIndex.getter(v22, v25);
      if (*i == v58[0])
      {
        v67;
        BUG();
      }

      v26 = v72;
      v28 = dispatch thunk of Collection.subscript.read(v58, i, v22, v72);
      v29 = v27[1];
      v30 = v29;
      v31 = 0xE000000000000000;
      if (v29)
      {
        v30 = *v27;
        v31 = v27[1];
      }

      v61 = v31;
      v60 = v30;
      v29;
      v28(v58, 0);
      dispatch thunk of Collection.formIndex(after:)(i, v62, v26);
      v32 = v67;
      v33 = v64;
      if (!v67)
      {
        v33 = 0;
        v32 = 0xE000000000000000;
      }

      v34 = v69;
      v65 = v69;
      v35 = v69[2];
      v36 = v69[3];
      v37 = v35 + 1;
      if (v36 >> 1 <= v35)
      {
        v69 = (v35 + 1);
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v36 >= 2, v37, 1);
        v37 = v69;
        v34 = v65;
      }

      v34[2] = v37;
      v38 = 4 * v35;
      v34[v38 + 4] = v33;
      v34[v38 + 5] = v32;
      v34[v38 + 6] = v60;
      v69 = v34;
      v34[v38 + 7] = v61;
      v39 = v66-- == 1;
      v19 = v62;
      v20 = v63;
    }

    while (!v39);
  }

  v66 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<Column<String>>);
  v70 = (v20 + *(v66 + 36));
  v40 = lazy protocol witness table accessor for type Column<String> and conformance Column<A>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &protocol conformance descriptor for Column<A>);
  for (i = v40; ; v40 = i)
  {
    v41 = v40;
    dispatch thunk of Collection.endIndex.getter(v19, v40);
    if (*v70 == v58[0])
    {
      break;
    }

    v72 = dispatch thunk of Collection.subscript.read(v58, v70, v19, v41);
    v64 = *v42;
    v67 = v42[1];
    v67;
    (v72)(v58, 0);
    dispatch thunk of Collection.formIndex(after:)(v70, v19, v41);
    v72 = *(v66 + 36);
    v43 = v68;
    dispatch thunk of Collection.endIndex.getter(v19, v41);
    if (*(v43 + v72) == v58[0])
    {
      v67;
      break;
    }

    v72 += v43;
    v45 = dispatch thunk of Collection.subscript.read(v58, v72, v19, v41);
    v46 = v44[1];
    v47 = v46;
    v48 = 0xE000000000000000;
    if (v46)
    {
      v47 = *v44;
      v48 = v44[1];
    }

    v61 = v48;
    v60 = v47;
    v46;
    v45(v58, 0);
    dispatch thunk of Collection.formIndex(after:)(v72, v19, i);
    v49 = v67;
    v50 = v64;
    if (!v67)
    {
      v50 = 0;
      v49 = 0xE000000000000000;
    }

    v51 = v69;
    v65 = v69;
    v52 = v69[2];
    v53 = v69[3];
    if (v53 >> 1 <= v52)
    {
      v64 = v50;
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v53 >= 2, v52 + 1, 1);
      v50 = v64;
      v51 = v65;
    }

    v51[2] = v52 + 1;
    v54 = 4 * v52;
    v51[v54 + 4] = v50;
    v51[v54 + 5] = v49;
    v51[v54 + 6] = v60;
    v69 = v51;
    v51[v54 + 7] = v61;
    v19 = v62;
  }

  v55 = v63;
  *(v63 + *(v59 + 56)) = 1;
  outlined destroy of Tensor?(v55, &demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>.Iterator);
  return v69;
}

uint64_t MLTextClassifier.evaluation(on:)(uint64_t a1, double a2)
{
  v3 = static _TextUtilities.getTextLabeledDictionary(from:)(a1, a2);
  v4 = unpackLabeledTexts(_:)(v3);
  _s8CreateML16MLTextClassifierV10evaluation2on5usingAA19MLClassifierMetricsVx_So7NLModelCtSlRzSS4text_SS5labelt7ElementRtzlFZSaySSAK_SSALtG_Tt2g5(v4, *v2);
  v3;
  return v4;
}

uint64_t MLTextClassifier.evaluation(on:)(uint64_t a1)
{
  v2 = unpackLabeledTexts(_:)(a1);
  _s8CreateML16MLTextClassifierV10evaluation2on5usingAA19MLClassifierMetricsVx_So7NLModelCtSlRzSS4text_SS5labelt7ElementRtzlFZSaySSAK_SSALtG_Tt2g5(v2, *v1);
  return v2;
}

uint64_t MLTextClassifier.evaluation(on:textColumn:labelColumn:)(uint64_t a1, uint64_t a2, void *a3, uint64_t a4, void *a5)
{
  v35 = v6;
  _ = a5;
  v43._countAndFlagsBits = a4;
  v41 = v5;
  v38 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>);
  v8 = *(*(v38 - 8) + 64);
  v9 = alloca(v8);
  v10 = alloca(v8);
  v37 = &v34;
  v36 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  v43._object = *(v36 - 8);
  v11 = *(v43._object + 8);
  v12 = alloca(v11);
  v13 = alloca(v11);
  v45 = &v34;
  v14 = alloca(v11);
  v15 = alloca(v11);
  v44 = &v34;
  v16 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any.Type>);
  v17 = swift_allocObject(v16, 40, 7);
  v17[2] = 1;
  v17[3] = 2;
  v17[4] = &type metadata for String;
  v39 = a2;
  v18._countAndFlagsBits = a2;
  v19 = a3;
  v18._object = a3;
  DataFrame.validateColumnTypes(_:_:context:)(v18, v17, __PAIR128__(0xE400000000000000, 1954047316));
  v17;
  if (v20)
  {
    goto LABEL_3;
  }

  v40 = v19;
  v21 = v44;
  object = v43._object;
  v23 = swift_allocObject(v16, 40, 7);
  v23[2] = 1;
  v23[3] = 2;
  v23[4] = &type metadata for String;
  v24._countAndFlagsBits = v43._countAndFlagsBits;
  v24._object = _;
  DataFrame.validateColumnTypes(_:_:context:)(v24, v23, __PAIR128__(0xE500000000000000, 0x6C6562614CLL));
  v23;
  if (v20)
  {
LABEL_3:
    v25 = v41;
    *v41 = v20;
    v26 = type metadata accessor for MLClassifierMetrics.Contents(0);
    return swift_storeEnumTagMultiPayload(v25, v26, 2);
  }

  else
  {
    DataFrame.subscript.getter(v39, v40, &type metadata for String);
    DataFrame.subscript.getter(v43._countAndFlagsBits, _, &type metadata for String);
    v28 = object[2];
    v29 = v37;
    v30 = v36;
    v28(v37, v21, v36);
    v31 = v45;
    v28((v29 + *(v38 + 52)), v45, v30);
    ML16MLTextClassifierV10evaluation2on10textColumn05labelH0AA19MLClassifierMetricsV11f31Data0M5FrameV_S2StFSS0G0_SS0I0tM19_AOtXEfU_Tf3nnnpf_nTf1cn_n = _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVy11TabularData6ColumnVySSGAKG_SS4text_SS5labelts5NeverOTg5043_sSSSgAAS2SIgggoo_AA_AAtSS4text_SS5labelts5k106OIegnrzr_TR143_s8CreateML16MLTextClassifierV10evaluation2on10textColumn05labelH0AA19MLClassifierMetricsV11f31Data0M5FrameV_S2StFSS0G0_SS0I0tM19_AOtXEfU_Tf3nnnpf_nTf1cn_n(v29);
    outlined destroy of Tensor?(v29, &demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>);
    _s8CreateML16MLTextClassifierV10evaluation2on5usingAA19MLClassifierMetricsVx_So7NLModelCtSlRzSS4text_SS5labelt7ElementRtzlFZSaySSAK_SSALtG_Tt2g5(ML16MLTextClassifierV10evaluation2on10textColumn05labelH0AA19MLClassifierMetricsV11f31Data0M5FrameV_S2StFSS0G0_SS0I0tM19_AOtXEfU_Tf3nnnpf_nTf1cn_n, *v35);
    v33 = *(v43._object + 1);
    v33(v31, v30);
    v33(v44, v30);
    return ML16MLTextClassifierV10evaluation2on10textColumn05labelH0AA19MLClassifierMetricsV11f31Data0M5FrameV_S2StFSS0G0_SS0I0tM19_AOtXEfU_Tf3nnnpf_nTf1cn_n;
  }
}

{
  v15 = v5;
  v16 = a5;
  v17 = a4;
  v18 = a3;
  v19 = a2;
  v6 = type metadata accessor for DataFrame(0);
  v7 = *(v6 - 8);
  v8 = *(v7 + 64);
  v9 = alloca(v8);
  v10 = alloca(v8);
  v11 = *(a1 + 8);
  v13 = *a1;
  v14 = v11;
  outlined copy of Result<_DataTable, Error>(v13, v11);
  DataFrame.init(_:)(&v13);
  MLTextClassifier.evaluation(on:textColumn:labelColumn:)(&v13, v19, v18, v17, v16);
  return (*(v7 + 8))(&v13, v6);
}

uint64_t outlined init with copy of Zip2Sequence<Column<String>, Column<String>>(uint64_t a1, uint64_t a2)
{
  v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<Column<String>, Column<String>>);
  (*(*(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

void *initializeBufferWithCopyOfBuffer for MLSupportVectorClassifier.Classifier(void *a1, uint64_t *a2, uint64_t a3)
{
  v3 = a1;
  v4 = *(*(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    v9 = *a2;
    *v3 = *a2;
    v3 = (v9 + ((v4 + 16) & ~v4));
  }

  else
  {
    *a1 = *a2;
    v6 = a2[1];
    v3[1] = v6;
    v7 = a2[2];
    v3[2] = v7;
    v3[3] = a2[3];
    v21 = v3 + 4;
    v22 = (a2 + 4);
    v8 = a2[7];
    v6;
    v7;
    if (v8)
    {
      v3[7] = v8;
      (**(v8 - 8))(v21, v22, v8);
    }

    else
    {
      v10 = *v22;
      *(v3 + 3) = *(a2 + 3);
      *v21 = v10;
    }

    *(v3 + 4) = *(a2 + 4);
    *(v3 + 80) = *(a2 + 80);
    v11 = *(a3 + 28);
    v12 = v3 + v11;
    v13 = a2 + v11;
    v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    if (swift_getEnumCaseMultiPayload(v13, v14) == 1)
    {
      v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>);
      (*(*(v15 - 8) + 16))(v12, v13, v15);
      v16 = 1;
      v17 = v12;
      v18 = v14;
    }

    else
    {
      v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>);
      (*(*(v19 - 8) + 16))(v12, v13, v19);
      v17 = v12;
      v18 = v14;
      v16 = 0;
    }

    swift_storeEnumTagMultiPayload(v17, v18, v16);
  }

  return v3;
}

uint64_t destroy for MLSupportVectorClassifier.Classifier(void *a1, uint64_t a2)
{
  a1[1];
  a1[2];
  if (a1[7])
  {
    __swift_destroy_boxed_opaque_existential_1Tm(a1 + 4);
  }

  v2 = a1 + *(a2 + 28);
  v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  v4 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>;
  if (swift_getEnumCaseMultiPayload(v2, v3) == 1)
  {
    v4 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>;
  }

  v5 = __swift_instantiateConcreteTypeFromMangledName(v4);
  return (*(*(v5 - 8) + 8))(v2, v5);
}

uint64_t initializeWithCopy for MLSupportVectorClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *a1 = *a2;
  v4 = *(a2 + 8);
  *(a1 + 8) = v4;
  v5 = *(a2 + 16);
  *(a1 + 16) = v5;
  *(a1 + 24) = *(a2 + 24);
  v18 = (a1 + 32);
  v6 = *(a2 + 56);
  v4;
  v5;
  if (v6)
  {
    *(a1 + 56) = v6;
    (**(v6 - 8))(v18, a2 + 32, v6);
  }

  else
  {
    v7 = *(a2 + 32);
    *(a1 + 48) = *(a2 + 48);
    *v18 = v7;
  }

  *(a1 + 64) = *(a2 + 64);
  *(a1 + 80) = *(a2 + 80);
  v8 = *(a3 + 28);
  v9 = a1 + v8;
  v10 = v8 + a2;
  v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v10, v11);
  v13 = EnumCaseMultiPayload == 1;
  v14 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>;
  if (EnumCaseMultiPayload == 1)
  {
    v14 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>;
  }

  v15 = __swift_instantiateConcreteTypeFromMangledName(v14);
  (*(*(v15 - 8) + 16))(v9, v10, v15);
  swift_storeEnumTagMultiPayload(v9, v11, v13);
  return a1;
}

uint64_t assignWithCopy for MLSupportVectorClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *a1 = *a2;
  v5 = *(a2 + 8);
  v6 = *(a1 + 8);
  *(a1 + 8) = v5;
  v5;
  v6;
  v7 = *(a2 + 16);
  v8 = *(a1 + 16);
  *(a1 + 16) = v7;
  v7;
  v8;
  *(a1 + 24) = *(a2 + 24);
  v9 = *(a2 + 56);
  if (*(a1 + 56))
  {
    if (v9)
    {
      __swift_assign_boxed_opaque_existential_0((a1 + 32), (a2 + 32));
      goto LABEL_8;
    }

    __swift_destroy_boxed_opaque_existential_1Tm((a1 + 32));
  }

  else if (v9)
  {
    *(a1 + 56) = v9;
    (**(v9 - 8))(a1 + 32, a2 + 32);
    goto LABEL_8;
  }

  v10 = *(a2 + 32);
  *(a1 + 48) = *(a2 + 48);
  *(a1 + 32) = v10;
LABEL_8:
  *(a1 + 64) = *(a2 + 64);
  *(a1 + 72) = *(a2 + 72);
  *(a1 + 80) = *(a2 + 80);
  if (a1 != a2)
  {
    v11 = *(a3 + 28);
    v12 = v11 + a2;
    v13 = a1 + v11;
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v13, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v12, v14);
    v16 = EnumCaseMultiPayload == 1;
    v17 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>;
    if (EnumCaseMultiPayload == 1)
    {
      v17 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>;
    }

    v18 = __swift_instantiateConcreteTypeFromMangledName(v17);
    (*(*(v18 - 8) + 16))(v13, v12, v18);
    swift_storeEnumTagMultiPayload(v13, v14, v16);
  }

  return a1;
}

uint64_t initializeWithTake for MLSupportVectorClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *a1 = *a2;
  *(a1 + 16) = *(a2 + 16);
  v4 = *(a2 + 24);
  v5 = *(a2 + 40);
  v6 = *(a2 + 56);
  *(a1 + 65) = *(a2 + 65);
  *(a1 + 56) = v6;
  *(a1 + 40) = v5;
  *(a1 + 24) = v4;
  v7 = *(a3 + 28);
  v8 = a1 + v7;
  v9 = v7 + a2;
  v10 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v9, v10);
  v12 = EnumCaseMultiPayload == 1;
  v13 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>;
  if (EnumCaseMultiPayload == 1)
  {
    v13 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>;
  }

  v14 = __swift_instantiateConcreteTypeFromMangledName(v13);
  (*(*(v14 - 8) + 32))(v8, v9, v14);
  swift_storeEnumTagMultiPayload(v8, v10, v12);
  return a1;
}

uint64_t assignWithTake for MLSupportVectorClassifier.Classifier(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *a1 = *a2;
  v5 = *(a1 + 8);
  *(a1 + 8) = *(a2 + 8);
  v5;
  v6 = *(a1 + 16);
  *(a1 + 16) = *(a2 + 16);
  v6;
  *(a1 + 24) = *(a2 + 24);
  if (*(a1 + 56))
  {
    __swift_destroy_boxed_opaque_existential_1Tm((a1 + 32));
  }

  v7 = *(a2 + 32);
  *(a1 + 48) = *(a2 + 48);
  *(a1 + 32) = v7;
  *(a1 + 64) = *(a2 + 64);
  *(a1 + 80) = *(a2 + 80);
  if (a1 != a2)
  {
    v8 = *(a3 + 28);
    v9 = v8 + a2;
    v10 = a1 + v8;
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v10, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v9, v11);
    v13 = EnumCaseMultiPayload == 1;
    v14 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>;
    if (EnumCaseMultiPayload == 1)
    {
      v14 = &demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>;
    }

    v15 = __swift_instantiateConcreteTypeFromMangledName(v14);
    (*(*(v15 - 8) + 32))(v10, v9, v15);
    swift_storeEnumTagMultiPayload(v10, v11, v13);
  }

  return a1;
}

uint64_t sub_2A8812(uint64_t a1, unsigned int a2, uint64_t a3)
{
  if (a2 == 0x7FFFFFFF)
  {
    result = 0;
    if ((*(a1 + 8) & 0xFFFFFFFF00000001) == 0)
    {
      return (*(a1 + 8) >> 1) + 1;
    }
  }

  else
  {
    v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    return __swift_getEnumTagSinglePayload(*(a3 + 28) + a1, a2, v5);
  }

  return result;
}

uint64_t sub_2A889F(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  if (a3 == 0x7FFFFFFF)
  {
    *(a1 + 8) = 2 * (a2 - 1);
  }

  else
  {
    v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    return __swift_storeEnumTagSinglePayload(*(a4 + 28) + a1, a2, a2, v5);
  }

  return result;
}

uint64_t type metadata accessor for MLSupportVectorClassifier.Classifier(uint64_t a1)
{
  result = type metadata singleton initialization cache for MLSupportVectorClassifier.Classifier;
  if (!type metadata singleton initialization cache for MLSupportVectorClassifier.Classifier)
  {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLSupportVectorClassifier.Classifier);
  }

  return result;
}

uint64_t type metadata completion function for MLSupportVectorClassifier.Classifier(uint64_t a1)
{
  v3[0] = &unk_348C88;
  v3[1] = &value witness table for Builtin.BridgeObject + 64;
  v3[2] = &unk_348CA0;
  result = type metadata accessor for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>(319);
  if (v2 <= 0x3F)
  {
    v3[3] = *(result - 8) + 64;
    swift_initStructMetadata(a1, 256, 4, v3, a1 + 16);
    return 0;
  }

  return result;
}

uint64_t type metadata accessor for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>(uint64_t a1)
{
  result = lazy cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>;
  if (!lazy cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>)
  {
    v2 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>);
    v3 = __swift_instantiateConcreteTypeFromMangledNameAbstract(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>);
    result = type metadata accessor for Either(a1, v2, v3, v4);
    if (!v5)
    {
      lazy cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>> = result;
    }
  }

  return result;
}

uint64_t lazy protocol witness table accessor for type MLSupportVectorClassifier.Model and conformance MLSupportVectorClassifier.Model()
{
  result = lazy protocol witness table cache variable for type MLSupportVectorClassifier.Model and conformance MLSupportVectorClassifier.Model;
  if (!lazy protocol witness table cache variable for type MLSupportVectorClassifier.Model and conformance MLSupportVectorClassifier.Model)
  {
    v1 = type metadata accessor for MLSupportVectorClassifier.Model(255);
    result = swift_getWitnessTable(&protocol conformance descriptor for MLSupportVectorClassifier.Model, v1);
    lazy protocol witness table cache variable for type MLSupportVectorClassifier.Model and conformance MLSupportVectorClassifier.Model = result;
  }

  return result;
}

void *_sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVySay6CoreML13MLShapedArrayVySdGG11TabularData12FilledColumnVyAM0M0VySSGGG_18CreateMLComponents16AnnotatedFeatureVyAKSSGs5NeverOTg503_s6f4ML13hi9VySdGSS18n14MLComponents16pqu22ADSSGIegngr_AD_SStAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSSGAY_SStcfu0_Tf3nnnpf_nTf1cn_nTm(uint64_t a1)
{
  v96 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Double>, String>);
  v97 = *(v96 - 8);
  v1 = *(v97 + 64);
  v2 = alloca(v1);
  v3 = alloca(v1);
  v105 = &v87;
  v4 = alloca(v1);
  v5 = alloca(v1);
  v100 = &v87;
  v117 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
  v116 = *(v117 - 8);
  v6 = *(v116 + 64);
  v7 = alloca(v6);
  v8 = alloca(v6);
  v109 = &v87;
  v9 = alloca(v6);
  v10 = alloca(v6);
  v98 = &v87;
  v11 = alloca(v6);
  v12 = alloca(v6);
  v104 = &v87;
  v99 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLShapedArray<Double>, String));
  v13 = *(*(v99 - 8) + 64);
  v14 = alloca(v13);
  v15 = alloca(v13);
  v88 = &v87;
  v16 = alloca(v13);
  v17 = alloca(v13);
  v91 = &v87;
  v18 = alloca(v13);
  v19 = alloca(v13);
  v92 = &v87;
  v107 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>);
  v115 = *(v107 - 8);
  v20 = *(v115 + 64);
  v21 = alloca(v20);
  v22 = alloca(v20);
  v110 = &v87;
  v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>);
  v24 = *(v23 - 8);
  v25 = v23;
  v102 = v23;
  v26 = *(v24 + 64);
  v27 = alloca(v26);
  v28 = alloca(v26);
  v111 = &v87;
  v101 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>.Iterator);
  v29 = *(*(v101 - 8) + 64);
  v30 = alloca(v29);
  v31 = alloca(v29);
  v113 = a1;
  v32 = *(*a1 + 16);
  v33 = a1 + *(v25 + 52);
  v112 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<String>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<String>>, &protocol conformance descriptor for FilledColumn<A>);
  v34 = v107;
  v35 = dispatch thunk of Sequence.underestimatedCount.getter(v107, v112);
  v103 = v35;
  if (v35 < v32)
  {
    v32 = v35;
  }

  v114 = _swiftEmptyArrayStorage;
  v36 = 0;
  if (v32 > 0)
  {
    v36 = v32;
  }

  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v36, 0);
  v108 = v114;
  v37 = v111;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v113, v111, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>);
  v106 = *v37;
  v87 = v106;
  v88 = 0;
  (*(v115 + 32))(v110, &v37[*(v102 + 52)], v34);
  v38 = *(v101 + 52);
  v113 = &v87;
  v95 = &v87 + v38;
  dispatch thunk of Sequence.makeIterator()(v34, v112);
  if (v103 < 0)
  {
    BUG();
  }

  v39 = v32;
  if (!v32)
  {
    v42 = v116;
    goto LABEL_20;
  }

  v40 = v106;
  v89 = *(v106 + 16);
  v41 = 0;
  v42 = v116;
  v43 = v117;
  v90 = v32;
  do
  {
    if (v89 == v41)
    {
      goto LABEL_19;
    }

    v44 = v109;
    if (v41 >= *(v40 + 16))
    {
      BUG();
    }

    v45 = v41 + 1;
    v46 = v40 + ((*(v42 + 80) + 32) & ~*(v42 + 80)) + *(v42 + 72) * v41;
    v115 = v45;
    v113[1] = v45;
    v110 = *(v42 + 16);
    (v110)(v44, v46, v43);
    v47 = *(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<String>>>) + 36);
    v48 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<String>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<String>>, &protocol conformance descriptor for FilledColumn<A>);
    v49 = v95;
    v50 = v107;
    v111 = v48;
    dispatch thunk of Collection.endIndex.getter(v107, v48);
    if (*&v49[v47] == v93)
    {
      (*(v116 + 8))(v109, v117);
LABEL_19:
      BUG();
    }

    v51 = &v49[v47];
    v52 = v50;
    v53 = v111;
    v103 = dispatch thunk of Collection.subscript.read(&v93, v51, v52, v111);
    v112 = *v54;
    v102 = *(v54 + 8);
    v102;
    v103(&v93, 0);
    dispatch thunk of Collection.formIndex(after:)(v51, v107, v53);
    v55 = *(v99 + 48);
    v56 = v88;
    (*(v116 + 32))(v88, v109, v117);
    v57 = v112;
    *(v56 + v55) = v112;
    v58 = v102;
    *(v56 + v55 + 8) = v102;
    v59 = v98;
    (v110)(v98, v56, v117);
    v93 = v57;
    v94 = v58;
    v58;
    AnnotatedFeature.init(feature:annotation:)(v59, &v93, v117, &type metadata for String);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v56, &demangling cache variable for type metadata for (MLShapedArray<Double>, String));
    v60 = v108;
    v114 = v108;
    v61 = v108[2];
    v42 = v116;
    if (v108[3] >> 1 <= v61)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v108[3] >= 2uLL, v61 + 1, 1);
      v42 = v116;
      v60 = v114;
    }

    v60[2] = v61 + 1;
    v62 = *(v97 + 80);
    v108 = v60;
    (*(v97 + 32))(v60 + ((v62 + 32) & ~v62) + *(v97 + 72) * v61, v105, v96);
    v41 = v115;
    v39 = v90;
    v40 = v106;
    v43 = v117;
  }

  while (v90 != v115);
  while (1)
  {
    v63 = v104;
    if (v39 == *(v40 + 16))
    {
      break;
    }

    if (v39 >= *(v40 + 16))
    {
      BUG();
    }

    v64 = (v39 + 1);
    v65 = v40 + ((*(v42 + 80) + 32) & ~*(v42 + 80)) + *(v42 + 72) * v39;
    v109 = v64;
    v113[1] = v64;
    v105 = *(v42 + 16);
    (v105)(v63, v65, v43);
    v66 = *(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<String>>>) + 36);
    v67 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<String>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<String>>, &protocol conformance descriptor for FilledColumn<A>);
    v68 = v95;
    v69 = v107;
    v115 = v67;
    dispatch thunk of Collection.endIndex.getter(v107, v67);
    if (*&v68[v66] == v93)
    {
      (*(v116 + 8))(v104, v117);
      break;
    }

    v70 = &v68[v66];
    v71 = v69;
    v72 = v115;
    v112 = dispatch thunk of Collection.subscript.read(&v93, v70, v71, v115);
    v110 = *v73;
    v111 = v73[1];
    v111;
    v112(&v93, 0);
    dispatch thunk of Collection.formIndex(after:)(v70, v107, v72);
    v74 = v99;
    v75 = *(v99 + 48);
    v76 = v91;
    (*(v116 + 32))(v91, v104, v117);
    *(v76 + v75) = v110;
    *(v76 + v75 + 8) = v111;
    v77 = v92;
    outlined init with take of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(v76, v92, &demangling cache variable for type metadata for (MLShapedArray<Double>, String));
    v78 = *(v74 + 48);
    v115 = *(v77 + v78);
    v79 = *(v77 + v78 + 8);
    v80 = v98;
    v81 = v117;
    (v105)(v98, v77, v117);
    v93 = v115;
    v94 = v79;
    v79;
    AnnotatedFeature.init(feature:annotation:)(v80, &v93, v81, &type metadata for String);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v77, &demangling cache variable for type metadata for (MLShapedArray<Double>, String));
    v82 = v108;
    v114 = v108;
    v83 = v108[2];
    v42 = v116;
    if (v108[3] >> 1 <= v83)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v108[3] >= 2uLL, v83 + 1, 1);
      v42 = v116;
      v82 = v114;
    }

    v82[2] = v83 + 1;
    v84 = *(v97 + 80);
    v108 = v82;
    (*(v97 + 32))(v82 + ((v84 + 32) & ~v84) + *(v97 + 72) * v83, v100, v96);
    v39 = v109;
LABEL_20:
    v43 = v117;
    v40 = v106;
  }

  v85 = v113;
  *(v113 + *(v101 + 56)) = 1;
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v85, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>.Iterator);
  return v108;
}

void *_sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVySay6CoreML13MLShapedArrayVySdGG11TabularData12FilledColumnVyAM0M0VySiGGG_18CreateMLComponents16AnnotatedFeatureVyAKSiGs5NeverOTg503_s6f4ML13hi9VySdGSi18n14MLComponents16pqu22ADSiGIegnyr_AD_SitAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSiGAY_Sitcfu2_Tf3nnnpf_nTf1cn_nTm(uint64_t a1)
{
  v93 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnnotatedFeature<MLShapedArray<Double>, Int>);
  v94 = *(v93 - 8);
  v1 = *(v94 + 64);
  v2 = alloca(v1);
  v3 = alloca(v1);
  v103 = &v85;
  v4 = alloca(v1);
  v5 = alloca(v1);
  v88 = &v85;
  v110 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MLShapedArray<Double>);
  v112 = *(v110 - 8);
  v6 = *(v112 + 64);
  v7 = alloca(v6);
  v8 = alloca(v6);
  v105 = &v85;
  v9 = alloca(v6);
  v10 = alloca(v6);
  v95 = &v85;
  v11 = alloca(v6);
  v12 = alloca(v6);
  v101 = &v85;
  v96 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLShapedArray<Double>, Int));
  v13 = *(*(v96 - 8) + 64);
  v14 = alloca(v13);
  v15 = alloca(v13);
  v86 = &v85;
  v16 = alloca(v13);
  v17 = alloca(v13);
  v89 = &v85;
  v18 = alloca(v13);
  v19 = alloca(v13);
  v90 = &v85;
  v100 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<Int>>);
  v111 = *(v100 - 8);
  v20 = *(v111 + 64);
  v21 = alloca(v20);
  v22 = alloca(v20);
  v106 = &v85;
  v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>);
  v24 = *(v23 - 8);
  v25 = v23;
  v107 = v23;
  v26 = *(v24 + 64);
  v27 = alloca(v26);
  v28 = alloca(v26);
  v98 = &v85;
  v97 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>.Iterator);
  v29 = *(*(v97 - 8) + 64);
  v30 = alloca(v29);
  v31 = alloca(v29);
  v109 = a1;
  v32 = *(*a1 + 16);
  v33 = a1 + *(v25 + 52);
  v99 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<Int>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<Int>>, &protocol conformance descriptor for FilledColumn<A>);
  v34 = v100;
  v35 = dispatch thunk of Sequence.underestimatedCount.getter(v100, v99);
  v102 = v35;
  if (v35 < v32)
  {
    v32 = v35;
  }

  v108 = _swiftEmptyArrayStorage;
  v36 = 0;
  if (v32 > 0)
  {
    v36 = v32;
  }

  specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(0, v36, 0);
  v104 = v108;
  v37 = v98;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v109, v98, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>);
  v109 = *v37;
  v85 = v109;
  v86 = 0;
  (*(v111 + 32))(v106, v37 + *(v107 + 13), v34);
  v38 = *(v97 + 52);
  v107 = &v85;
  v92 = &v85 + v38;
  dispatch thunk of Sequence.makeIterator()(v34, v99);
  if (v102 < 0)
  {
    BUG();
  }

  if (v32)
  {
    v39 = v109;
    v102 = *(v109 + 16);
    v40 = 0;
    v41 = v112;
    v87 = v32;
    while (1)
    {
      if (v102 == v40)
      {
        goto LABEL_29;
      }

      v42 = v105;
      if (v40 >= *(v39 + 16))
      {
        BUG();
      }

      v43 = (v40 + 1);
      v44 = v39 + ((*(v41 + 80) + 32) & ~*(v41 + 80)) + *(v41 + 72) * v40;
      v106 = v43;
      v107[1] = v43;
      v98 = *(v41 + 16);
      (v98)(v42, v44, v110);
      v45 = *(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<Int>>>) + 36);
      v46 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<Int>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<Int>>, &protocol conformance descriptor for FilledColumn<A>);
      v47 = v92;
      v48 = v100;
      v111 = v46;
      dispatch thunk of Collection.endIndex.getter(v100, v46);
      if (*&v47[v45] == v91[0])
      {
        break;
      }

      v49 = &v47[v45];
      v50 = dispatch thunk of Collection.subscript.read(v91, v49, v48, v111);
      v99 = *v51;
      v50(v91, 0);
      dispatch thunk of Collection.formIndex(after:)(v49, v48, v111);
      v52 = *(v96 + 48);
      v53 = v86;
      v54 = v110;
      (*(v112 + 32))(v86, v105, v110);
      v55 = v99;
      *(v53 + v52) = v99;
      v56 = v95;
      (v98)(v95, v53, v54);
      v91[0] = v55;
      AnnotatedFeature.init(feature:annotation:)(v56, v91, v54, &type metadata for Int);
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v53, &demangling cache variable for type metadata for (MLShapedArray<Double>, Int));
      v57 = v104;
      v108 = v104;
      v58 = v104[2];
      v41 = v112;
      if (v104[3] >> 1 <= v58)
      {
        specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v104[3] >= 2uLL, v58 + 1, 1);
        v41 = v112;
        v57 = v108;
      }

      v57[2] = v58 + 1;
      v59 = *(v94 + 80);
      v104 = v57;
      (*(v94 + 32))(v57 + ((v59 + 32) & ~v59) + *(v94 + 72) * v58, v103, v93);
      v40 = v106;
      v32 = v87;
      v39 = v109;
      if (v87 == v106)
      {
        goto LABEL_16;
      }
    }

    (*(v112 + 8))(v105, v110);
LABEL_29:
    BUG();
  }

  v41 = v112;
  v39 = v109;
LABEL_16:
  v60 = v110;
  while (1)
  {
    v61 = v101;
    if (v32 == *(v39 + 16))
    {
      break;
    }

    if (v32 >= *(v39 + 16))
    {
      BUG();
    }

    v62 = (v32 + 1);
    v63 = v39 + ((*(v41 + 80) + 32) & ~*(v41 + 80)) + *(v41 + 72) * v32;
    v105 = v62;
    v107[1] = v62;
    v103 = *(v41 + 16);
    (v103)(v61, v63, v60);
    v64 = *(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for IndexingIterator<FilledColumn<Column<Int>>>) + 36);
    v65 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FilledColumn<Column<Int>> and conformance FilledColumn<A>, &demangling cache variable for type metadata for FilledColumn<Column<Int>>, &protocol conformance descriptor for FilledColumn<A>);
    v66 = v92;
    v67 = v100;
    v111 = v65;
    dispatch thunk of Collection.endIndex.getter(v100, v65);
    if (*&v66[v64] == v91[0])
    {
      (*(v112 + 8))(v101, v110);
      break;
    }

    v68 = &v66[v64];
    v69 = dispatch thunk of Collection.subscript.read(v91, v68, v67, v111);
    v106 = *v70;
    v69(v91, 0);
    dispatch thunk of Collection.formIndex(after:)(v68, v67, v111);
    v71 = v96;
    v72 = *(v96 + 48);
    v73 = v89;
    v74 = v110;
    (*(v112 + 32))(v89, v101, v110);
    *(v73 + v72) = v106;
    v75 = v73;
    v76 = v90;
    outlined init with take of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(v75, v90, &demangling cache variable for type metadata for (MLShapedArray<Double>, Int));
    v77 = *(v76 + *(v71 + 48));
    v78 = v95;
    (v103)(v95, v76, v74);
    v91[0] = v77;
    v79 = v88;
    AnnotatedFeature.init(feature:annotation:)(v78, v91, v74, &type metadata for Int);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v76, &demangling cache variable for type metadata for (MLShapedArray<Double>, Int));
    v80 = v104;
    v108 = v104;
    v81 = v104[2];
    v41 = v112;
    if (v104[3] >> 1 <= v81)
    {
      specialized ContiguousArray._createNewBuffer(bufferIsUnique:minimumCapacity:growForAppend:)(v104[3] >= 2uLL, v81 + 1, 1);
      v41 = v112;
      v80 = v108;
    }

    v80[2] = v81 + 1;
    v82 = *(v94 + 80);
    v104 = v80;
    (*(v94 + 32))(v80 + ((v82 + 32) & ~v82) + *(v94 + 72) * v81, v79, v93);
    v32 = v105;
    v60 = v110;
    v39 = v109;
  }

  v83 = v107;
  *(v107 + *(v97 + 56)) = 1;
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v83, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>.Iterator);
  return v104;
}

uint64_t MLSupportVectorClassifier.Classifier.init(labelsColumn:targetColumnName:featureColumnNames:parameters:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
  v103 = v6;
  v112 = a5;
  v107 = a4;
  v109 = a2;
  v113 = a1;
  v8 = v5;
  v101 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>);
  v100 = *(v101 - 8);
  v9 = *(v100 + 64);
  v10 = alloca(v9);
  v11 = alloca(v9);
  v91 = &v78;
  v93 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  v92 = *(v93 - 8);
  v12 = *(v92 + 64);
  v13 = alloca(v12);
  v14 = alloca(v12);
  v97 = &v78;
  v15 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<Int>>) - 8) + 64);
  v16 = alloca(v15);
  v17 = alloca(v15);
  v98 = &v78;
  v108 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>.Configuration);
  v106 = *(v108 - 8);
  v18 = *(v106 + 64);
  v19 = alloca(v18);
  v20 = alloca(v18);
  v99 = &v78;
  v21 = alloca(v18);
  v22 = alloca(v18);
  v111 = &v78;
  v94 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>);
  v95 = *(v94 - 8);
  v23 = *(v95 + 64);
  v24 = alloca(v23);
  v25 = alloca(v23);
  v84 = &v78;
  v104 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  v26 = *(*(v104 - 8) + 64);
  v27 = alloca(v26);
  v28 = alloca(v26);
  v102 = &v78;
  v29 = alloca(v26);
  v30 = alloca(v26);
  v96 = &v78;
  v85 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  v86 = *(v85 - 8);
  v31 = *(v86 + 64);
  v32 = alloca(v31);
  v33 = alloca(v31);
  v34 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>) - 8) + 64);
  v35 = alloca(v34);
  v36 = alloca(v34);
  v87 = &v78;
  v110 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>.Configuration);
  v105 = *(v110 - 8);
  v37 = *(v105 + 64);
  v38 = alloca(v37);
  v39 = alloca(v37);
  v88 = &v78;
  v40 = alloca(v37);
  v41 = alloca(v37);
  *v8 = v109;
  v109 = a3;
  v8[1] = a3;
  v8[2] = v107;
  v89 = v8;
  v83 = v8 + 3;
  outlined init with copy of MLSupportVectorClassifier.ModelParameters(v112, (v8 + 3));
  v42 = AnyColumn.wrappedElementType.getter();
  if (swift_dynamicCastMetatype(v42, &type metadata for String))
  {
    outlined init with copy of MLSupportVectorClassifier.ModelParameters(v112, v79);
    v111 = lazy protocol witness table accessor for type Double and conformance Double();
    LinearSupportVectorClassifier.Configuration.init()(&type metadata for Double, &type metadata for String, &protocol witness table for Double, v111, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String);
    v90 = &v78;
    v43 = v110;
    LinearSupportVectorClassifier.Configuration.maximumIterations.setter(v79[0], v110);
    LinearSupportVectorClassifier.Configuration.penalty.setter(v43, v80);
    LinearSupportVectorClassifier.Configuration.convergenceThreshold.setter(v43, v81);
    LinearSupportVectorClassifier.Configuration.scaleFeatures.setter(v82, v43);
    outlined destroy of MLSupportVectorClassifier.ModelParameters(v79);
    v44 = AnyColumn.assumingType<A>(_:)(&type metadata for String, &type metadata for String);
    v79[0] = 0;
    v79[1] = 0xE000000000000000;
    v45 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>, &protocol conformance descriptor for Column<A>);
    v46 = v85;
    OptionalColumnProtocol.filled(with:)(v79, v85, v45);
    (*(v86 + 8))(&v78, v46, v44);
    v47 = _sShyShyxGqd__nc7ElementQyd__RszSTRd__lufCSS_11TabularData12FilledColumnVyAD0E0VySSGGTt0g5();
    v48 = v88;
    v49 = v90;
    (*(v105 + 16))(v88, v90, v110);
    v50 = v84;
    v51 = v103;
    LinearSupportVectorClassifier.init(labels:configuration:)(v47, v48, &type metadata for Double, &type metadata for String, &protocol witness table for Double, v111, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String, &protocol witness table for String);
    if (v51)
    {
      outlined destroy of MLSupportVectorClassifier.ModelParameters(v112);
      v52 = type metadata accessor for AnyColumn(0);
      (*(*(v52 - 8) + 8))(v113, v52);
      v53 = v49;
      v54 = v110;
      v55 = v105;
LABEL_7:
      (*(v55 + 8))(v53, v54);
LABEL_10:
      v107;
      v109;
      return outlined destroy of MLSupportVectorClassifier.ModelParameters(v83);
    }

    outlined destroy of MLSupportVectorClassifier.ModelParameters(v112);
    v67 = type metadata accessor for AnyColumn(0);
    (*(*(v67 - 8) + 8))(v113, v67);
    (*(v105 + 8))(v49, v110);
    v68 = v96;
    (*(v95 + 32))(v96, v50, v94);
    v69 = v68;
    v70 = v104;
    v71 = 0;
  }

  else
  {
    v56 = v112;
    if (!swift_dynamicCastMetatype(v42, &type metadata for Int))
    {
      v72 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v72, 0, 0);
      *v73 = 0xD000000000000025;
      *(v73 + 8) = "start time column" + 0x8000000000000000;
      *(v73 + 16) = 0;
      *(v73 + 32) = 0;
      *(v73 + 48) = 1;
      swift_willThrow(&type metadata for MLCreateError, v72);
      outlined destroy of MLSupportVectorClassifier.ModelParameters(v56);
      v74 = type metadata accessor for AnyColumn(0);
      (*(*(v74 - 8) + 8))(v113, v74);
      goto LABEL_10;
    }

    outlined init with copy of MLSupportVectorClassifier.ModelParameters(v56, v79);
    v110 = lazy protocol witness table accessor for type Double and conformance Double();
    LinearSupportVectorClassifier.Configuration.init()(&type metadata for Double, &type metadata for Int, &protocol witness table for Double, v110, &protocol witness table for Int, &protocol witness table for Int, &protocol witness table for Int, &protocol witness table for Int);
    v57 = v108;
    LinearSupportVectorClassifier.Configuration.maximumIterations.setter(v79[0], v108);
    LinearSupportVectorClassifier.Configuration.penalty.setter(v57, v80);
    LinearSupportVectorClassifier.Configuration.convergenceThreshold.setter(v57, v81);
    LinearSupportVectorClassifier.Configuration.scaleFeatures.setter(v82, v57);
    outlined destroy of MLSupportVectorClassifier.ModelParameters(v79);
    v58 = v97;
    v59 = AnyColumn.assumingType<A>(_:)(&type metadata for Int, &type metadata for Int);
    v79[0] = 0;
    v60 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Int> and conformance Column<A>, &demangling cache variable for type metadata for Column<Int>, &protocol conformance descriptor for Column<A>);
    v61 = v93;
    OptionalColumnProtocol.filled(with:)(v79, v93, v60);
    (*(v92 + 8))(v58, v61, v59);
    v62 = _sShyShyxGqd__nc7ElementQyd__RszSTRd__lufCSi_11TabularData12FilledColumnVyAD0E0VySiGGTt0g5();
    v63 = v99;
    (*(v106 + 16))(v99, v111, v108);
    v64 = v91;
    v65 = v103;
    LinearSupportVectorClassifier.init(labels:configuration:)(v62, v63, &type metadata for Double, &type metadata for Int, &protocol witness table for Double, v110, &protocol witness table for Int, &protocol witness table for Int, &protocol witness table for Int, &protocol witness table for Int);
    if (v65)
    {
      outlined destroy of MLSupportVectorClassifier.ModelParameters(v112);
      v66 = type metadata accessor for AnyColumn(0);
      (*(*(v66 - 8) + 8))(v113, v66);
      v53 = v111;
      v54 = v108;
      v55 = v106;
      goto LABEL_7;
    }

    outlined destroy of MLSupportVectorClassifier.ModelParameters(v112);
    v76 = type metadata accessor for AnyColumn(0);
    (*(*(v76 - 8) + 8))(v113, v76);
    (*(v106 + 8))(v111, v108);
    v68 = v102;
    (*(v100 + 32))(v102, v64, v101);
    v71 = 1;
    v69 = v68;
    v70 = v104;
  }

  swift_storeEnumTagMultiPayload(v69, v70, v71);
  v77 = type metadata accessor for MLSupportVectorClassifier.Classifier(0);
  return outlined init with take of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(v68, v89 + *(v77 + 28), &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
}

uint64_t MLSupportVectorClassifier.Classifier.fitted(to:validateOn:eventHandler:)(uint64_t a1, void *a2, uint64_t a3, uint64_t a4)
{
  v292 = v5;
  v263 = a4;
  v264 = a3;
  v290 = a2;
  v265 = v4;
  v252 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>);
  v251 = *(v252 - 8);
  v8 = *(v251 + 64);
  v9 = alloca(v8);
  v10 = alloca(v8);
  v241 = &v234;
  v11 = alloca(v8);
  v12 = alloca(v8);
  v255 = &v234;
  v247 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>);
  v13 = *(*(v247 - 8) + 64);
  v14 = alloca(v13);
  v15 = alloca(v13);
  v246 = &v234;
  v242 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Int>);
  v237 = *(v242 - 8);
  v16 = *(v237 + 64);
  v17 = alloca(v16);
  v18 = alloca(v16);
  v243 = &v234;
  v278 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<Int>>);
  v272 = *(v278 - 8);
  v19 = *(v272 + 64);
  v20 = alloca(v19);
  v21 = alloca(v19);
  v259 = &v234;
  v22 = alloca(v19);
  v23 = alloca(v19);
  v276 = &v234;
  v282 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>);
  v274 = *(v282 - 1);
  v24 = *(v274 + 64);
  v25 = alloca(v24);
  v26 = alloca(v24);
  v283 = &v234;
  v261 = type metadata accessor for AnyColumn(0);
  v260 = *(v261 - 8);
  v27 = *(v260 + 64);
  v28 = alloca(v27);
  v29 = alloca(v27);
  v262 = &v234;
  v254 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>);
  v253 = *(v254 - 8);
  v30 = *(v253 + 64);
  v31 = alloca(v30);
  v32 = alloca(v30);
  v250 = &v234;
  v33 = alloca(v30);
  v34 = alloca(v30);
  v256 = &v234;
  v286 = type metadata accessor for DataFrame(0);
  v281 = *(v286 - 8);
  v35 = *(v281 + 64);
  v36 = alloca(v35);
  v37 = alloca(v35);
  v271 = &v234;
  v38 = alloca(v35);
  v39 = alloca(v35);
  v257 = &v234;
  v249 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>);
  v40 = *(*(v249 - 8) + 64);
  v41 = alloca(v40);
  v42 = alloca(v40);
  v248 = &v234;
  v287 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DenseMatrix<Double>);
  v288 = *(v287 - 8);
  v43 = *(v288 + 64);
  v44 = alloca(v43);
  v45 = alloca(v43);
  v258 = &v234;
  v46 = alloca(v43);
  v47 = alloca(v43);
  v269 = &v234;
  v48 = alloca(v43);
  v49 = alloca(v43);
  v266 = &v234;
  v50 = alloca(v43);
  v51 = alloca(v43);
  v270 = &v234;
  v244 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  v238 = *(v244 - 8);
  v52 = *(v238 + 64);
  v53 = alloca(v52);
  v54 = alloca(v52);
  v245 = &v234;
  v279 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>);
  v273 = *(v279 - 8);
  v55 = *(v273 + 64);
  v56 = alloca(v55);
  v57 = alloca(v55);
  v267 = &v234;
  v58 = alloca(v55);
  v59 = alloca(v55);
  v277 = &v234;
  v284 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>);
  v275 = *(v284 - 1);
  v60 = *(v275 + 64);
  v61 = alloca(v60);
  v62 = alloca(v60);
  v285 = &v234;
  v236 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  v63 = *(*(v236 - 8) + 64);
  v64 = alloca(v63);
  v65 = alloca(v63);
  v235 = &v234;
  v66 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataFrame?) - 8) + 64);
  v67 = alloca(v66);
  v68 = alloca(v66);
  v239 = &v234;
  v69 = alloca(v66);
  v70 = alloca(v66);
  v240 = &v234;
  v71 = alloca(v66);
  v72 = alloca(v66);
  v293._object = &v234;
  v73 = *v6;
  v291 = v6;
  v74 = v6[1];
  v75._countAndFlagsBits = v73;
  v75._object = v74;
  *&v294 = a1;
  if (DataFrame.indexOfColumn(_:)(v75).is_nil)
  {
    *&v289 = 0;
    *(&v289 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(53);
    v76._object = "er.Classifier.swift" + 0x8000000000000000;
    v76._countAndFlagsBits = 0xD00000000000001ELL;
    String.append(_:)(v76);
    v74;
    v76._countAndFlagsBits = v73;
    v76._object = v74;
    String.append(_:)(v76);
    v74;
    v77._object = "Training data must contain a '" + 0x8000000000000000;
    v77._countAndFlagsBits = 0xD000000000000015;
LABEL_3:
    String.append(_:)(v77);
    v294 = v289;
    v78 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v78, 0, 0);
    *v79 = v294;
    *(v79 + 16) = 0;
    *(v79 + 32) = 0;
    *(v79 + 48) = 0;
    return swift_willThrow(&type metadata for MLCreateError, v78);
  }

  v293._countAndFlagsBits = v73;
  v280 = v74;
  v81 = v290;
  v82 = v286;
  EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v290, 1, v286);
  v84 = v281;
  if (EnumTagSinglePayload != 1)
  {
    v85 = v81;
    object = v293._object;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v85, v293._object, &demangling cache variable for type metadata for DataFrame?);
    if (__swift_getEnumTagSinglePayload(object, 1, v82) == 1)
    {
      BUG();
    }

    v87._countAndFlagsBits = v293._countAndFlagsBits;
    v87._object = v280;
    is_nil = DataFrame.indexOfColumn(_:)(v87).is_nil;
    (*(v84 + 8))(object, v82);
    if (is_nil)
    {
      *&v289 = 0;
      *(&v289 + 1) = 0xE000000000000000;
      _StringGuts.grow(_:)(55);
      v89._object = "trings but it contains " + 0x8000000000000000;
      v89._countAndFlagsBits = 0xD000000000000020;
      String.append(_:)(v89);
      v90 = v280;
      v280;
      v89._countAndFlagsBits = v293._countAndFlagsBits;
      v89._object = v90;
      String.append(_:)(v89);
      v90;
      v77._object = "Training data must contain a '" + 0x8000000000000000;
      v77._countAndFlagsBits = 0xD000000000000015;
      goto LABEL_3;
    }
  }

  v91 = v291;
  v92 = v291[2];
  v93 = alloca(24);
  v94 = alloca(32);
  v236 = v294;
  v92;
  v95 = v292;
  ML16ColumnDescriptorVsAE_pTg5 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_8CreateML16ColumnDescriptorVsAE_pTg5(partial apply for closure #1 in FeatureVectorizer.fitted(to:), &v234, v92);
  if (v95)
  {
    return v92;
  }

  v292 = ML16ColumnDescriptorVsAE_pTg5;
  v293._object = 0;
  v268 = "raining samples." + 0x8000000000000000;
  v92;
  v97 = type metadata accessor for MLSupportVectorClassifier.Classifier(0);
  v98 = v235;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v91 + *(v97 + 28), v235, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  if (swift_getEnumCaseMultiPayload(v98, v236) != 1)
  {
    (*(v275 + 32))(v285, v98, v284);
    countAndFlagsBits = v293._countAndFlagsBits;
    v111._countAndFlagsBits = v293._countAndFlagsBits;
    v112 = v280;
    v111._object = v280;
    if ((_s11TabularData0B5FrameV14containsColumnySbSS_xmtlFSS_Tt0g5(v111) & 1) == 0)
    {
      v292;
      *&v289 = 0;
      *(&v289 + 1) = 0xE000000000000000;
      _StringGuts.grow(_:)(59);
      v131._countAndFlagsBits = 0x6320736C6562614CLL;
      v131._object = 0xEF27206E6D756C6FLL;
      String.append(_:)(v131);
      v112;
      v131._countAndFlagsBits = countAndFlagsBits;
      v131._object = v112;
      String.append(_:)(v131);
      v112;
      v131._object = "Validation labels column '" + 0x8000000000000000;
      v131._countAndFlagsBits = 0xD000000000000027;
      String.append(_:)(v131);
      v132 = v262;
      DataFrame.subscript.getter(countAndFlagsBits, v112);
      v133 = AnyColumn.wrappedElementType.getter();
      (*(v260 + 8))(v132, v261);
      v134 = _typeName(_:qualified:)(v133, 0);
      v136 = v135;
      v131._countAndFlagsBits = v134;
      v131._object = v135;
      String.append(_:)(v131);
      v136;
      v131._countAndFlagsBits = 46;
      v131._object = 0xE100000000000000;
      String.append(_:)(v131);
      v294 = v289;
      v131._object = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v131._object, 0, 0);
      *v137 = v294;
      *(v137 + 16) = 0;
      *(v137 + 32) = 0;
      *(v137 + 48) = 1;
      swift_willThrow(&type metadata for MLCreateError, v131._object);
      goto LABEL_22;
    }

    v113 = v245;
    v114 = v112;
    v115 = v294;
    DataFrame.subscript.getter(countAndFlagsBits, v114, &type metadata for String);
    *&v289 = 0;
    *(&v289 + 1) = 0xE000000000000000;
    v116 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>, &protocol conformance descriptor for Column<A>);
    v117 = v244;
    v291 = v116;
    OptionalColumnProtocol.filled(with:)(&v289, v244, v116);
    v282 = *(v238 + 8);
    (v282)(v113, v117);
    v118 = v270;
    v119 = v292;
    v120 = v293._object;
    specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(v115, 0, v292, 0xD000000000000013, v268);
    if (v120)
    {
      v119;
LABEL_18:
      (*(v273 + 8))(v277, v279);
LABEL_22:
      v128 = v285;
      v129 = v284;
      v130 = v275;
      return (*(v130 + 8))(v128, v129);
    }

    v153 = static MLSupportVectorClassifier.Model.buildFeatures(from:)(v118);
    v154 = v248;
    *v248 = v153;
    v155 = v154 + *(v249 + 52);
    v283 = *(v273 + 16);
    (v283)(v155, v277, v279);
    MLComponents16AnnotatedFeatureVyAKSSGs5NeverOTg503_s6f4ML13hi9VySdGSS18n14MLComponents16pqu22ADSSGIegngr_AD_SStAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSSGAY_SStcfu0_Tf3nnnpf_nTf1cn_nTm = _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVySay6CoreML13MLShapedArrayVySdGG11TabularData12FilledColumnVyAM0M0VySSGGG_18CreateMLComponents16AnnotatedFeatureVyAKSSGs5NeverOTg503_s6f4ML13hi9VySdGSS18n14MLComponents16pqu22ADSSGIegngr_AD_SStAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSSGAY_SStcfu0_Tf3nnnpf_nTf1cn_nTm(v154);
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v154, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>);
    v157 = v240;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v290, v240, &demangling cache variable for type metadata for DataFrame?);
    v158 = __swift_getEnumTagSinglePayload(v157, 1, v286);
    *&v294 = MLComponents16AnnotatedFeatureVyAKSSGs5NeverOTg503_s6f4ML13hi9VySdGSS18n14MLComponents16pqu22ADSSGIegngr_AD_SStAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSSGAY_SStcfu0_Tf3nnnpf_nTf1cn_nTm;
    if (v158 == 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v157, &demangling cache variable for type metadata for DataFrame?);
      *&v289 = MLComponents16AnnotatedFeatureVyAKSSGs5NeverOTg503_s6f4ML13hi9VySdGSS18n14MLComponents16pqu22ADSSGIegngr_AD_SStAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSSGAY_SStcfu0_Tf3nnnpf_nTf1cn_nTm;
      v159 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, String>]);
      v160 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Double>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, String>], &protocol conformance descriptor for [A]);
      v161 = v285;
      v162 = v284;
      LinearSupportVectorClassifier.fitted<A>(to:eventHandler:)(&v289, v264, v263, v284, v159, v160);
      (*(v288 + 8))(v270, v287);
      (*(v273 + 8))(v277, v279);
      (*(v275 + 8))(v161, v162);
      v294;
      v191 = type metadata accessor for MLSupportVectorClassifier.Model(0);
      v192 = v265;
      v193 = v265 + *(v191 + 24);
      v194 = v193;
      v195 = v250;
    }

    else
    {
      v169 = v257;
      (*(v281 + 32))(v257, v157, v286);
      v170._countAndFlagsBits = v293._countAndFlagsBits;
      v170._object = v280;
      v171 = v280;
      if ((_s11TabularData0B5FrameV14containsColumnySbSS_xmtlFSS_Tt0g5(v170) & 1) == 0)
      {
        v294;
        v292;
        *&v289 = 0;
        *(&v289 + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(70);
        v180._object = "ntegers but it contains " + 0x8000000000000000;
        v180._countAndFlagsBits = 0xD00000000000001ALL;
        String.append(_:)(v180);
        v171;
        v180._countAndFlagsBits = v293._countAndFlagsBits;
        v180._object = v171;
        String.append(_:)(v180);
        v171;
        v180._object = "Validation labels column '" + 0x8000000000000000;
        v180._countAndFlagsBits = 0xD000000000000027;
        String.append(_:)(v180);
        v181 = v169;
        v182 = v262;
        DataFrame.subscript.getter(v293._countAndFlagsBits, v171);
        v183 = AnyColumn.wrappedElementType.getter();
        (*(v260 + 8))(v182, v261);
        v184 = _typeName(_:qualified:)(v183, 0);
        v186 = v185;
        v180._countAndFlagsBits = v184;
        v180._object = v185;
        String.append(_:)(v180);
        v186;
        v180._countAndFlagsBits = 46;
        v180._object = 0xE100000000000000;
        String.append(_:)(v180);
        v294 = v289;
        v180._object = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v180._object, 0, 0);
        *v187 = v294;
        *(v187 + 16) = 0;
        *(v187 + 32) = 0;
        *(v187 + 48) = 1;
        swift_willThrow(&type metadata for MLCreateError, v180._object);
        (*(v281 + 8))(v181, v286);
        (*(v288 + 8))(v270, v287);
        goto LABEL_18;
      }

      specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(v169, 0, v292, 0xD000000000000013, v268);
      v290 = static MLSupportVectorClassifier.Model.buildFeatures(from:)(v266);
      v212 = v245;
      v293._object = 0;
      DataFrame.subscript.getter(v293._countAndFlagsBits, v280, &type metadata for String);
      *&v289 = 0;
      *(&v289 + 1) = 0xE000000000000000;
      v213 = v244;
      OptionalColumnProtocol.filled(with:)(&v289, v244, v291);
      (v282)(v212, v213);
      v214 = v248;
      *v248 = v290;
      (v283)(*(v249 + 52) + v214, v267, v279);
      v215 = v293._object;
      v216 = _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVySay6CoreML13MLShapedArrayVySdGG11TabularData12FilledColumnVyAM0M0VySSGGG_18CreateMLComponents16AnnotatedFeatureVyAKSSGs5NeverOTg503_s6f4ML13hi9VySdGSS18n14MLComponents16pqu22ADSSGIegngr_AD_SStAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSSGAY_SStcfu0_Tf3nnnpf_nTf1cn_nTm(v214);
      v291 = v215;
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v214, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<String>>>);
      *&v289 = v294;
      v290 = v216;
      v234 = v216;
      v217 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, String>]);
      v218 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Double>, String>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, String>], &protocol conformance descriptor for [A]);
      v219 = v291;
      LinearSupportVectorClassifier.fitted<A, B>(to:validateOn:eventHandler:)(&v289, &v234, v264, v263, v284, v217, v217, v218, v218);
      if (v219)
      {
        v292;
        v291 = *(v273 + 8);
        v220 = v279;
        (v291)(v267, v279);
        v221 = *(v288 + 8);
        v222 = v287;
        v221(v266, v287);
        (*(v281 + 8))(v257, v286);
        v221(v270, v222);
        (v291)(v277, v220);
        (*(v275 + 8))(v285, v284);
        v294;
        v152 = v290;
        return v152;
      }

      v291 = *(v273 + 8);
      v230 = v279;
      (v291)(v267, v279);
      v231 = *(v288 + 8);
      v232 = v287;
      v231(v266, v287);
      (*(v281 + 8))(v257, v286);
      v231(v270, v232);
      (v291)(v277, v230);
      (*(v275 + 8))(v285, v284);
      v294;
      v290;
      v233 = type metadata accessor for MLSupportVectorClassifier.Model(0);
      v192 = v265;
      v193 = v265 + *(v233 + 24);
      v194 = v193;
      v195 = v256;
    }

    (*(v253 + 32))(v194, v195, v254);
    v196 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
    swift_storeEnumTagMultiPayload(v193, v196, 0);
LABEL_40:
    v197 = v293._countAndFlagsBits;
    goto LABEL_41;
  }

  (*(v274 + 32))(v283, v98, v282);
  v99 = v293._countAndFlagsBits;
  v100._countAndFlagsBits = v293._countAndFlagsBits;
  v101 = v280;
  v100._object = v280;
  if ((_s11TabularData0B5FrameV14containsColumnySbSS_xmtlFSi_Tt0g5(v100) & 1) == 0)
  {
    v292;
    *&v289 = 0;
    *(&v289 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(60);
    v121._countAndFlagsBits = 0x6320736C6562614CLL;
    v121._object = 0xEF27206E6D756C6FLL;
    String.append(_:)(v121);
    v101;
    v121._countAndFlagsBits = v99;
    v121._object = v101;
    String.append(_:)(v121);
    v101;
    v121._object = "' column with labels." + 0x8000000000000000;
    v121._countAndFlagsBits = 0xD000000000000028;
    String.append(_:)(v121);
    v121._countAndFlagsBits = v99;
    v122 = v262;
    DataFrame.subscript.getter(v121._countAndFlagsBits, v101);
    v123 = AnyColumn.wrappedElementType.getter();
    (*(v260 + 8))(v122, v261);
    v124 = _typeName(_:qualified:)(v123, 0);
    v126 = v125;
    v121._countAndFlagsBits = v124;
    v121._object = v125;
    String.append(_:)(v121);
    v126;
    v121._countAndFlagsBits = 46;
    v121._object = 0xE100000000000000;
    String.append(_:)(v121);
    v294 = v289;
    v121._object = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v121._object, 0, 0);
    *v127 = v294;
    *(v127 + 16) = 0;
    *(v127 + 32) = 0;
    *(v127 + 48) = 1;
    swift_willThrow(&type metadata for MLCreateError, v121._object);
    goto LABEL_20;
  }

  v102 = v99;
  v103 = v243;
  DataFrame.subscript.getter(v102, v101, &type metadata for Int);
  *&v289 = 0;
  v104 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<Int> and conformance Column<A>, &demangling cache variable for type metadata for Column<Int>, &protocol conformance descriptor for Column<A>);
  v105 = v242;
  v291 = v104;
  OptionalColumnProtocol.filled(with:)(&v289, v242, v104);
  v106 = *(v237 + 8);
  (v106)(v103, v105);
  v107 = v269;
  v108 = v292;
  v109 = v293._object;
  specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(v294, 0, v292, 0xD000000000000013, v268);
  if (v109)
  {
    v108;
LABEL_14:
    (*(v272 + 8))(v276, v278);
LABEL_20:
    v128 = v283;
    v129 = v282;
    v130 = v274;
    return (*(v130 + 8))(v128, v129);
  }

  v284 = v106;
  v138 = static MLSupportVectorClassifier.Model.buildFeatures(from:)(v107);
  v139 = v246;
  *v246 = v138;
  v140 = v139 + *(v247 + 52);
  v285 = *(v272 + 16);
  (v285)(v140, v276, v278);
  MLComponents16AnnotatedFeatureVyAKSiGs5NeverOTg503_s6f4ML13hi9VySdGSi18n14MLComponents16pqu22ADSiGIegnyr_AD_SitAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSiGAY_Sitcfu2_Tf3nnnpf_nTf1cn_nTm = _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVySay6CoreML13MLShapedArrayVySdGG11TabularData12FilledColumnVyAM0M0VySiGGG_18CreateMLComponents16AnnotatedFeatureVyAKSiGs5NeverOTg503_s6f4ML13hi9VySdGSi18n14MLComponents16pqu22ADSiGIegnyr_AD_SitAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSiGAY_Sitcfu2_Tf3nnnpf_nTf1cn_nTm(v139);
  v293._object = 0;
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v139, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>);
  v142 = v239;
  outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v290, v239, &demangling cache variable for type metadata for DataFrame?);
  v143 = v286;
  v144 = __swift_getEnumTagSinglePayload(v142, 1, v286);
  *&v294 = MLComponents16AnnotatedFeatureVyAKSiGs5NeverOTg503_s6f4ML13hi9VySdGSi18n14MLComponents16pqu22ADSiGIegnyr_AD_SitAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSiGAY_Sitcfu2_Tf3nnnpf_nTf1cn_nTm;
  if (v144 == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v142, &demangling cache variable for type metadata for DataFrame?);
    *&v289 = MLComponents16AnnotatedFeatureVyAKSiGs5NeverOTg503_s6f4ML13hi9VySdGSi18n14MLComponents16pqu22ADSiGIegnyr_AD_SitAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSiGAY_Sitcfu2_Tf3nnnpf_nTf1cn_nTm;
    v145 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, Int>]);
    v146 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Double>, Int>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, Int>], &protocol conformance descriptor for [A]);
    v147 = v241;
    v148 = v145;
    v149 = v283;
    v150 = v293._object;
    v151 = v282;
    LinearSupportVectorClassifier.fitted<A>(to:eventHandler:)(&v289, v264, v263, v282, v148, v146);
    v293._object = v150;
    if (v150)
    {
      v292;
      (*(v288 + 8))(v269, v287);
      (*(v272 + 8))(v276, v278);
      (*(v274 + 8))(v149, v151);
      v152 = v294;
      return v152;
    }

    (*(v288 + 8))(v269, v287);
    (*(v272 + 8))(v276, v278);
    (*(v274 + 8))(v149, v151);
    v294;
    v188 = type metadata accessor for MLSupportVectorClassifier.Model(0);
    v192 = v265;
    v189 = v265 + *(v188 + 24);
    (*(v251 + 32))(v189, v147, v252);
    v190 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
    swift_storeEnumTagMultiPayload(v189, v190, 1);
    goto LABEL_40;
  }

  (*(v281 + 32))(v271, v142, v143);
  v163._countAndFlagsBits = v293._countAndFlagsBits;
  v164 = v280;
  v163._object = v280;
  if ((_s11TabularData0B5FrameV14containsColumnySbSS_xmtlFSi_Tt0g5(v163) & 1) == 0)
  {
    v294;
    v292;
    *&v289 = 0;
    *(&v289 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(71);
    v172._object = "ntegers but it contains " + 0x8000000000000000;
    v172._countAndFlagsBits = 0xD00000000000001ALL;
    String.append(_:)(v172);
    v164;
    v172._countAndFlagsBits = v293._countAndFlagsBits;
    v172._object = v164;
    String.append(_:)(v172);
    v164;
    v172._object = "' column with labels." + 0x8000000000000000;
    v172._countAndFlagsBits = 0xD000000000000028;
    String.append(_:)(v172);
    v173 = v262;
    v172._object = v164;
    v174 = v271;
    DataFrame.subscript.getter(v293._countAndFlagsBits, v172._object);
    v175 = AnyColumn.wrappedElementType.getter();
    (*(v260 + 8))(v173, v261);
    v176 = _typeName(_:qualified:)(v175, 0);
    v178 = v177;
    v172._countAndFlagsBits = v176;
    v172._object = v177;
    String.append(_:)(v172);
    v178;
    v172._countAndFlagsBits = 46;
    v172._object = 0xE100000000000000;
    String.append(_:)(v172);
    v294 = v289;
    v172._object = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v172._object, 0, 0);
    *v179 = v294;
    *(v179 + 16) = 0;
    *(v179 + 32) = 0;
    *(v179 + 48) = 1;
    swift_willThrow(&type metadata for MLCreateError, v172._object);
    v168 = v174;
    goto LABEL_36;
  }

  v165 = v258;
  v166 = v292;
  v167 = v293._object;
  specialized FeatureVectorizer.Transformer.vectorized(_:includingBias:)(v271, 0, v292, 0xD000000000000013, v268);
  if (v167)
  {
    v294;
    v166;
    v168 = v271;
LABEL_36:
    (*(v281 + 8))(v168, v286);
    (*(v288 + 8))(v269, v287);
    goto LABEL_14;
  }

  v290 = static MLSupportVectorClassifier.Model.buildFeatures(from:)(v165);
  v199 = v243;
  v293._object = 0;
  DataFrame.subscript.getter(v293._countAndFlagsBits, v280, &type metadata for Int);
  *&v289 = 0;
  v200 = v259;
  v201 = v242;
  OptionalColumnProtocol.filled(with:)(&v289, v242, v291);
  (v284)(v199, v201);
  v202 = v246;
  *v246 = v290;
  (v285)(*(v247 + 52) + v202, v200, v278);
  v203 = v293._object;
  v204 = _sSTsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFs12Zip2SequenceVySay6CoreML13MLShapedArrayVySdGG11TabularData12FilledColumnVyAM0M0VySiGGG_18CreateMLComponents16AnnotatedFeatureVyAKSiGs5NeverOTg503_s6f4ML13hi9VySdGSi18n14MLComponents16pqu22ADSiGIegnyr_AD_SitAHs5r101OIegnrzr_TR03_s8e142ML25MLSupportVectorClassifierV0E0V6fitted2to10validateOn12eventHandlerAC5ModelV11j71Data0N5FrameV_ANSgy0A12MLComponents5EventVYbcSgtKFAP16gh4Vy04a4B013cD19uV25GSiGAY_Sitcfu2_Tf3nnnpf_nTf1cn_nTm(v202);
  v291 = v203;
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v202, &demangling cache variable for type metadata for Zip2Sequence<[MLShapedArray<Double>], FilledColumn<Column<Int>>>);
  *&v289 = v294;
  v290 = v204;
  v234 = v204;
  v205 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, Int>]);
  v206 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [AnnotatedFeature<MLShapedArray<Double>, Int>] and conformance [A], &demangling cache variable for type metadata for [AnnotatedFeature<MLShapedArray<Double>, Int>], &protocol conformance descriptor for [A]);
  v207 = v291;
  LinearSupportVectorClassifier.fitted<A, B>(to:validateOn:eventHandler:)(&v289, &v234, v264, v263, v282, v205, v205, v206, v206);
  v293._object = v207;
  if (v207)
  {
    v292;
    v208 = *(v272 + 8);
    v209 = v278;
    v208(v259, v278);
    v210 = *(v288 + 8);
    v211 = v287;
    v210(v258, v287);
    (*(v281 + 8))(v271, v286);
    v210(v269, v211);
    v208(v276, v209);
    (*(v274 + 8))(v283, v282);
    v294;
    v152 = v290;
    return v152;
  }

  v223 = *(v272 + 8);
  v224 = v278;
  v223(v259, v278);
  v225 = *(v288 + 8);
  v226 = v287;
  v225(v258, v287);
  (*(v281 + 8))(v271, v286);
  v225(v269, v226);
  v223(v276, v224);
  (*(v274 + 8))(v283, v282);
  v294;
  v290;
  v227 = type metadata accessor for MLSupportVectorClassifier.Model(0);
  v192 = v265;
  v228 = v265 + *(v227 + 24);
  (*(v251 + 32))(v228, v255, v252);
  v229 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
  swift_storeEnumTagMultiPayload(v228, v229, 1);
  v197 = v293._countAndFlagsBits;
LABEL_41:
  *v192 = v197;
  v198 = v280;
  v192[1] = v280;
  v192[2] = v292;
  v192[3] = 0xD000000000000013;
  v192[4] = v268;
  return v198;
}

uint64_t MLSupportVectorClassifier.Classifier.encode(_:to:)(uint64_t a1, uint64_t a2)
{
  v72 = v2;
  v55 = v3;
  v62 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>);
  v61 = *(v62 - 8);
  v4 = *(v61 + 64);
  v5 = alloca(v4);
  v6 = alloca(v4);
  v58 = &v50;
  v67 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>);
  v69 = *(v67 - 8);
  v7 = *(v69 + 64);
  v8 = alloca(v7);
  v9 = alloca(v7);
  v68 = &v50;
  v64 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>);
  v63 = *(v64 - 8);
  v10 = *(v63 + 64);
  v11 = alloca(v10);
  v12 = alloca(v10);
  v59 = &v50;
  v70 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>);
  v73 = *(v70 - 8);
  v13 = *(v73 + 64);
  v14 = alloca(v13);
  v15 = alloca(v13);
  v65 = &v50;
  v56 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  v16 = *(*(v56 - 8) + 64);
  v17 = alloca(v16);
  v18 = alloca(v16);
  v60 = &v50;
  v19 = alloca(v16);
  v20 = alloca(v16);
  v71 = &v50;
  v57 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>, Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>));
  v21 = *(*(v57 - 8) + 64);
  v22 = alloca(v21);
  v23 = alloca(v21);
  v74 = &v50;
  v24 = *(a1 + 16);
  v54 = a1;
  v25 = *(a1 + 32);
  v51 = v24;
  v52 = v25;
  v26 = *(a2 + 24);
  v53 = *(a2 + 32);
  v66 = a2;
  __swift_mutable_project_boxed_opaque_existential_1(a2, v26);
  v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
  v28 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer, &demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer, &protocol conformance descriptor for FeatureVectorizer<A>.Transformer);
  v29 = v72;
  result = (dispatch thunk of EstimatorEncoder.encode<A>(_:))(&v51, v27, v28, v26, v53, v30, v50);
  if (!v29)
  {
    v72 = 0;
    v32 = *(type metadata accessor for MLSupportVectorClassifier.Classifier(0) + 28) + v55;
    v33 = *(type metadata accessor for MLSupportVectorClassifier.Model(0) + 24) + v54;
    v34 = v74;
    v35 = v74 + *(v57 + 48);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v32, v74, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v33, v35, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
    if (swift_getEnumCaseMultiPayload(v34, v56) == 1)
    {
      v36 = v60;
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v74, v60, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
      v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
      EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(v35, v37);
      v39 = v66;
      if (EnumCaseMultiPayload == 1)
      {
        v40 = v36;
        v41 = v67;
        (*(v69 + 32))(v68, v40, v67);
        v42 = v58;
        (*(v61 + 32))(v58, v35, v62);
        LinearSupportVectorClassifier.encode(_:to:)(v42, v39, v41);
        (*(v61 + 8))(v42, v62);
        v43 = v68;
        v44 = v41;
        v45 = v69;
LABEL_7:
        (*(v45 + 8))(v43, v44);
        return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v74, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
      }

      v73 = v69;
      v70 = v67;
      v71 = v36;
    }

    else
    {
      v46 = v71;
      outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v74, v71, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
      v47 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
      if (swift_getEnumCaseMultiPayload(v35, v47) != 1)
      {
        v48 = v70;
        (*(v73 + 32))(v65, v46, v70);
        v49 = v59;
        (*(v63 + 32))(v59, v35, v64);
        LinearSupportVectorClassifier.encode(_:to:)(v49, v66, v48);
        (*(v63 + 8))(v49, v64);
        v43 = v65;
        v44 = v48;
        v45 = v73;
        goto LABEL_7;
      }
    }

    (*(v73 + 8))(v71, v70);
    _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, 0xD00000000000002FLL, "Classifier.Classifier.swift" + 0x8000000000000000, "CreateML/MLSupportVectorClassifier.Classifier.swift", 51, 2, 175, 0);
    BUG();
  }

  return result;
}

uint64_t MLSupportVectorClassifier.Classifier.decode(from:)(uint64_t a1)
{
  v71 = v2;
  v73 = v3;
  v64 = v1;
  v58 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, Int>);
  v57 = *(v58 - 8);
  v4 = *(v57 + 64);
  v5 = alloca(v4);
  v6 = alloca(v4);
  v66 = v49;
  v50 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, Int>);
  v54 = *(v50 - 8);
  v7 = *(v54 + 64);
  v8 = alloca(v7);
  v9 = alloca(v7);
  v51 = v49;
  v60 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifierModel<Double, String>);
  v61 = *(v60 - 8);
  v10 = *(v61 + 64);
  v11 = alloca(v10);
  v12 = alloca(v10);
  v67 = v49;
  v68 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
  v13 = *(*(v68 - 8) + 64);
  v14 = alloca(v13);
  v15 = alloca(v13);
  v62 = v49;
  v16 = alloca(v13);
  v17 = alloca(v13);
  v59 = v49;
  v56 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LinearSupportVectorClassifier<Double, String>);
  v55 = *(v56 - 8);
  v18 = *(v55 + 64);
  v19 = alloca(v18);
  v20 = alloca(v18);
  v53 = v49;
  v52 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
  v21 = *(*(v52 - 8) + 64);
  v22 = alloca(v21);
  v23 = alloca(v21);
  v72 = v49;
  v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer);
  v25 = *(a1 + 24);
  v26 = *(a1 + 32);
  v65 = a1;
  __swift_mutable_project_boxed_opaque_existential_1(a1, v25);
  v27 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type FeatureVectorizer<Double>.Transformer and conformance FeatureVectorizer<A>.Transformer, &demangling cache variable for type metadata for FeatureVectorizer<Double>.Transformer, &protocol conformance descriptor for FeatureVectorizer<A>.Transformer);
  v28 = v71;
  result = dispatch thunk of EstimatorDecoder.decode<A>(_:)(v24, v24, v27, v25, v26);
  if (!v28)
  {
    v30 = v53;
    v31 = v51;
    v32 = v50;
    v71 = 0;
    v69 = v49[1];
    v63 = v49[2];
    v70 = v49[3];
    v33 = type metadata accessor for MLSupportVectorClassifier.Classifier(0);
    v34 = v72;
    outlined init with copy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v73 + *(v33 + 28), v72, &demangling cache variable for type metadata for Either<LinearSupportVectorClassifier<Double, String>, LinearSupportVectorClassifier<Double, Int>>);
    if (swift_getEnumCaseMultiPayload(v34, v52) == 1)
    {
      v35 = v54;
      (*(v54 + 32))(v31, v72, v32);
      v72 = *v73;
      v73 = v73[1];
      v73;
      v36 = v71;
      LinearSupportVectorClassifier.decode(from:)(v65, v32);
      (*(v35 + 8))(v31, v32);
      v37 = v64;
      if (!v36)
      {
        v38 = v72;
        v39 = v62;
        (*(v57 + 32))(v62, v66, v58);
        v40 = 1;
        v41 = v39;
        v42 = v68;
LABEL_8:
        swift_storeEnumTagMultiPayload(v41, v42, v40);
        *v37 = v38;
        v37[1] = v73;
        v37[2] = v69;
        v37[3] = v63;
        v37[4] = v70;
        v48 = type metadata accessor for MLSupportVectorClassifier.Model(0);
        return outlined init with take of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(v39, v37 + *(v48 + 24), &demangling cache variable for type metadata for Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>);
      }
    }

    else
    {
      v43 = v30;
      v44 = v30;
      v45 = v56;
      v46 = v55;
      (*(v55 + 32))(v44, v72, v56);
      v72 = *v73;
      v73 = v73[1];
      v73;
      v47 = v71;
      LinearSupportVectorClassifier.decode(from:)(v65, v45);
      (*(v46 + 8))(v43, v45);
      v37 = v64;
      if (!v47)
      {
        v38 = v72;
        v39 = v59;
        (*(v61 + 32))(v59, v67, v60);
        v41 = v39;
        v42 = v68;
        v40 = 0;
        goto LABEL_8;
      }
    }

    v70;
    v69;
    return v73;
  }

  return result;
}

uint64_t outlined init with take of Either<LinearSupportVectorClassifierModel<Double, String>, LinearSupportVectorClassifierModel<Double, Int>>(uint64_t a1, uint64_t a2, uint64_t *a3)
{
  v3 = __swift_instantiateConcreteTypeFromMangledName(a3);
  (*(*(v3 - 8) + 32))(a2, a1, v3);
  return a2;
}

uint64_t MLHandActionClassifier.GraphCNN.iterateTraining(trainingData:validationData:epochCount:)(uint64_t a1, uint64_t a2, Swift::Int a3, double a4)
{
  v8[1] = v4;
  v10 = _swiftEmptyDictionarySingleton;
  context = _objc_autoreleasePoolPush();
  closure #1 in MLHandActionClassifier.GraphCNN.iterateTraining(trainingData:validationData:epochCount:)(v5, a1, &v10, a3, a2, v8, a4);
  _objc_autoreleasePoolPop(context);
  if (v4)
  {
    return v10;
  }

  else
  {
    return v10;
  }
}

uint64_t MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  *(v4 + 104) = v3;
  v5 = type metadata accessor for Event(0, a2, a3);
  *(v4 + 112) = v5;
  v6 = *(v5 - 8);
  *(v4 + 120) = v6;
  *(v4 + 128) = swift_task_alloc((*(v6 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  v7 = type metadata accessor for Tensor(0);
  *(v4 + 136) = v7;
  v8 = *(v7 - 8);
  *(v4 + 144) = v8;
  *(v4 + 152) = swift_task_alloc((*(v8 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  v9 = (*(*(type metadata accessor for MLClassifierMetrics(0) - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  *(v4 + 160) = swift_task_alloc(v9);
  *(v4 + 168) = swift_task_alloc(v9);
  v10 = type metadata accessor for TrainingTablePrinter(0);
  *(v4 + 176) = v10;
  *(v4 + 184) = swift_task_alloc((*(*(v10 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  v11 = type metadata accessor for MetricsKey(0);
  *(v4 + 192) = v11;
  v12 = *(v11 - 8);
  *(v4 + 200) = v12;
  v13 = (*(v12 + 64) + 15) & 0xFFFFFFFFFFFFFFF0;
  *(v4 + 208) = swift_task_alloc(v13);
  *(v4 + 216) = swift_task_alloc(v13);
  v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);
  *(v4 + 224) = swift_task_alloc((*(*(v14 - 8) + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>);
  *(v4 + 232) = v15;
  v16 = *(v15 - 8);
  *(v4 + 240) = v16;
  *(v4 + 248) = swift_task_alloc((*(v16 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  *(v4 + 256) = *a1;
  *(v4 + 296) = *(a1 + 8);
  *(v4 + 264) = *a2;
  *(v4 + 297) = *(a2 + 8);
  return swift_task_switch(MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:), 0, 0);
}

uint64_t MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:)(double a1)
{
  v122 = v1 | 0x1000000000000000;
  v121 = v2;
  v3 = *(v2 + 297);
  v4 = v2[33];
  v5 = *(v2 + 296);
  v6 = v2[32];
  v120 = v2[31];
  v7 = v2[13];
  v118 = v2[28];
  *&v116 = *v7;
  v91 = v6;
  v92 = v5;
  *&v111 = v4;
  BYTE8(v111) = v3;
  v8 = type metadata accessor for MLHandActionClassifier(0);
  v9 = (v7 + *(v8 + 28));
  static MLHandActionClassifier.prepareDataset(classLabels:trainingFeatures:validationFeatures:parameters:)(v120, v118, v116, &v91, &v111, v9, a1);
  v120 = v9;
  v117 = v8;
  v10 = *(v2[13] + 8);
  MLHandActionClassifier.GraphCNN.loadPretrainedCoreMLModel()();
  if (v11)
  {
    *&v116 = v11;
    v14 = v2[28];
    (*(v2[30] + 8))(v2[31], v2[29]);
    v15 = v14;
LABEL_3:
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v15, &demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);
    v16 = v2[31];
    v17 = v2[28];
    v18 = v2[27];
    v19 = v2[26];
    v20 = v2[23];
    v117 = v2[21];
    v119 = v2[20];
    v120 = v2[16];
    v118 = v2[19];
    v16;
    v17;
    v18;
    v19;
    v20;
    v117;
    v119;
    v118;
    v120;
    return (v2[1])();
  }

  v118 = v2[29];
  v22 = v2;
  v23 = v2[24];
  v119 = v2[28];
  v110 = v10;
  MLHandActionClassifier.GraphCNN.initDevice()();
  v24 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, MetricsKey)>);
  v25 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, MetricsKey));
  v26 = *(v25 - 8);
  v27 = *(v26 + 80);
  v28 = (v27 + 32) & ~*(v26 + 80);
  v29 = swift_allocObject(v24, v28 + *(v26 + 72), v27 | 7);
  *(v29 + 16) = 1;
  *(v29 + 24) = 2;
  v30 = v29 + v28 + *(v25 + 48);
  *(v29 + v28) = 0xD000000000000011;
  *(v29 + v28 + 8) = "eature extractor should be " + 0x8000000000000000;
  static MetricsKey.trainingAccuracy.getter();
  v31 = Dictionary.init(dictionaryLiteral:)(v29, &type metadata for String, v23, &protocol witness table for String);
  if (__swift_getEnumTagSinglePayload(v119, 1, v118) != 1)
  {
    v32 = v22[27];
    v33 = v22[26];
    v118 = v22[24];
    v119 = v22[25];
    static MetricsKey.validationAccuracy.getter();
    (*(v119 + 32))(v33, v32, v118);
    isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v31);
    *&v111 = v31;
    specialized _NativeDictionary.setValue(_:forKey:isUnique:)(v33, 0xD000000000000013, ("Validation Data\n" + 0x8000000000000000), isUniquelyReferenced_nonNull_native);
    v31 = v111;
  }

  v35 = v120;
  v93 = v22 + 2;
  v95 = v22 + 6;
  v108 = v22 + 10;
  v94 = v22 + 11;
  v105 = v22 + 12;
  v36 = v22[22];
  v120 = v22;
  v37 = v22[23];
  *(v37 + *(v36 + 24)) = v31;
  type metadata accessor for OS_os_log();
  v38 = OS_os_log.init(subsystem:category:)(0xD000000000000027, "el with empty dataset." + 0x8000000000000000, 0x72705F656C626174, 0xED00007265746E69);
  v39 = *(v36 + 20);
  v107 = v38;
  *(v37 + v39) = v38;
  Date.init()(0xD000000000000027);
  TrainingTablePrinter.beginTable()();
  v40 = *(v35 + *(type metadata accessor for MLHandActionClassifier.ModelParameters(0) + 24));
  v98 = v40;
  if (v40 < 0)
  {
    BUG();
  }

  v41 = v120;
  if (v40)
  {
    v106 = v120[25];
    v102 = v120[15];
    v99 = v120[18];
    v96 = "oseClassifier.swift" + 0x8000000000000000;
    v100 = "ve training confusion matrix" + 0x8000000000000000;
    v103 = "usion matrix at iteration " + 0x8000000000000000;
    v42 = 0;
    v97 = 0xD000000000000012;
    v109 = &type metadata for Any + 8;
    v101 = 0xD000000000000014;
    v104 = 0xD000000000000016;
    while (1)
    {
      v43 = v41[28];
      v44 = v41[31];
      v118 = v42;
      v45 = MLHandActionClassifier.GraphCNN.iterateTraining(trainingData:validationData:epochCount:)(v44, v43, v42, *v12.i64);
      v46 = v93;
      specialized Dictionary.subscript.getter(v97, v96, v45);
      if (!v41[5])
      {
        v45;
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v46, &demangling cache variable for type metadata for Any?);
        goto LABEL_19;
      }

      v47 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
      if (!swift_dynamicCast(v94, v46, v109, v47, 6))
      {
        break;
      }

      v113 = *&v47;
      v119 = v45;
      v48 = v41[11];
      v49 = v41[21];
      v50 = v116;
      static _MetricUtilities.makeClassifierMetrics(confusionMeter:classLabels:supplementMissingClassLabels:)(*v12.i64, v13, v48, v116, 0);
      v115 = v41[24];
      v51 = v41[17];
      v52 = v120[19];
      outlined assign with take of MLClassifierMetrics(v41[21], v120[13] + *(v117 + 32));
      v114 = v48;
      _MetricUtilities.ConfusionMatrixMeter.value(normalized:)(0, *v12.i64, v13);
      v112 = static _MetricUtilities.top1Accuracy(confusionMatrix:classCount:)(v52, *(v50 + 16));
      v53 = *(v99 + 8);
      v53(v52, v51);
      v54 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(MetricsKey, Double)>);
      v55 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MetricsKey, Double));
      v56 = *(v55 - 8);
      v57 = *(v56 + 80);
      v58 = (v57 + 32) & ~*(v56 + 80);
      v59 = swift_allocObject(v54, v58 + *(v56 + 72), v57 | 7);
      *(v59 + 16) = 1;
      *(v59 + 24) = 2;
      v60 = *(v55 + 48);
      static MetricsKey.trainingAccuracy.getter();
      v12 = *&v112;
      *(v60 + v59 + v58) = v112;
      v61 = v120;
      v62 = lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(&lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey, &type metadata accessor for MetricsKey, &protocol conformance descriptor for MetricsKey);
      v63 = Dictionary.init(dictionaryLiteral:)(v59, v115, &type metadata for Double, v62);
      v64 = v95;
      v65 = v119;
      specialized Dictionary.subscript.getter(v101, v100, v119);
      v65;
      if (v61[9])
      {
        if (swift_dynamicCast(v105, v64, v109, *&v113, 6))
        {
          v119 = v63;
          v66 = v61[20];
          static _MetricUtilities.makeClassifierMetrics(confusionMeter:classLabels:supplementMissingClassLabels:)(*v12.i64, v13, v61[12], v116, 0);
          v67 = v120[27];
          v115 = v120[24];
          v68 = v120[20];
          v112 = *(v120 + 17);
          v69 = v120[19];
          outlined assign with take of MLClassifierMetrics(v68, v120[13] + *(v117 + 36));
          v70 = static MetricsKey.validationAccuracy.getter();
          _MetricUtilities.ConfusionMatrixMeter.value(normalized:)(0, v70, v13);
          v113 = static _MetricUtilities.top1Accuracy(confusionMatrix:classCount:)(v69, *(v116 + 16));
          v53(v69, *&v112);
          v71 = v119;
          v72 = swift_isUniquelyReferenced_nonNull_native(v119);
          *&v111 = v71;
          v12 = *&v113;
          specialized _NativeDictionary.setValue(_:forKey:isUnique:)(v67, v72, v113);
          v63 = v111;
          v73 = v67;
          v61 = v120;
          (*(v106 + 8))(v73, v115);
        }
      }

      else
      {
        outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v64, &demangling cache variable for type metadata for Any?);
      }

      v74 = v118;
      v119 = v118 + 1;
      v75 = v61[23];
      v76 = v120[14];
      v77 = v120[16];
      v78 = v63;
      v79 = specialized _dictionaryUpCast<A, B, C, D>(_:)(v63);
      v78;
      Event.init(origin:itemCount:totalItemCount:metrics:)(v104, v103, v74, 0, 1, v79);
      TrainingTablePrinter.print(_:)(v77, v12);

      v80 = v76;
      v41 = v120;
      (*(v102 + 8))(v77, v80);
      v42 = v119;
      if (v98 == v119)
      {
        goto LABEL_16;
      }
    }

    v45;
LABEL_19:
    v114 = v41[31];
    v117 = v41[30];
    v115 = v41[29];
    v84 = v41[23];
    v119 = v41[28];
    *&v111 = 0;
    *(&v111 + 1) = 0xE000000000000000;
    _StringGuts.grow(_:)(60);
    v85._object = "ml.handactionclassifier" + 0x8000000000000000;
    v85._countAndFlagsBits = 0xD00000000000003ALL;
    String.append(_:)(v85);
    v120[10] = v118;
    v86 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
    v88 = v87;
    v85._countAndFlagsBits = v86;
    v85._object = v87;
    String.append(_:)(v85);
    v88;
    v116 = v111;
    v2 = v120;
    v85._object = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    v89 = swift_allocError(&type metadata for MLCreateError, v85._object, 0, 0);
    *v90 = v116;
    *(v90 + 16) = 0;
    *(v90 + 32) = 0;
    *(v90 + 48) = 0;
    *&v116 = v89;
    swift_willThrow(&type metadata for MLCreateError, v85._object);
    outlined destroy of MLActivityClassifier.ModelParameters(v84, type metadata accessor for TrainingTablePrinter);
    (*(v117 + 8))(v114, v115);
    v15 = v119;
    goto LABEL_3;
  }

LABEL_16:
  static os_log_type_t.info.getter();
  v81 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  v82 = swift_allocObject(v81, 72, 7);
  v82[2] = 1;
  v82[3] = 2;
  v82[7] = &type metadata for Int;
  v82[8] = &protocol witness table for Int;
  v82[4] = 3;
  os_log(_:dso:log:type:_:)("event: %lu", 10);
  v82;
  v83 = swift_task_alloc(80);
  v41[34] = v83;
  *v83 = v41;
  v83[1] = MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:);
  return MLHandActionClassifier.GraphCNN.compile()();
}

uint64_t MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:)(uint64_t a1)
{
  v5 = *(*v2 + 272);
  v4 = *v2;
  *(*v2 + 280) = v1;
  v5;
  if (v1)
  {
    v6 = MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:);
  }

  else
  {
    *(v4 + 288) = a1;
    v6 = MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:);
  }

  return swift_task_switch(v6, 0, 0);
}

uint64_t MLHandActionClassifier.runTrainingLoop(trainingData:validationData:loadPretrain:)()
{
  v13 = *(v0 + 288);
  v1 = *(v0 + 248);
  v14 = *(v0 + 240);
  v2 = *(v0 + 232);
  v3 = *(v0 + 224);
  v11 = *(v0 + 216);
  v10 = *(v0 + 208);
  v12 = *(v0 + 184);
  v9 = *(v0 + 168);
  v8 = *(v0 + 160);
  v7 = *(v0 + 152);
  v4 = *(v0 + 104);
  v6 = *(v0 + 128);
  outlined destroy of MLActivityClassifier.ModelParameters(v12, type metadata accessor for TrainingTablePrinter);
  (*(v14 + 8))(v1, v2);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v3, &demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);

  *(v4 + 16) = v13;
  v1;
  v3;
  v11;
  v10;
  v12;
  v9;
  v8;
  v7;
  v6;
  return (*(v0 + 8))();
}

{
  v1 = *(v0 + 248);
  v2 = *(v0 + 240);
  v3 = *(v0 + 232);
  v4 = *(v0 + 224);
  outlined destroy of MLActivityClassifier.ModelParameters(*(v0 + 184), type metadata accessor for TrainingTablePrinter);
  (*(v2 + 8))(v1, v3);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v4, &demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);
  v10 = *(v0 + 280);
  v5 = *(v0 + 224);
  v6 = *(v0 + 216);
  v7 = *(v0 + 208);
  v8 = *(v0 + 184);
  v14 = *(v0 + 168);
  v13 = *(v0 + 160);
  v11 = *(v0 + 128);
  v12 = *(v0 + 152);
  *(v0 + 248);
  v5;
  v6;
  v7;
  v8;
  v14;
  v13;
  v12;
  v11;
  return (*(v0 + 8))();
}

uint64_t MLHandActionClassifier.GraphCNN.evaluate(_:)(void *a1)
{
  v73 = v2;
  context = a1;
  v3 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LossReduction?) - 8) + 64);
  v4 = alloca(v3);
  v5 = alloca(v3);
  v56 = v54;
  v61 = type metadata accessor for Tensor(0);
  v60 = *(v61 - 8);
  v6 = *(v60 + 64);
  v7 = alloca(v6);
  v8 = alloca(v6);
  v57 = v54;
  v9 = alloca(v6);
  v10 = alloca(v6);
  v59 = v54;
  v11 = alloca(v6);
  v12 = alloca(v6);
  v58 = v54;
  v13 = alloca(v6);
  v14 = alloca(v6);
  v70 = v54;
  v71 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>);
  v65 = *(v71 - 8);
  v15 = *(v65 + 64);
  v16 = alloca(v15);
  v17 = alloca(v15);
  v66 = v54;
  v18 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>?) - 8) + 64);
  v19 = alloca(v18);
  v20 = alloca(v18);
  v67 = v54;
  v75 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>, DataSample<Tensor, Tensor>>.Iterator);
  v21 = *(*(v75 - 8) + 64);
  v22 = alloca(v21);
  v23 = alloca(v21);
  v74 = v54;
  v24 = type metadata accessor for LearningPhase(0);
  v25 = *(v24 - 8);
  v26 = *(v25 + 64);
  v27 = alloca(v26);
  v28 = alloca(v26);
  (*(v25 + 104))(v54, enum case for LearningPhase.inference(_:), v24);
  swift_beginAccess(v73 + OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model, v54, 33, 0);
  v77 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  v29 = lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, &protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  Layer.prepare(for:)(v54, v77, v29);
  swift_endAccess(v54);
  (*(v25 + 8))(v54, v24);
  v30 = *(*(v73 + 16) + 16);
  v31 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
  swift_allocObject(v31, *(v31 + 48), *(v31 + 52));
  result = _MetricUtilities.ConfusionMatrixMeter.init(classCount:)(v30);
  if (!v1)
  {
    v68 = result;
    v64 = 0;
    v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>);
    v34 = v74;
    Dataset.makeIterator()(v33);
    v35 = *(v75 + 44);
    v62 = *(v34 + v35);
    v63 = *(v34 + v35 + 8);
    v75 = lazy protocol witness table accessor for type Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>.Iterator and conformance Batches<A>.Iterator();
    v69 = enum case for LossReduction.mean(_:);
    LODWORD(v77) = 0;
    v76 = 0;
    while (1)
    {
      v36 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>.Iterator);
      dispatch thunk of IteratorProtocol.next()(v36, v75);
      v37 = *v54;
      if (*v54)
      {
        v55 = *v54;
        v38 = v67;
        v62(&v55);
        v37;
        v39 = v38;
        v40 = 0;
      }

      else
      {
        v38 = v67;
        v39 = v67;
        v40 = 1;
      }

      v41 = v71;
      __swift_storeEnumTagSinglePayload(v39, v40, 1, v71);
      v42 = v70;
      if (__swift_getEnumTagSinglePayload(v38, 1, v41) == 1)
      {
        break;
      }

      (*(v65 + 32))(v66, v38, v41);
      context = _objc_autoreleasePoolPush();
      DataSample.features.getter(v41);
      v43 = v58;
      v44 = v41;
      v45 = v59;
      DataSample.labels.getter(v44);
      MLHandActionClassifier.GraphCNN.callAsFunction(_:)(v42);
      v46 = type metadata accessor for LossReduction(0);
      v47 = v56;
      (*(*(v46 - 8) + 104))(v56, v69, v46);
      __swift_storeEnumTagSinglePayload(v47, 0, 1, v46);
      v48 = v57;
      softmaxCrossEntropy(logits:labels:labelSmoothing:axis:reduction:)(v45, v43, -1, v47, 0.0);
      v49 = v47;
      v50 = v48;
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v49, &demangling cache variable for type metadata for LossReduction?);
      _MetricUtilities.ConfusionMatrixMeter.add(predicted:target:)(v45, v43);
      Tensor.scalar<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
      if (__OFADD__(1, v76))
      {
        BUG();
      }

      ++v76;
      *&v77 = *&v77 + v54[0];
      v51 = *(v60 + 8);
      v52 = v50;
      v53 = v61;
      v51(v52, v61);
      v51(v45, v53);
      v51(v43, v53);
      v51(v70, v53);
      _objc_autoreleasePoolPop(context);
      (*(v65 + 8))(v66, v71);
    }

    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v74, &demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>, DataSample<Tensor, Tensor>>.Iterator);
    return v68;
  }

  return result;
}

BOOL specialized Dataset.isEmpty.getter()
{
  v0 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>?) - 8) + 64);
  v1 = alloca(v0);
  v2 = alloca(v0);
  v22 = v21;
  v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>, DataSample<Tensor, Tensor>>.Iterator);
  v4 = *(*(v3 - 8) + 64);
  v5 = alloca(v4);
  v6 = alloca(v4);
  v7 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>);
  Dataset.makeIterator()(v7);
  v8 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>.Iterator);
  v9 = lazy protocol witness table accessor for type Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>.Iterator and conformance Batches<A>.Iterator();
  dispatch thunk of IteratorProtocol.next()(v8, v9);
  v10 = v21[0];
  if (v21[0])
  {
    v11 = *(v3 + 44);
    v12 = *(v21 + v11);
    v13 = *(&v21[1] + v11);
    v21[1] = v21[0];
    v14 = v22;
    v12();
    v10;
    v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>);
    v16 = v14;
    v17 = 0;
  }

  else
  {
    v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>);
    v14 = v22;
    v16 = v22;
    v17 = 1;
  }

  __swift_storeEnumTagSinglePayload(v16, v17, 1, v15);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v21, &demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>, DataSample<Tensor, Tensor>>.Iterator);
  v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>);
  EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v14, 1, v18);
  if (EnumTagSinglePayload != 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v14, &demangling cache variable for type metadata for DataSample<Tensor, Tensor>?);
  }

  return EnumTagSinglePayload == 1;
}

Swift::Void __swiftcall MLHandActionClassifier.GraphCNN.initDevice()()
{
  v40 = v0;
  v1 = type metadata accessor for Logger(0);
  v47 = *(v1 - 8);
  v2 = *(v47 + 64);
  v3 = alloca(v2);
  v4 = alloca(v2);
  v45 = v39;
  v5 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for ComputeDevice?) - 8) + 64);
  v6 = alloca(v5);
  v7 = alloca(v5);
  v8 = type metadata accessor for ComputeDevice(0);
  v9 = *(v8 - 8);
  v10 = *(v9 + 64);
  v11 = alloca(v10);
  v12 = alloca(v10);
  v49 = v39;
  v13 = alloca(v10);
  v14 = alloca(v10);
  static ComputeDevice.gpu.getter();
  EnumTagSinglePayload = __swift_getEnumTagSinglePayload(v39, 1, v8);
  v42 = v9;
  if (EnumTagSinglePayload == 1)
  {
    static ComputeDevice.cpu.getter();
    if (__swift_getEnumTagSinglePayload(v39, 1, v8) != 1)
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v39, &demangling cache variable for type metadata for ComputeDevice?);
    }
  }

  else
  {
    (*(v9 + 32))(v39, v39, v8);
  }

  v16 = v49;
  if (one-time initialization token for logger != -1)
  {
    swift_once(&one-time initialization token for logger, one-time initialization function for logger);
  }

  v17 = __swift_project_value_buffer(v1, static MLHandActionClassifier.logger);
  v18 = v45;
  v46 = v1;
  (*(v47 + 16))(v45, v17, v1);
  v19 = v16;
  v41 = v39;
  v48 = v8;
  v20 = v42;
  (*(v42 + 16))(v19, v39, v8);
  v21 = Logger.logObject.getter();
  v22 = static os_log_type_t.info.getter();
  if (os_log_type_enabled(v21, v22))
  {
    v23 = swift_slowAlloc(12, -1);
    v43 = swift_slowAlloc(32, -1);
    v39[0] = v43;
    *v23 = 136315138;
    v24 = lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(&lazy protocol witness table cache variable for type ComputeDevice and conformance ComputeDevice, &type metadata accessor for ComputeDevice, &protocol conformance descriptor for ComputeDevice);
    log = v21;
    v25 = v49;
    v26 = dispatch thunk of CustomStringConvertible.description.getter(v48, v24);
    v28 = v27;
    *(v23 + 4) = getNullTerminatedUTF8PointerImpl(_:storingStringOwnersIn:)(v26, v27, v39);
    v28;
    v29 = v25;
    v30 = v48;
    v49 = *(v20 + 8);
    (v49)(v29, v48);
    v31 = log;
    _os_log_impl(&dword_0, log, v22, "Using %s to create model", v23, 0xCu);
    v32 = v43;
    __swift_destroy_boxed_opaque_existential_1Tm(v43);
    v32, -1, -1;
    v23, -1, -1;

    (*(v47 + 8))(v45, v46);
    v33 = v30;
  }

  else
  {
    v34 = *(v20 + 8);
    v35 = v49;
    v33 = v48;
    v49 = v34;
    (v34)(v35, v48);

    (*(v47 + 8))(v18, v46);
  }

  swift_beginAccess(OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model + v40, v39, 33, 0);
  v36 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  v37 = lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, &protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  v38 = v41;
  Layer.place(on:)(v41, v36, v37);
  swift_endAccess(v39);
  (v49)(v38, v33);
}

uint64_t closure #1 in MLHandActionClassifier.GraphCNN.iterateTraining(trainingData:validationData:epochCount:)(uint64_t a1, uint64_t a2, uint64_t a3, Swift::Int a4, uint64_t a5, void *a6, double a7)
{
  v28 = a6;
  v31 = v7;
  v30 = a5;
  epoch = a4;
  v26 = a3;
  v8 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?) - 8) + 64);
  v9 = alloca(v8);
  v10 = alloca(v8);
  v22 = v20;
  v29 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>);
  v11 = *(v29 - 8);
  v12 = *(v11 + 64);
  v13 = alloca(v12);
  v14 = alloca(v12);
  v27 = a1;
  v15 = v31;
  result = MLHandActionClassifier.GraphCNN.train(_:)(a2);
  if (v15)
  {
    *v28 = v15;
  }

  else
  {
    v24 = v20;
    v31 = v11;
    v21 = &type metadata for Double;
    v20[0] = a7;
    v17 = result;
    specialized Dictionary.subscript.setter(v20, 0x676E696E69617274, 0xED000073736F6C5FLL);
    v25 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
    v21 = v25;
    *&v20[0] = v17;

    specialized Dictionary.subscript.setter(v20, 0xD000000000000012, ("oseClassifier.swift" + 0x8000000000000000));
    MLHandActionClassifier.GraphCNN.adjustLearningRate(epoch:)(epoch);
    v18 = v22;
    outlined init with copy of Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?(v30, v22);
    if (__swift_getEnumTagSinglePayload(v18, 1, v29) == 1)
    {

      return outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>?);
    }

    else
    {
      v30 = v17;
      v19 = v24;
      (*(v31 + 32))(v24, v18, v29);
      v28 = MLHandActionClassifier.GraphCNN.evaluate(_:)(v19);
      v21 = &type metadata for Double;
      v20[0] = a7;
      specialized Dictionary.subscript.setter(v20, 0x69746164696C6176, 0xEF73736F6C5F6E6FLL);
      v21 = v25;
      *&v20[0] = v28;
      specialized Dictionary.subscript.setter(v20, 0xD000000000000014, ("ve training confusion matrix" + 0x8000000000000000));

      return (*(v31 + 8))(v19, v29);
    }
  }

  return result;
}

uint64_t MLHandActionClassifier.GraphCNN.train(_:)(uint64_t a1)
{
  v83 = v1;
  v87 = a1;
  v78 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  v3 = *(*(v78 - 8) + 64);
  v4 = alloca(v3);
  v5 = alloca(v3);
  v65 = &v61;
  v68 = type metadata accessor for Tensor(0);
  v69 = *(v68 - 8);
  v6 = *(v69 + 64);
  v7 = alloca(v6);
  v8 = alloca(v6);
  v66 = &v61;
  v9 = alloca(v6);
  v10 = alloca(v6);
  v76 = &v61;
  v11 = alloca(v6);
  v12 = alloca(v6);
  v82 = &v61;
  v79 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>);
  v74 = *(v79 - 8);
  v13 = *(v74 + 64);
  v14 = alloca(v13);
  v15 = alloca(v13);
  v77 = &v61;
  v16 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for DataSample<Tensor, Tensor>?) - 8) + 64);
  v17 = alloca(v16);
  v18 = alloca(v16);
  v80 = &v61;
  v84 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>, DataSample<Tensor, Tensor>>.Iterator);
  v19 = *(*(v84 - 1) + 64);
  v20 = alloca(v19);
  v21 = alloca(v19);
  v86 = &v61;
  v22 = type metadata accessor for LearningPhase(0);
  v23 = *(v22 - 8);
  v24 = v22;
  v88 = v22;
  v25 = *(v23 + 64);
  v26 = alloca(v25);
  v27 = alloca(v25);
  (*(v23 + 104))(&v61, enum case for LearningPhase.training(_:), v24);
  v85 = v2;
  v28 = v2 + OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model;
  swift_beginAccess(v2 + OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model, v63, 33, 0);
  v67 = lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, &protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  v75 = v28;
  Layer.prepare(for:)(&v61, v78, v67);
  swift_endAccess(v63);
  (*(v23 + 8))(&v61, v88);
  if (specialized Dataset.isEmpty.getter())
  {
    v29 = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
    swift_allocError(&type metadata for MLCreateError, v29, 0, 0);
    *v30 = 0xD000000000000036;
    *(v30 + 8) = "must contain a '" + 0x8000000000000000;
    *(v30 + 16) = 0;
    *(v30 + 32) = 0;
    *(v30 + 48) = 1;
    return swift_willThrow(&type metadata for MLCreateError, v29);
  }

  else
  {
    v32 = v85;
    v33 = *(*(v85 + 16) + 16);
    v34 = type metadata accessor for _MetricUtilities.ConfusionMatrixMeter(0);
    swift_allocObject(v34, *(v34 + 48), *(v34 + 52));
    v35 = v83;
    result = _MetricUtilities.ConfusionMatrixMeter.init(classCount:)(v33);
    if (!v35)
    {
      v81 = result;
      v73 = 0;
      v36 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Dataset<[(label: Int, keypoints: MLMultiArray)], DataSample<Tensor, Tensor>>);
      v37 = v86;
      Dataset.makeIterator()(v36);
      v38 = *(v84 + 11);
      v71 = *(v37 + v38);
      v72 = *(v37 + v38 + 8);
      v85 = OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_optimizer + v32;
      LODWORD(v88) = 0;
      v87 = 0;
      v70 = lazy protocol witness table accessor for type Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>.Iterator and conformance Batches<A>.Iterator();
      v39 = v79;
      while (1)
      {
        v40 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>.Iterator);
        dispatch thunk of IteratorProtocol.next()(v40, v70);
        v41 = *v63;
        if (*v63)
        {
          v62[0] = *v63;
          v42 = v80;
          v71(v62);
          v43 = v42;
          v41;
          v44 = v42;
          v45 = 0;
        }

        else
        {
          v43 = v80;
          v44 = v80;
          v45 = 1;
        }

        __swift_storeEnumTagSinglePayload(v44, v45, 1, v39);
        v46 = v82;
        if (__swift_getEnumTagSinglePayload(v43, 1, v39) == 1)
        {
          break;
        }

        (*(v74 + 32))(v77, v43, v39);
        context = _objc_autoreleasePoolPush();
        DataSample.features.getter(v39);
        v47 = v46;
        v48 = v76;
        DataSample.labels.getter(v39);
        v49 = v48;
        v50 = v65;
        outlined init with copy of MLHandActionClassifier.GraphCNNModel(v75, v65);
        v84 = &v61;
        v51 = alloca(40);
        v52 = alloca(48);
        v62[1] = v47;
        v62[2] = v49;
        *v63 = v81;
        v53 = v66;
        v83 = valueWithGradient<A>(at:of:)(v66, v50, partial apply for closure #1 in closure #1 in MLHandActionClassifier.GraphCNN.train(_:), &v61, v78, v67);
        outlined destroy of MLActivityClassifier.ModelParameters(v50, type metadata accessor for MLHandActionClassifier.GraphCNNModel);
        swift_beginAccess(v85, v63, 33, 0);
        v54 = v75;
        swift_beginAccess(v75, v62, 33, 0);
        v55 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for SGD<MLHandActionClassifier.GraphCNNModel>);
        v56 = v54;
        v57 = v83;
        SGD.update(_:with:)(v56, v83, v55);
        swift_endAccess(v62);
        swift_endAccess(v63);
        v57;
        Tensor.scalar<A>(as:)(&type metadata for Float, &type metadata for Float, &protocol witness table for Float);
        if (__OFADD__(1, v87))
        {
          BUG();
        }

        ++v87;
        *&v88 = *&v88 + v63[0];
        v58 = *(v69 + 8);
        v59 = v53;
        v60 = v68;
        v58(v59, v68);
        v58(v76, v60);
        v58(v82, v60);
        _objc_autoreleasePoolPop(context);
        v39 = v79;
        (*(v74 + 8))(v77, v79);
      }

      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v86, &demangling cache variable for type metadata for LazyMapSequence<Batches<LazyPrefetchingMapSequence<LazySequence<Sampling<[(label: Int, keypoints: MLMultiArray)]>>, DataSample<Tensor, Tensor>>>, DataSample<Tensor, Tensor>>.Iterator);
      return v81;
    }
  }

  return result;
}

Swift::Void __swiftcall MLHandActionClassifier.GraphCNN.adjustLearningRate(epoch:)(Swift::Int epoch)
{
  v2 = 0x3C23D70Au;
  for (i = 0; i != 3; ++i)
  {
    v4 = v2;
    if (*(&outlined read-only object #0 of one-time initialization function for adjustLearningRateSteps + i + 4) <= epoch)
    {
      *&v4 = *&v2 * 0.1;
      v2 = v4;
    }
  }

  v7 = v2;
  v5 = OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_optimizer;
  swift_beginAccess(OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_optimizer + v1, v6, 1, 0);
  *(v1 + v5) = v7;
}

uint64_t outlined init with copy of MLHandActionClassifier.GraphCNNModel(uint64_t a1, uint64_t a2)
{
  v2 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  (*(*(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t closure #1 in closure #1 in MLHandActionClassifier.GraphCNN.train(_:)(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4)
{
  v23 = a4;
  v24 = a3;
  v27 = a1;
  v26 = v4;
  v5 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for LossReduction?) - 8) + 64);
  v6 = alloca(v5);
  v7 = alloca(v5);
  v8 = type metadata accessor for Tensor(0);
  v25 = *(v8 - 8);
  v9 = *(v25 + 64);
  v10 = alloca(v9);
  v11 = alloca(v9);
  v12 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  v13 = lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, &protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  Layer.callAsFunction(_:)(a2, v12, v13);
  v14 = enum case for LossReduction.mean(_:);
  v15 = type metadata accessor for LossReduction(0);
  (*(*(v15 - 8) + 104))(v18, v14, v15);
  __swift_storeEnumTagSinglePayload(v18, 0, 1, v15);
  v16 = v24;
  softmaxCrossEntropy(logits:labels:labelSmoothing:axis:reduction:)(v18, v24, -1, v18, 0.0);
  outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(v18, &demangling cache variable for type metadata for LossReduction?);
  v20 = v23;
  v21 = v18;
  v22 = v16;
  withoutGradient<A>(_:)(partial apply for closure #1 in closure #1 in closure #1 in MLHandActionClassifier.GraphCNN.train(_:), v19, &type metadata for () + 8);
  return (*(v25 + 8))(v18, v8);
}

uint64_t partial apply for closure #1 in closure #1 in closure #1 in MLHandActionClassifier.GraphCNN.train(_:)()
{
  v1 = v0[3];
  v2 = v0[4];
  v3 = v0[2];
  return _MetricUtilities.ConfusionMatrixMeter.add(predicted:target:)(v1, v2);
}

uint64_t __swift_project_value_buffer(uint64_t a1, uint64_t a2)
{
  result = a2;
  if ((*(*(a1 - 8) + 82) & 2) != 0)
  {
    return *a2;
  }

  return result;
}

uint64_t getNullTerminatedUTF8PointerImpl(_:storingStringOwnersIn:)(uint64_t a1, int64_t a2, uint64_t *a3)
{
  v4 = specialized _StringGuts._deconstructUTF8<A>(scratch:)(v10, 0, 0, 1, a1, a2);
  v5 = v10[0];
  if (v4)
  {
    v6 = v4;
    ObjectType = swift_getObjectType(v4);
    v10[0] = v6;
    v7 = *a3;
    if (*a3)
    {
      outlined init with copy of Any(v10, *a3);
      *a3 = v7 + 32;
    }
  }

  else
  {
    ObjectType = &type metadata for _StringGuts;
    v10[0] = a1;
    v10[1] = a2;
    v8 = *a3;
    if (*a3)
    {
      outlined init with copy of Any(v10, *a3);
      *a3 = v8 + 32;
    }

    a2;
  }

  __swift_destroy_boxed_opaque_existential_1Tm(v10);
  return v5;
}

uint64_t specialized _StringGuts._deconstructUTF8<A>(scratch:)(uint64_t *a1, void *a2, uint64_t a3, char a4, uint64_t a5, int64_t a6)
{
  if ((a6 & 0x2000000000000000) != 0)
  {
    if ((a4 & 1) == 0)
    {
      v9 = HIBYTE(a6) & 0xF;
      if (a2 != 0 && a3 - a2 > v9)
      {
        __src[0] = a5;
        __src[1] = a6 & 0xFFFFFFFFFFFFFFLL;
        memcpy(a2, __src, v9);
        *(a2 + v9) = 0;
        *a1 = a2;
        return 0;
      }
    }

LABEL_10:
    v8 = _StringGuts._allocateForDeconstruct()(a5, a6);
    *a1 = v10;
    return v8;
  }

  if ((a6 & 0x1000000000000000) != 0)
  {
    goto LABEL_10;
  }

  if ((a5 & 0x1000000000000000) != 0)
  {
    v7 = (a6 & 0xFFFFFFFFFFFFFFFLL) + 32;
  }

  else
  {
    v7 = _StringObject.sharedUTF8.getter(a5, a6);
    if (!v7)
    {
      BUG();
    }
  }

  *a1 = v7;
  if (a6 < 0)
  {
    return 0;
  }

  v8 = a6 & 0xFFFFFFFFFFFFFFFLL;
  swift_unknownObjectRetain(v8);
  return v8;
}

char *_StringGuts._allocateForDeconstruct()(uint64_t a1, unint64_t a2)
{
  v2 = specialized _copyCollectionToContiguousArray<A>(_:)(a1, a2);
  if (!swift_isUniquelyReferenced_nonNull_native(v2))
  {
    v2 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, *(v2 + 2) + 1, 1, v2);
  }

  v3 = *(v2 + 2);
  if (*(v2 + 3) >> 1 <= v3)
  {
    v2 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(*(v2 + 3) >= 2uLL, v3 + 1, 1, v2);
  }

  *(v2 + 2) = v3 + 1;
  v2[v3 + 32] = 0;
  return v2;
}

void *specialized _copyCollectionToContiguousArray<A>(_:)(uint64_t a1, unint64_t a2)
{
  if ((a2 & 0x1000000000000000) != 0)
  {
    v2 = String.UTF8View._foreignCount()();
  }

  else if ((a2 & 0x2000000000000000) != 0)
  {
    v2 = HIBYTE(a2) & 0xF;
  }

  else
  {
    v2 = a1 & 0xFFFFFFFFFFFFLL;
  }

  if (!v2)
  {
    return _swiftEmptyArrayStorage;
  }

  v3 = _ss22_ContiguousArrayBufferV19_uninitializedCount15minimumCapacityAByxGSi_SitcfCs5UInt8V_Tt1gq5(v2, 0);
  v4 = _StringGuts.copyUTF8(into:)(v3 + 4, v2, a1, a2);
  if (v5)
  {
    BUG();
  }

  if (v4 != v2)
  {
    BUG();
  }

  return v3;
}

void *_ss22_ContiguousArrayBufferV19_uninitializedCount15minimumCapacityAByxGSi_SitcfCs5UInt8V_Tt1gq5(uint64_t a1, uint64_t a2)
{
  v2 = a2;
  if (a2 <= a1)
  {
    v2 = a1;
  }

  if (!v2)
  {
    return _swiftEmptyArrayStorage;
  }

  v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<UInt8>);
  v4 = swift_allocObject(v3, v2 + 32, 7);
  v5 = _swift_stdlib_malloc_size(v4);
  v4[2] = a1;
  v4[3] = 2 * v5 - 64;
  return v4;
}

uint64_t lazy protocol witness table accessor for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel(uint64_t *a1, uint64_t (*a2)(uint64_t), uint64_t a3)
{
  result = *a1;
  if (!*a1)
  {
    v5 = a2(255);
    result = swift_getWitnessTable(a3, v5);
    *a1 = result;
  }

  return result;
}

uint64_t *initializeBufferWithCopyOfBuffer for TrainingTablePrinter(uint64_t *a1, uint64_t *a2, uint64_t a3)
{
  v3 = a1;
  v4 = *(*(a3 - 8) + 80);
  if ((v4 & 0x20000) != 0)
  {
    v11 = *a2;
    *v3 = *a2;
    v3 = (v11 + ((v4 + 16) & ~v4));
    v11;
  }

  else
  {
    v6 = type metadata accessor for Date(0);
    (*(*(v6 - 8) + 16))(a1, a2, v6);
    v7 = *(a3 + 20);
    v8 = *(a2 + v7);
    *(v3 + v7) = v8;
    v9 = *(a3 + 24);
    v10 = *(a2 + v9);
    *(v3 + v9) = v10;
    v8;
    v10;
  }

  return v3;
}

uint64_t destroy for TrainingTablePrinter(uint64_t a1, uint64_t a2)
{
  v2 = type metadata accessor for Date(0);
  (*(*(v2 - 8) + 8))(a1, v2);

  return *(a1 + *(a2 + 24));
}

uint64_t initializeWithCopy for TrainingTablePrinter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v5 = type metadata accessor for Date(0);
  (*(*(v5 - 8) + 16))(a1, a2, v5);
  v6 = *(a3 + 20);
  v7 = *(a2 + v6);
  *(a1 + v6) = v7;
  v8 = *(a3 + 24);
  v9 = *(a2 + v8);
  *(a1 + v8) = v9;
  v7;
  v9;
  return a1;
}

uint64_t assignWithCopy for TrainingTablePrinter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v5 = type metadata accessor for Date(0);
  (*(*(v5 - 8) + 24))(a1, a2, v5);
  v6 = *(a3 + 20);
  v7 = *(a2 + v6);
  v8 = *(a1 + v6);
  *(a1 + v6) = v7;
  v7;

  v9 = *(a3 + 24);
  v10 = *(a2 + v9);
  v11 = *(a1 + v9);
  *(a1 + v9) = v10;
  v10;
  v11;
  return a1;
}

uint64_t initializeWithTake for TrainingTablePrinter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v4 = type metadata accessor for Date(0);
  (*(*(v4 - 8) + 32))(a1, a2, v4);
  *(a1 + *(a3 + 20)) = *(a2 + *(a3 + 20));
  *(a1 + *(a3 + 24)) = *(a2 + *(a3 + 24));
  return a1;
}

uint64_t assignWithTake for TrainingTablePrinter(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v5 = type metadata accessor for Date(0);
  (*(*(v5 - 8) + 40))(a1, a2, v5);
  v6 = *(a3 + 20);
  v7 = *(a1 + v6);
  *(a1 + v6) = *(a2 + v6);

  v8 = *(a3 + 24);
  v9 = *(a1 + v8);
  *(a1 + v8) = *(a2 + v8);
  v9;
  return a1;
}

uint64_t sub_2AF09A(uint64_t a1, unsigned int a2, uint64_t a3)
{
  v4 = 0;
  v5 = type metadata accessor for Date(0);
  if (*(*(v5 - 8) + 84) == a2)
  {
    return __swift_getEnumTagSinglePayload(a1, a2, v5);
  }

  if ((*(a1 + *(a3 + 20)) & 0xFFFFFFFF00000001) == 0)
  {
    return (*(a1 + *(a3 + 20)) >> 1) + 1;
  }

  return v4;
}

uint64_t sub_2AF123(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  v6 = type metadata accessor for Date(0);
  if (*(*(v6 - 8) + 84) == a3)
  {
    return __swift_storeEnumTagSinglePayload(a1, a2, a2, v6);
  }

  result = *(a4 + 20);
  *(a1 + result) = 2 * (a2 - 1);
  return result;
}

uint64_t type metadata completion function for TrainingTablePrinter(uint64_t a1)
{
  result = type metadata accessor for Date(319);
  if (v2 <= 0x3F)
  {
    v3[0] = *(result - 8) + 64;
    v3[1] = &value witness table for Builtin.UnknownObject + 64;
    v3[2] = &value witness table for Builtin.BridgeObject + 64;
    swift_initStructMetadata(a1, 256, 3, v3, a1 + 16);
    return 0;
  }

  return result;
}

Swift::Void __swiftcall TrainingTablePrinter.beginTable()()
{
  v22 = v0;
  v20 = type metadata accessor for TrainingTablePrinter(0);
  v1 = *(v0 + *(v20 + 20));
  static os_log_type_t.info.getter();
  v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  v3 = swift_allocObject(v2, 72, 7);
  v3[2] = 1;
  v3[3] = 2;
  v3[7] = &type metadata for Int;
  v3[8] = &protocol witness table for Int;
  v3[4] = 0;
  v4 = v1;
  v21 = v1;
  os_log(_:dso:log:type:_:)("event: %lu", 10);
  v3;
  LOBYTE(v3) = static os_log_type_t.info.getter();
  v5 = swift_allocObject(v2, 152, 7);
  v5[2] = 3;
  v5[3] = 6;
  v5[7] = &type metadata for Int;
  v5[8] = &protocol witness table for Int;
  v5[4] = 1;
  v5[12] = &type metadata for Int;
  v5[13] = &protocol witness table for Int;
  v5[9] = 0;
  v5[17] = &type metadata for String;
  v6 = lazy protocol witness table accessor for type String and conformance String();
  v5[18] = v6;
  v5[14] = 0x6F69746172657449;
  v5[15] = 0xE90000000000006ELL;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %{public}s", 42, 2, &dword_0, v4, v3, v5);
  v5;
  LOBYTE(v4) = static os_log_type_t.info.getter();
  v18 = v2;
  v7 = swift_allocObject(v2, 152, 7);
  *(v7 + 16) = 3;
  *(v7 + 24) = 6;
  *(v7 + 56) = &type metadata for Int;
  *(v7 + 64) = &protocol witness table for Int;
  *(v7 + 32) = 1;
  *(v7 + 96) = &type metadata for Int;
  *(v7 + 104) = &protocol witness table for Int;
  *(v7 + 72) = 1;
  *(v7 + 136) = &type metadata for String;
  v19 = v6;
  *(v7 + 144) = v6;
  strcpy((v7 + 112), "Elapsed Time");
  *(v7 + 125) = 0;
  *(v7 + 126) = -5120;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %{public}s", 42, 2, &dword_0, v21, v4, v7);
  v7;
  v8 = *(v22 + *(v20 + 24));
  specialized EnumeratedSequence.makeIterator()(v8);
  v23 = v8;
  swift_bridgeObjectRetain_n(v8, 2);
  while (1)
  {
    v9 = specialized EnumeratedSequence.Iterator.next()();
    if (!v11)
    {
      break;
    }

    v12 = v9;
    v13 = v10;
    v14 = v11;
    v15 = static os_log_type_t.info.getter();
    v16 = swift_allocObject(v18, 152, 7);
    v16[2] = 3;
    v16[3] = 6;
    v16[7] = &type metadata for Int;
    v16[8] = &protocol witness table for Int;
    v16[4] = 1;
    if (v12 < 0)
    {
      BUG();
    }

    v16[12] = &type metadata for UInt64;
    v16[13] = &protocol witness table for UInt64;
    v16[9] = v12 + 2;
    v16[17] = &type metadata for String;
    v16[18] = v19;
    v16[14] = v13;
    v16[15] = v14;
    os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %{public}s", 42, 2, &dword_0, v21, v15, v16);
    v16;
  }

  outlined consume of [String : [Double]].Iterator._Variant(v17);
  v23;
}

Swift::Void __swiftcall TrainingTablePrinter.print(iteration:metrics:)(Swift::Int iteration, Swift::OpaquePointer metrics)
{
  v60 = v2;
  rawValue = metrics._rawValue;
  v68 = iteration;
  v4 = type metadata accessor for MetricsKey(0);
  v58 = *(v4 - 8);
  v5 = *(v58 + 64);
  v6 = alloca(v5);
  v7 = alloca(v5);
  v63 = &v52;
  v8 = alloca(v5);
  v9 = alloca(v5);
  v64 = &v52;
  v10 = alloca(v5);
  v11 = alloca(v5);
  v61 = &v52;
  v12 = alloca(v5);
  v13 = alloca(v5);
  v62 = &v52;
  v14 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey)?) - 8) + 64);
  v15 = alloca(v14);
  v16 = alloca(v14);
  v56 = &v52;
  v17 = alloca(v14);
  v18 = alloca(v14);
  v57 = &v52;
  v69 = type metadata accessor for TrainingTablePrinter(0);
  v65 = *(v2 + *(v69 + 20));
  LOBYTE(v66) = static os_log_type_t.info.getter();
  v19 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  v20 = swift_allocObject(v19, 152, 7);
  v20[2] = 3;
  v20[3] = 6;
  v20[7] = &type metadata for Int;
  v20[8] = &protocol witness table for Int;
  v20[4] = 2;
  v20[12] = &type metadata for Int;
  v20[13] = &protocol witness table for Int;
  v20[9] = 0;
  v20[17] = &type metadata for Int;
  v20[18] = &protocol witness table for Int;
  v20[14] = v68;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %d", 34, 2, &dword_0);
  v20;
  LOBYTE(v68) = static os_log_type_t.info.getter();
  v66 = v19;
  v21 = swift_allocObject(v19, 152, 7);
  *(v21 + 16) = 3;
  *(v21 + 24) = 6;
  *(v21 + 56) = &type metadata for Int;
  *(v21 + 64) = &protocol witness table for Int;
  *(v21 + 32) = 2;
  v22 = v64;
  *(v21 + 96) = &type metadata for Int;
  *(v21 + 104) = &protocol witness table for Int;
  *(v21 + 72) = 1;
  v23 = v60;
  *v3.i64 = Date.timeIntervalSinceNow.getter();
  *(v21 + 136) = &type metadata for Double;
  *(v21 + 144) = &protocol witness table for Double;
  _mm_storel_ps((v21 + 112), _mm_xor_ps(v3, xmmword_33DFE0));
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %f", 34, 2, &dword_0, v65, v68, v21);
  v21;
  v24 = *(v23 + *(v69 + 24));
  specialized EnumeratedSequence.makeIterator()(v24);
  v24;
  for (i = v4; ; v36(v62, i))
  {
    v25 = v56;
    specialized EnumeratedSequence.Iterator.next()();
    v26 = v57;
    outlined init with take of (offset: Int, element: MetricsKey)?(v25, v57);
    v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey));
    if (__swift_getEnumTagSinglePayload(v26, 1, v27) == 1)
    {
      break;
    }

    v68 = *v26;
    v28 = v26 + *(v27 + 48);
    v29 = v62;
    v30 = v22;
    v31 = v58;
    (*(v58 + 32))(v62, v28, v4);
    v32 = *(v31 + 16);
    v33 = v61;
    v32(v61, v29, i);
    v32(v30, v33, i);
    v34 = i;
    v35 = v63;
    static MetricsKey.trainingLoss.getter();
    v69 = lazy protocol witness table accessor for type MetricsKey and conformance MetricsKey();
    LOBYTE(v30) = dispatch thunk of static Equatable.== infix(_:_:)(v35, v30, v34, v69);
    v36 = *(v31 + 8);
    v36(v35, v34);
    if (v30)
    {
      v37 = v34;
      v38 = 0;
      v22 = v64;
    }

    else
    {
      static MetricsKey.trainingAccuracy.getter();
      v22 = v64;
      v37 = v34;
      v39 = v35;
      v40 = dispatch thunk of static Equatable.== infix(_:_:)(v35, v64, v34, v69);
      v36(v39, v34);
      v38 = 3;
      if ((v40 & 1) == 0)
      {
        v41 = v63;
        static MetricsKey.validationLoss.getter();
        v42 = dispatch thunk of static Equatable.== infix(_:_:)(v41, v22, v37, v69);
        v36(v41, v37);
        v38 = 4;
        if ((v42 & 1) == 0)
        {
          v49 = v63;
          static MetricsKey.validationAccuracy.getter();
          v50 = dispatch thunk of static Equatable.== infix(_:_:)(v49, v22, v37, v69);
          v36(v61, v37);
          v36(v49, v37);
          v36(v22, v37);
          v38 = 5;
          if ((v50 & 1) == 0)
          {
            goto LABEL_12;
          }

          goto LABEL_8;
        }
      }
    }

    v36(v61, v37);
    v36(v22, v37);
LABEL_8:
    v43 = rawValue;
    if (!rawValue[2] || (v44 = specialized __RawDictionaryStorage.find<A>(_:)(v38), (v45 & 1) == 0))
    {
      v53 = 0;
      v54 = 0xE000000000000000;
      _StringGuts.grow(_:)(32);
      v51._object = "gUtilities.swift" + 0x8000000000000000;
      v51._countAndFlagsBits = 0xD00000000000001DLL;
      String.append(_:)(v51);
      _print_unlocked<A, B>(_:_:)(v62, &v53, i, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
      v51._countAndFlagsBits = 46;
      v51._object = 0xE100000000000000;
      String.append(_:)(v51);
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v53, v54, "CreateML/_LoggingUtilities.swift", 32, 2, 122, 0);
      BUG();
    }

    v69 = *(v43[7] + 8 * v44);
    v46 = static os_log_type_t.info.getter();
    v47 = swift_allocObject(v66, 152, 7);
    v47[2] = 3;
    v47[3] = 6;
    v47[7] = &type metadata for Int;
    v47[8] = &protocol witness table for Int;
    v47[4] = 2;
    v48 = v68 + 2;
    if (__OFADD__(2, v68))
    {
      BUG();
    }

    v47[12] = &type metadata for Int;
    v47[13] = &protocol witness table for Int;
    v47[9] = v48;
    v47[17] = &type metadata for Double;
    v47[18] = &protocol witness table for Double;
    v47[14] = v69;
    os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %f", 34, 2, &dword_0, v65, v46, v47);
    v47;
LABEL_12:
    v4 = i;
  }

  outlined consume of [String : [Double]].Iterator._Variant(v55);
}

Swift::Void __swiftcall _TablePrinter.beginTable()()
{
  v1 = type metadata accessor for _TablePrinter(0);
  v22 = *(v0 + *(v1 + 24));
  static os_log_type_t.info.getter();
  v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  v2 = swift_allocObject(v23, 72, 7);
  v2[2] = 1;
  v2[3] = 2;
  v2[7] = &type metadata for Int;
  v2[8] = &protocol witness table for Int;
  v2[4] = 0;
  os_log(_:dso:log:type:_:)("event: %lu", 10);
  v2;
  v3 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  inited = swift_initStackObject(v3, v20);
  *(inited + 16) = 3;
  *(inited + 24) = 6;
  strcpy((inited + 32), "Elapsed Time");
  *(inited + 45) = 0;
  *(inited + 46) = -5120;
  v5 = *(v1 + 28);
  v7 = *(v0 + v5 + 8);
  *&v21 = *(v0 + v5);
  v6 = v21;
  *(&v21 + 1) = v7;
  v7;
  v8._countAndFlagsBits = 0x737365636F725020;
  v8._object = 0xEA00000000006465;
  String.append(_:)(v8);
  *(inited + 48) = v21;
  *&v21 = 0;
  *(&v21 + 1) = 0xE000000000000000;
  _StringGuts.grow(_:)(18);
  *(&v21 + 1);
  *&v21 = 0xD000000000000010;
  *(&v21 + 1) = "mn: %lu, value: %d" + 0x8000000000000000;
  v7;
  v8._countAndFlagsBits = v6;
  v8._object = v7;
  String.append(_:)(v8);
  v7;
  *(inited + 64) = v21;
  v25 = *(inited + 32);
  v9 = *(inited + 40);
  inited;
  v9;
  v10 = static os_log_type_t.info.getter();
  v11 = v23;
  v12 = swift_allocObject(v23, 152, 7);
  v12[2] = 3;
  v12[3] = 6;
  v12[7] = &type metadata for Int;
  v12[8] = &protocol witness table for Int;
  v12[4] = 1;
  v12[12] = &type metadata for UInt64;
  v12[13] = &protocol witness table for UInt64;
  v12[9] = 0;
  v12[17] = &type metadata for String;
  v24 = lazy protocol witness table accessor for type String and conformance String();
  v12[18] = v24;
  v12[14] = v25;
  v12[15] = v9;
  v9;
  v13 = v10;
  v14 = v22;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %{public}s", 42, 2, &dword_0, v22, v13, v12);
  v9;
  v12;
  v25 = *(inited + 48);
  v15 = *(inited + 56);
  v15;
  v26 = static os_log_type_t.info.getter();
  v16 = swift_allocObject(v11, 152, 7);
  v16[2] = 3;
  v16[3] = 6;
  v16[7] = &type metadata for Int;
  v16[8] = &protocol witness table for Int;
  v16[4] = 1;
  v16[12] = &type metadata for UInt64;
  v16[13] = &protocol witness table for UInt64;
  v16[9] = 1;
  v16[17] = &type metadata for String;
  v16[18] = v24;
  v16[14] = v25;
  v16[15] = v15;
  v15;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %{public}s", 42, 2, &dword_0, v14, v26, v16);
  v15;
  v16;
  v17 = *(inited + 64);
  v18 = *(inited + 72);
  v18;
  LOBYTE(v11) = static os_log_type_t.info.getter();
  v19 = swift_allocObject(v23, 152, 7);
  v19[2] = 3;
  v19[3] = 6;
  v19[7] = &type metadata for Int;
  v19[8] = &protocol witness table for Int;
  v19[4] = 1;
  v19[12] = &type metadata for UInt64;
  v19[13] = &protocol witness table for UInt64;
  v19[9] = 2;
  v19[17] = &type metadata for String;
  v19[18] = v24;
  v19[14] = v17;
  v19[15] = v18;
  v18;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %{public}s", 42, 2, &dword_0, v22, v11, v19);
  inited;
  v18;
  v19;
  swift_setDeallocating(inited);
  specialized _ContiguousArrayStorage.__deallocating_deinit();
}

Swift::Void __swiftcall _TablePrinter.printRow(currentFileIndex:)(Swift::Int currentFileIndex)
{
  v3 = type metadata accessor for _TablePrinter(0);
  v10 = *(v1 + *(v3 + 24));
  v9 = v1;
  v12 = static os_log_type_t.info.getter();
  v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  v4 = swift_allocObject(v11, 152, 7);
  *(v4 + 16) = 3;
  *(v4 + 24) = 6;
  *(v4 + 56) = &type metadata for Int;
  *(v4 + 64) = &protocol witness table for Int;
  *(v4 + 32) = 2;
  *(v4 + 96) = &type metadata for Int;
  *(v4 + 104) = &protocol witness table for Int;
  *(v4 + 72) = 0;
  v5 = v1 + *(v3 + 20);
  *v2.i64 = Date.timeIntervalSinceNow.getter();
  *(v4 + 136) = &type metadata for Double;
  *(v4 + 144) = &protocol witness table for Double;
  _mm_storel_ps((v4 + 112), _mm_xor_ps(v2, xmmword_33DFE0));
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %f", 34, 2, &dword_0, v10, v12, v4);
  v4;
  static os_log_type_t.info.getter();
  v6 = swift_allocObject(v11, 152, 7);
  v6[2] = 3;
  v6[3] = 6;
  v6[7] = &type metadata for Int;
  v6[8] = &protocol witness table for Int;
  v6[4] = 2;
  v6[12] = &type metadata for Int;
  v6[13] = &protocol witness table for Int;
  v6[9] = 1;
  v6[17] = &type metadata for Int;
  v6[18] = &protocol witness table for Int;
  v6[14] = currentFileIndex;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %d", 34, 2, &dword_0);
  v6;
  static os_log_type_t.info.getter();
  v7 = swift_allocObject(v11, 152, 7);
  v7[2] = 3;
  v7[3] = 6;
  v7[7] = &type metadata for Int;
  v7[8] = &protocol witness table for Int;
  v7[4] = 2;
  v7[12] = &type metadata for Int;
  v7[13] = &protocol witness table for Int;
  v7[9] = 2;
  v8 = *v9;
  v7[17] = &type metadata for Int;
  v7[18] = &protocol witness table for Int;
  v7[14] = v8;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %d", 34, 2, &dword_0);
  v7;
}

void *specialized EnumeratedSequence.makeIterator()(uint64_t a1)
{
  v2 = -(-1 << *(a1 + 32));
  v3 = ~(-1 << v2);
  if (v2 >= 64)
  {
    v3 = -1;
  }

  v4 = *(a1 + 64) & v3;
  v5 = ~(-1 << *(a1 + 32));
  *result = a1;
  result[1] = a1 + 64;
  result[2] = v5;
  result[3] = 0;
  result[4] = v4;
  result[5] = 0;
  return result;
}

uint64_t specialized EnumeratedSequence.Iterator.next()()
{
  v1 = v0[3];
  v2 = v0[4];
  if (!v2)
  {
    v10 = v1 + 1;
    if (__OFADD__(1, v1))
    {
      BUG();
    }

    v11 = (v0[2] + 64) >> 6;
    if (v10 >= v11)
    {
      v13 = v0[3];
    }

    else
    {
      v12 = v0[1];
      v2 = *(v12 + 8 * v10);
      if (v2)
      {
        v3 = v1 + 1;
        goto LABEL_3;
      }

      v13 = v1 + 2;
      if (v1 + 2 >= v11)
      {
        v13 = v1 + 1;
      }

      else
      {
        v2 = *(v12 + 8 * v10 + 8);
        if (v2)
        {
          v3 = v1 + 2;
          goto LABEL_3;
        }

        v3 = v1 + 3;
        if (v1 + 3 < v11)
        {
          v2 = *(v12 + 8 * v10 + 16);
          if (v2)
          {
            goto LABEL_3;
          }

          v15 = v1 + 4;
          v13 = v1 + 3;
          if (v1 + 4 < v11)
          {
            v2 = *(v12 + 8 * v10 + 24);
            if (v2)
            {
LABEL_20:
              v3 = v15;
              goto LABEL_3;
            }

            v3 = v1 + 5;
            v13 = v1 + 4;
            if (v1 + 5 < v11)
            {
              v2 = *(v12 + 8 * v10 + 32);
              if (v2)
              {
                goto LABEL_3;
              }

              v15 = v1 + 6;
              v13 = v1 + 5;
              if (v1 + 6 < v11)
              {
                v2 = *(v12 + 8 * v10 + 40);
                if (v2)
                {
                  goto LABEL_20;
                }

                v3 = v1 + 7;
                v13 = v1 + 6;
                if (v1 + 7 < v11)
                {
                  v2 = *(v12 + 8 * v10 + 48);
                  if (v2)
                  {
                    goto LABEL_3;
                  }

                  v13 = v11 - 1;
                  v16 = v1 + 8;
                  while (v16 < v11)
                  {
                    v2 = *(v12 + 8 * v16++);
                    if (v2)
                    {
                      v1 = v16 - 1;
                      goto LABEL_2;
                    }
                  }
                }
              }
            }
          }
        }
      }
    }

    v0[3] = v13;
    v0[4] = 0;
    return 0;
  }

LABEL_2:
  v3 = v1;
LABEL_3:
  _BitScanForward64(&v4, v2);
  v5 = *(*v0 + 48);
  v6 = (v3 << 10) | (16 * v4);
  v7 = *(v5 + v6);
  v8 = *(v5 + v6 + 8);
  v0[3] = v3;
  v0[4] = v2 & (v2 - 1);
  v9 = v0[5];
  if (__OFADD__(1, v9))
  {
    BUG();
  }

  v0[5] = v9 + 1;
  v8;
  return v9;
}

{
  v2 = v0;
  v3 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for MetricsKey?) - 8) + 64);
  v4 = alloca(v3);
  v5 = alloca(v3);
  v6 = type metadata accessor for MetricsKey(0);
  v7 = *(v6 - 8);
  v8 = *(v7 + 64);
  v9 = alloca(v8);
  v10 = alloca(v8);
  v41 = &v39;
  v11 = *v1;
  v12 = v1[1];
  v13 = v1[2];
  v14 = v1[3];
  v15 = v1[4];
  v42 = v2;
  v43 = v7;
  v44 = v12;
  v40 = v13;
  if (v15)
  {
    v16 = v14;
LABEL_3:
    _BitScanForward64(&v17, v15);
    v45 = v15 & (v15 - 1);
    v18 = v6;
    v19 = v11;
    (*(v7 + 16))(&v39, *(v11 + 56) + *(v7 + 72) * (v17 | (v16 << 6)), v6);
    v46 = v16;
    v20 = 0;
    goto LABEL_10;
  }

  v21 = v14 + 1;
  if (__OFADD__(1, v14))
  {
    BUG();
  }

  v22 = (v13 + 64) >> 6;
  if (v21 >= v22)
  {
    v45 = 0;
    v46 = v14;
    v20 = 1;
LABEL_9:
    v18 = v6;
    v19 = v11;
    goto LABEL_10;
  }

  v15 = *(v12 + 8 * v21);
  if (v15)
  {
    v16 = v14 + 1;
    goto LABEL_3;
  }

  v16 = v14 + 2;
  if (v14 + 2 >= v22)
  {
    v45 = 0;
    v20 = 1;
    v46 = v21;
    goto LABEL_9;
  }

  v15 = *(v12 + 8 * v21 + 8);
  if (v15)
  {
    goto LABEL_3;
  }

  v37 = v14 + 3;
  if (v14 + 3 >= v22)
  {
    goto LABEL_29;
  }

  v15 = *(v12 + 8 * v21 + 16);
  if (v15)
  {
LABEL_19:
    v16 = v37;
    goto LABEL_3;
  }

  v16 = v14 + 4;
  if (v14 + 4 >= v22)
  {
    v45 = 0;
    v20 = 1;
    v46 = v21 + 2;
    goto LABEL_9;
  }

  v15 = *(v12 + 8 * v21 + 24);
  if (v15)
  {
    goto LABEL_3;
  }

  v37 = v14 + 5;
  if (v14 + 5 >= v22)
  {
LABEL_29:
    v45 = 0;
    v20 = 1;
    v46 = v16;
    goto LABEL_9;
  }

  v15 = *(v12 + 8 * v21 + 32);
  if (v15)
  {
    goto LABEL_19;
  }

  if (v14 + 6 >= v22)
  {
    v45 = 0;
    v20 = 1;
    v46 = v21 + 4;
    v19 = v11;
    v18 = v6;
  }

  else
  {
    v18 = v6;
    v15 = *(v44 + 8 * v21 + 40);
    if (v15)
    {
      v16 = v14 + 6;
LABEL_28:
      v7 = v43;
      goto LABEL_3;
    }

    v16 = v14 + 7;
    if (v14 + 7 >= v22)
    {
      v45 = 0;
      v20 = 1;
      v46 = v21 + 5;
      v19 = v11;
    }

    else
    {
      v15 = *(v44 + 8 * v21 + 48);
      v7 = v43;
      if (v15)
      {
        goto LABEL_3;
      }

      v38 = v14 + 8;
      while (v38 < v22)
      {
        v15 = *(v44 + 8 * v38++);
        if (v15)
        {
          v16 = v38 - 1;
          goto LABEL_28;
        }
      }

      v20 = 1;
      v46 = v22 - 1;
      v19 = v11;
      v45 = 0;
    }
  }

LABEL_10:
  __swift_storeEnumTagSinglePayload(&v39, v20, 1, v18);
  *v1 = v19;
  v1[1] = v44;
  v1[2] = v40;
  v1[3] = v46;
  v1[4] = v45;
  if (__swift_getEnumTagSinglePayload(&v39, 1, v18) == 1)
  {
    outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(&v39, &demangling cache variable for type metadata for MetricsKey?);
    v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey));
    v24 = v42;
    v25 = 1;
    v26 = v23;
  }

  else
  {
    v27 = v18;
    v28 = *(v43 + 32);
    v29 = v41;
    v28(v41, &v39, v27);
    v44 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey));
    v30 = v27;
    v31 = v42;
    v32 = v42 + *(v44 + 48);
    v33 = v1[5];
    *v42 = v33;
    v28(v32, v29, v30);
    v34 = __OFADD__(1, v33);
    v35 = v33 + 1;
    if (v34)
    {
      BUG();
    }

    v1[5] = v35;
    v24 = v31;
    v25 = 0;
    v26 = v44;
  }

  return __swift_storeEnumTagSinglePayload(v24, v25, 1, v26);
}

{
  v2 = v0;
  *&v8 = *v1;
  BYTE8(v8) = *(v1 + 8);
  outlined copy of Result<_DataTable, Error>(*v1, SBYTE8(v8));
  v3 = MLDataTable.size.getter();
  result = outlined consume of Result<_DataTable, Error>(v8, SBYTE8(v8));
  v5 = *(v1 + 16);
  if (v5 == v3)
  {
    *(v2 + 16) = 0;
    *v2 = 0;
  }

  else
  {
    MLDataTable.Rows.subscript.getter(*(v1 + 16));
    *(v1 + 16) = specialized RandomAccessCollection<>.index(after:)(v5, *v1, *(v1 + 8));
    v6 = *(v1 + 24);
    *v2 = v6;
    *(v2 + 8) = v8;
    *(v2 + 24) = v9;
    v7 = __OFADD__(1, v6);
    result = v6 + 1;
    if (v7)
    {
      BUG();
    }

    *(v1 + 24) = result;
  }

  return result;
}

uint64_t specialized EnumeratedSequence.Iterator.next()(double a1)
{
  v3 = v2;
  v4 = v1;
  v5 = *v2;
  result = CMLSequence.size.getter();
  v7 = v3[1];
  if (v7 == result)
  {
    *v4 = 0;
    *(v4 + 16) = 0;
    *(v4 + 24) = -1;
  }

  else
  {
    v8 = CMLSequence.value(at:)(v3[1]);
    MLDataValue.init(_:)(v8, a1);
    v9 = CMLSequence.size.getter();
    if (v7 < 0 || v7 >= v9)
    {
      BUG();
    }

    v3[1] = v7 + 1;
    v10 = v3[2];
    *v4 = v10;
    *(v4 + 8) = v12;
    *(v4 + 24) = v13;
    v11 = __OFADD__(1, v10);
    result = v10 + 1;
    if (v11)
    {
      BUG();
    }

    v3[2] = result;
  }

  return result;
}

Swift::Void __swiftcall log(_:type:)(Swift::String _, os_log_type_t type)
{
  v7 = type;
  v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
  v3 = swift_allocObject(v2, 64, 7);
  v3[1]._countAndFlagsBits = 1;
  v3[1]._object = &dword_0 + 2;
  v3[3]._object = &type metadata for String;
  v3[2] = _;
  _._object;
  print(_:separator:terminator:)(v3, 32, 0xE100000000000000, 10, 0xE100000000000000);
  v3;
  type metadata accessor for OS_os_log();
  v4 = static OS_os_log.default.getter(0);
  v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  v6 = swift_allocObject(v5, 72, 7);
  v6[1]._countAndFlagsBits = 1;
  v6[1]._object = &dword_0 + 2;
  v6[3]._object = &type metadata for String;
  v6[4]._countAndFlagsBits = lazy protocol witness table accessor for type String and conformance String();
  v6[2] = _;
  _._object;
  os_log(_:dso:log:type:_:)("%@\n", 3, 2, &dword_0, v4, v7, v6);

  v6;
}

Swift::String __swiftcall getOSVersion()()
{
  v22 = objc_opt_self(NSProcessInfo);
  v0 = [v22 processInfo];
  v1 = v0;
  objc_msgSend_stret(&v23, v1, "operatingSystemVersion");
  countAndFlagsBits = v23._countAndFlagsBits;

  v23._countAndFlagsBits = countAndFlagsBits;
  v3._countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  object = v3._object;
  v23 = v3;
  v3._object;
  v5._countAndFlagsBits = 46;
  v5._object = 0xE100000000000000;
  String.append(_:)(v5);
  object;
  v6 = v23;
  v7 = [v22 processInfo];
  v8 = v7;
  objc_msgSend_stret(&v23, v8, "operatingSystemVersion");
  v9 = v23._object;

  v23._countAndFlagsBits = v9;
  v10 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  v12 = v11;
  v23 = v6;
  v6._object;
  v5._countAndFlagsBits = v10;
  v5._object = v12;
  String.append(_:)(v5);
  v6._object;
  v12;
  v13 = v23._object;
  v23._object;
  v5._countAndFlagsBits = 46;
  v5._object = 0xE100000000000000;
  String.append(_:)(v5);
  v13;
  v14 = v23;
  v15 = [v22 processInfo];
  v16 = v15;
  objc_msgSend_stret(&v23, v16, "operatingSystemVersion");
  v17 = v24;

  v23._countAndFlagsBits = v17;
  v18 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  v20 = v19;
  v23 = v14;
  v14._object;
  v5._countAndFlagsBits = v18;
  v5._object = v20;
  String.append(_:)(v5);
  v14._object;
  v20;
  return v23;
}

uint64_t TrainingTablePrinter.print(_:)(uint64_t a1, __m128 a2)
{
  v33 = v2;
  v37 = a1;
  v38 = type metadata accessor for MetricsKey(0);
  v36 = *(v38 - 8);
  v3 = *(v36 + 64);
  v4 = alloca(v3);
  v5 = alloca(v3);
  v6 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey)?) - 8) + 64);
  v7 = alloca(v6);
  v8 = alloca(v6);
  v32 = v30;
  v9 = alloca(v6);
  v10 = alloca(v6);
  v39 = type metadata accessor for TrainingTablePrinter(0);
  v40 = *(v2 + *(v39 + 20));
  LOBYTE(v41) = static os_log_type_t.info.getter();
  v11 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<CVarArg>);
  v12 = swift_allocObject(v11, 152, 7);
  v12[2] = 3;
  v12[3] = 6;
  v12[7] = &type metadata for Int;
  v12[8] = &protocol witness table for Int;
  v12[4] = 2;
  v12[12] = &type metadata for Int;
  v12[13] = &protocol witness table for Int;
  v12[9] = 0;
  v13 = Event.itemCount.getter();
  v12[17] = &type metadata for Int;
  v12[18] = &protocol witness table for Int;
  v12[14] = v13;
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %d", 34, 2, &dword_0);
  v12;
  v42 = static os_log_type_t.info.getter();
  v41 = v11;
  v14 = swift_allocObject(v11, 152, 7);
  *(v14 + 16) = 3;
  *(v14 + 24) = 6;
  *(v14 + 56) = &type metadata for Int;
  *(v14 + 64) = &protocol witness table for Int;
  *(v14 + 32) = 2;
  *(v14 + 96) = &type metadata for Int;
  *(v14 + 104) = &protocol witness table for Int;
  *(v14 + 72) = 1;
  v15 = v33;
  *a2.i64 = Date.timeIntervalSinceNow.getter();
  *(v14 + 136) = &type metadata for Double;
  *(v14 + 144) = &protocol witness table for Double;
  _mm_storel_ps((v14 + 112), _mm_xor_ps(a2, xmmword_33DFE0));
  os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %f", 34, 2, &dword_0, v40, v42, v14);
  v14;
  v16 = *(v15 + *(v39 + 24));
  specialized EnumeratedSequence.makeIterator()(v16);
  v16;
  while (1)
  {
    v17 = v32;
    specialized EnumeratedSequence.Iterator.next()();
    outlined init with take of (offset: Int, element: MetricsKey)?(v17, v30);
    v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey));
    if (__swift_getEnumTagSinglePayload(v30, 1, v18) == 1)
    {
      return outlined consume of [String : [Double]].Iterator._Variant(v30[1]);
    }

    v19 = v30[0];
    (*(v36 + 32))(v30, v30 + *(v18 + 48), v38);
    v20 = Event.metrics.getter();
    if (*(v20 + 16) && (v21 = specialized __RawDictionaryStorage.find<A>(_:)(v30), (v22 & 1) != 0))
    {
      outlined init with copy of Any(*(v20 + 56) + 32 * v21, &v34);
    }

    else
    {
      v35 = 0;
      v34 = 0;
    }

    v20;
    if (!*(&v35 + 1))
    {
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(&v34, &demangling cache variable for type metadata for Sendable?);
LABEL_14:
      *&v34 = 0;
      *(&v34 + 1) = 0xE000000000000000;
      _StringGuts.grow(_:)(32);
      v29._object = "gUtilities.swift" + 0x8000000000000000;
      v29._countAndFlagsBits = 0xD00000000000001DLL;
      String.append(_:)(v29);
      _print_unlocked<A, B>(_:_:)(v30, &v34, v38, &type metadata for DefaultStringInterpolation, &protocol witness table for DefaultStringInterpolation);
      v29._countAndFlagsBits = 46;
      v29._object = 0xE100000000000000;
      String.append(_:)(v29);
      _assertionFailure(_:_:file:line:flags:)("Fatal error", 11, 2, v34, *(&v34 + 1), "CreateML/_LoggingUtilities.swift", 32, 2, 103, 0);
      BUG();
    }

    v23 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Sendable);
    if (!swift_dynamicCast(&v31, &v34, v23, &type metadata for Double, 6))
    {
      goto LABEL_14;
    }

    v39 = v31;
    v24 = static os_log_type_t.info.getter();
    v25 = swift_allocObject(v41, 152, 7);
    v25[2] = 3;
    v25[3] = 6;
    v25[7] = &type metadata for Int;
    v25[8] = &protocol witness table for Int;
    v25[4] = 2;
    v26 = __OFADD__(2, v19);
    v27 = v19 + 2;
    if (v26)
    {
      BUG();
    }

    v25[12] = &type metadata for Int;
    v25[13] = &protocol witness table for Int;
    v25[9] = v27;
    v25[17] = &type metadata for Double;
    v25[18] = &protocol witness table for Double;
    v25[14] = v39;
    os_log(_:dso:log:type:_:)("event: %lu, column: %lu, value: %f", 34, 2, &dword_0, v40, v24, v25);
    v25;
    (*(v36 + 8))(v30, v38);
  }
}

uint64_t outlined init with take of (offset: Int, element: MetricsKey)?(uint64_t a1, uint64_t a2)
{
  v2 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (offset: Int, element: MetricsKey)?);
  (*(*(v2 - 8) + 32))(a2, a1, v2);
  return a2;
}

uint64_t lazy protocol witness table accessor for type MetricsKey and conformance MetricsKey()
{
  result = lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey;
  if (!lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey)
  {
    v1 = type metadata accessor for MetricsKey(255);
    result = swift_getWitnessTable(&protocol conformance descriptor for MetricsKey, v1);
    lazy protocol witness table cache variable for type MetricsKey and conformance MetricsKey = result;
  }

  return result;
}

void *initializeBufferWithCopyOfBuffer for _TablePrinter(void *a1, char *a2, int *a3)
{
  v3 = a1;
  v4 = *(*(a3 - 1) + 80);
  if ((v4 & 0x20000) != 0)
  {
    v12 = *a2;
    *v3 = *a2;
    v3 = (v12 + ((v4 + 16) & ~v4));
    v12;
  }

  else
  {
    *a1 = *a2;
    v6 = a3[5];
    v7 = type metadata accessor for Date(0);
    (*(*(v7 - 8) + 16))(a1 + v6, &a2[v6], v7);
    v8 = a3[6];
    v9 = *&a2[v8];
    *(v3 + v8) = v9;
    v10 = a3[7];
    *(v3 + v10) = *&a2[v10];
    v11 = *&a2[v10 + 8];
    *(v3 + v10 + 8) = v11;
    v9;
    v11;
  }

  return v3;
}

uint64_t destroy for _TablePrinter(uint64_t a1, int *a2)
{
  v2 = a1 + a2[5];
  v3 = type metadata accessor for Date(0);
  (*(*(v3 - 8) + 8))(v2, v3);

  return *(a1 + a2[7] + 8);
}

char *initializeWithCopy for _TablePrinter(char *a1, char *a2, int *a3)
{
  *a1 = *a2;
  v5 = a3[5];
  v6 = type metadata accessor for Date(0);
  (*(*(v6 - 8) + 16))(&a1[v5], &a2[v5], v6);
  v7 = a3[6];
  v8 = *&a2[v7];
  *&a1[v7] = v8;
  v9 = a3[7];
  *&a1[v9] = *&a2[v9];
  v10 = *&a2[v9 + 8];
  *&a1[v9 + 8] = v10;
  v8;
  v10;
  return a1;
}

char *assignWithCopy for _TablePrinter(char *a1, char *a2, int *a3)
{
  *a1 = *a2;
  v5 = a3[5];
  v6 = type metadata accessor for Date(0);
  (*(*(v6 - 8) + 24))(&a1[v5], &a2[v5], v6);
  v7 = a3[6];
  v8 = *&a2[v7];
  v9 = *&a1[v7];
  *&a1[v7] = v8;
  v8;

  v10 = a3[7];
  *&a1[v10] = *&a2[v10];
  v11 = *&a2[v10 + 8];
  v12 = *&a1[v10 + 8];
  *&a1[v10 + 8] = v11;
  v11;
  v12;
  return a1;
}

char *initializeWithTake for _TablePrinter(char *a1, char *a2, int *a3)
{
  *a1 = *a2;
  v4 = a3[5];
  v5 = type metadata accessor for Date(0);
  (*(*(v5 - 8) + 32))(&a1[v4], &a2[v4], v5);
  *&a1[a3[6]] = *&a2[a3[6]];
  *&a1[a3[7]] = *&a2[a3[7]];
  return a1;
}

char *assignWithTake for _TablePrinter(char *a1, char *a2, int *a3)
{
  *a1 = *a2;
  v5 = a3[5];
  v6 = type metadata accessor for Date(0);
  (*(*(v6 - 8) + 40))(&a1[v5], &a2[v5], v6);
  v7 = a3[6];
  v8 = *&a1[v7];
  *&a1[v7] = *&a2[v7];

  v9 = a3[7];
  *&a1[v9] = *&a2[v9];
  v10 = *&a1[v9 + 8];
  *&a1[v9 + 8] = *&a2[v9 + 8];
  v10;
  return a1;
}

uint64_t sub_2B148B(uint64_t a1, unsigned int a2, uint64_t a3)
{
  v4 = 0;
  v5 = type metadata accessor for Date(0);
  if (*(*(v5 - 8) + 84) == a2)
  {
    return __swift_getEnumTagSinglePayload(*(a3 + 20) + a1, a2, v5);
  }

  if ((*(a1 + *(a3 + 24)) & 0xFFFFFFFF00000001) == 0)
  {
    return (*(a1 + *(a3 + 24)) >> 1) + 1;
  }

  return v4;
}

uint64_t sub_2B150D(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  v6 = type metadata accessor for Date(0);
  if (*(*(v6 - 8) + 84) == a3)
  {
    return __swift_storeEnumTagSinglePayload(*(a4 + 20) + a1, a2, a2, v6);
  }

  result = *(a4 + 24);
  *(a1 + result) = 2 * (a2 - 1);
  return result;
}

uint64_t type metadata completion function for _TablePrinter(uint64_t a1)
{
  v3[0] = &value witness table for Builtin.Int64 + 64;
  result = type metadata accessor for Date(319);
  if (v2 <= 0x3F)
  {
    v3[1] = *(result - 8) + 64;
    v3[2] = &value witness table for Builtin.UnknownObject + 64;
    v3[3] = &unk_348D58;
    swift_initStructMetadata(a1, 256, 4, v3, a1 + 16);
    return 0;
  }

  return result;
}

void *MLActionClassifier.DataSource.videosWithAnnotations()(__m128 a1)
{
  *&v160 = v2;
  *v171 = v3;
  v156 = v1;
  v166._object = type metadata accessor for DataFrame(0);
  v169._countAndFlagsBits = *(v166._object - 1);
  v4 = *(v169._countAndFlagsBits + 64);
  v5 = alloca(v4);
  v6 = alloca(v4);
  ML14_UntypedColumnC_s5Error_pTt1g5 = __src;
  v7 = alloca(v4);
  v8 = alloca(v4);
  *v165 = __src;
  v9 = type metadata accessor for UTType(0);
  v10 = *(v9 - 8);
  v11 = *(v10 + 64);
  v12 = alloca(v11);
  v13 = alloca(v11);
  *v161 = __src;
  v14 = alloca(v11);
  v15 = alloca(v11);
  v162._countAndFlagsBits = __src;
  *v167 = type metadata accessor for URL(0);
  named = *(*v167 - 8);
  v16 = *(named + 64);
  v17 = alloca(v16);
  v18 = alloca(v16);
  v158 = __src;
  v19 = alloca(v16);
  v20 = alloca(v16);
  v162._object = __src;
  v21 = alloca(v16);
  v22 = alloca(v16);
  v159 = __src;
  v23 = alloca(v16);
  v24 = alloca(v16);
  *v164 = __src;
  v25 = alloca(v16);
  v26 = alloca(v16);
  v166._countAndFlagsBits = __src;
  v27 = alloca(v16);
  v28 = alloca(v16);
  *v163 = __src;
  v29 = type metadata accessor for MLActionClassifier.DataSource(0);
  v30 = *(*(v29 - 8) + 64);
  v31 = alloca(v30);
  v32 = alloca(v30);
  outlined init with copy of MLActionClassifier.DataSource(*v171, __src);
  switch(swift_getEnumCaseMultiPayload(__src, v29))
  {
    case 0u:
      v33 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      v34 = __src + v33[12];
      v35 = v33[16];
      v166._countAndFlagsBits = *(__src + v35);
      *v171 = *(__src + v35 + 8);
      v36 = v33[20];
      *v163 = *(__src + v36);
      *v165 = *(__src + v36 + 8);
      v37 = v33[24];
      *v161 = *(__src + v37);
      v166._object = *(__src + v37 + 8);
      v38 = v33[28];
      v162._countAndFlagsBits = *(__src + v38);
      v169._countAndFlagsBits = *(__src + v38 + 8);
      v39 = *(named + 32);
      v40 = *v167;
      v39(*v164, __src, *v167);
      v41 = v159;
      v39(v159, v34, v40);
      object = v162._object;
      (*(named + 16))(v162._object, v41, v40);
      LOBYTE(__src[0]) = 1;
      *(&__src[0] + 1) = 44;
      __src[1] = 0xE100000000000000;
      *&__src[2] = 0xE000000000000000;
      *(&__src[2] + 1) = 92;
      *&__src[3] = 0xE100000000000000;
      BYTE8(__src[3]) = 1;
      *&__src[4] = 34;
      *(&__src[4] + 1) = 0xE100000000000000;
      LOBYTE(__src[5]) = 1;
      *(&__src[5] + 1) = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
      *&__src[6] = 10;
      *(&__src[6] + 1) = 0xE100000000000000;
      __src[7] = 0;
      LOBYTE(__src[8]) = 1;
      *(&__src[8] + 1) = 0;
      LOBYTE(__dst[0]) = 1;
      LOBYTE(v137) = 1;
      v138 = 44;
      v139 = 0xE100000000000000;
      v140 = 0;
      v141 = 0xE000000000000000;
      v142 = 92;
      v143 = 0xE100000000000000;
      v144 = 1;
      v145 = 34;
      v146 = 0xE100000000000000;
      v147 = 1;
      v148 = &outlined read-only object #0 of default argument 1 of MLDataTable.init(contentsOf:options:);
      v149 = 10;
      v150 = 0xE100000000000000;
      v151 = 0;
      v152 = 1;
      v153 = 0;
      outlined retain of MLDataTable.ParsingOptions(__src);
      outlined release of MLDataTable.ParsingOptions(&v137, 92);
      memcpy(__dst, __src, sizeof(__dst));
      v43 = v160;
      MLDataTable.init(contentsOf:options:)(object, __dst);
      v44 = *v167;
      v45 = *v164;
      if (v43)
      {
        v46 = *(named + 8);
        v46(v159, *v167);
        *v165;
        *v171;
        v166._object;
        v169._countAndFlagsBits;
        return v46(v45, v44);
      }

      v169._object = v154;
      LOBYTE(v170) = v155;
      v81._countAndFlagsBits = v166._countAndFlagsBits;
      v81._object = *v171;
      MLDataTable.subscript.getter(v81);
      v82 = *&__dst[0];
      v83 = BYTE8(__dst[0]);
      if (BYTE8(__dst[0]) || (outlined copy of Result<_DataTable, Error>(*&__dst[0], 0), v162._object = v82, _UntypedColumn.type.getter(), v82 = v162._object, outlined consume of Result<_DataTable, Error>(v162._object, 0), v154 != 2))
      {
        outlined consume of Result<_DataTable, Error>(v82, v83);
        *v165;
        v166._object;
        v169._countAndFlagsBits;
        *&__dst[0] = 0;
        *(&__dst[0] + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(26);
        *(&__dst[0] + 1);
        *&__dst[0] = 0x206E6D756C6F43;
        *(&__dst[0] + 1) = 0xE700000000000000;
        v104._countAndFlagsBits = v166._countAndFlagsBits;
        v105 = *v171;
        v104._object = *v171;
        String.append(_:)(v104);
        v105;
        v104._countAndFlagsBits = 0xD000000000000011;
        String.append(_:)(v104);
        v160 = __dst[0];
        v104._object = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v104._object, 0, 0);
        *v106 = v160;
        *(v106 + 16) = 0;
        *(v106 + 32) = 0;
        *(v106 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v104._object);
        v107 = *(named + 8);
        v108 = v159;
        v109 = *v167;
LABEL_27:
        v107(v108, v109);
        v107(*v164, v109);
        return outlined consume of Result<_DataTable, Error>(v169._object, v170);
      }

      *&v160 = 0;
      outlined copy of Result<_DataTable, Error>(v82, 0);
      _UntypedColumn.valueAtIndex(index:)(0, 0.0);
      v85 = *(&__dst[0] + 1);
      v84 = *&__dst[0];
      if (LOBYTE(__dst[1]) != 2)
      {
        outlined consume of MLDataValue(*&__dst[0], *(&__dst[0] + 1), __dst[1]);
        v84 = 0;
        v85 = 0xE000000000000000;
      }

      outlined consume of Result<_DataTable, Error>(v162._object, 0);
      *&__dst[0] = v84;
      *(&__dst[0] + 1) = v85;
      v86 = String.init<A>(_:)(__dst, &type metadata for String, &protocol witness table for String, &protocol witness table for String);
      v88 = v87;
      URL.init(fileURLWithPath:)(v86, v87);
      v88;
      v89 = objc_opt_self(NSFileManager);
      v90 = [v89 defaultManager];
      v91 = v90;
      URL.path.getter(v90);
      v93 = v92;
      v94 = String._bridgeToObjectiveC()();
      v93;
      LOBYTE(v93) = [v91 fileExistsAtPath:v94];

      if (v93)
      {
        v95 = *v171;
        countAndFlagsBits = v169._countAndFlagsBits;
        v97 = v166._object;
        v98 = *v165;
        v99 = v166._countAndFlagsBits;
      }

      else
      {
        v113 = v162._object;
        outlined copy of Result<_DataTable, Error>(v162._object, 0);
        MLAA22MLDataValueConvertibleRzlEySayxGAA0C6ColumnVyxGcfCSS_Tt0B5 = _sSa8CreateMLAA22MLDataValueConvertibleRzlEySayxGAA0C6ColumnVyxGcfCSS_Tt0B5(v113, 0, 0.0);
        v115 = alloca(24);
        v116 = alloca(32);
        *&__src[1] = *v164;
        v117 = v160;
        v118 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lFSaySSG_SSs5NeverOTg5(partial apply for closure #1 in static _VideoUtilities.getVideoURLsAndAnnotations(from:), __src, MLAA22MLDataValueConvertibleRzlEySayxGAA0C6ColumnVyxGcfCSS_Tt0B5);
        *&v160 = v117;
        MLAA22MLDataValueConvertibleRzlEySayxGAA0C6ColumnVyxGcfCSS_Tt0B5;
        *&__dst[0] = v118;
        v119 = alloca(24);
        v120 = alloca(24);
        *&__src[1] = __dst;
        ML14_UntypedColumnC_s5Error_pTt1g5 = _ss6ResultOsRi_zrlE8catchingAByxq_Gxyq_YKXE_tcfC8CreateML14_UntypedColumnC_s5Error_pTt1g5(partial apply for specialized closure #1 in MLUntypedColumn.init<A>(_:));
        v122 = v121;
        *&__dst[0];
        v123 = *v171;
        v171[0];
        MLDataTable.willMutate()();
        *&__dst[0] = ML14_UntypedColumnC_s5Error_pTt1g5;
        BYTE8(__dst[0]) = v122 & 1;
        v99 = v166._countAndFlagsBits;
        MLDataTable.setColumnImpl(newColumn:named:)(__dst, v166._countAndFlagsBits, v123);
        v123;
        outlined consume of Result<_DataTable, Error>(*&__dst[0], SBYTE8(__dst[0]));
        if (!v170)
        {
          v124 = v169._object;
          outlined copy of Result<_DataTable, Error>(v169._object, 0);
          _DataTable.columnNamesDidChange()();
          outlined consume of Result<_DataTable, Error>(v124, 0);
        }

        countAndFlagsBits = v169._countAndFlagsBits;
        v97 = v166._object;
        v98 = *v165;
        v95 = *v171;
      }

      v125 = v160;
      v134._object = countAndFlagsBits;
      v134._countAndFlagsBits = v162._countAndFlagsBits;
      static _VideoUtilities.renameVideoTableColumns(table:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(&v169._object, v99, v95, *v163, v98, *v161, v97, v134);
      v126 = v95;
      v127 = named;
      if (v125)
      {
        v126;
        v98;
        v97;
        v169._countAndFlagsBits;
        outlined consume of Result<_DataTable, Error>(v162._object, 0);
        v107 = *(v127 + 8);
        v109 = *v167;
        v107(v158, *v167);
        v108 = v159;
        goto LABEL_27;
      }

      v126;
      v98;
      v97;
      v169._countAndFlagsBits;
      outlined consume of Result<_DataTable, Error>(v162._object, 0);
      v128 = *(v127 + 8);
      v129 = *v167;
      v128(v158, *v167);
      v128(v159, v129);
      v128(*v164, v129);
LABEL_36:
      result = v169._object;
      v130 = v170;
      v131 = v156;
      *v156 = v169._object;
      *(v131 + 8) = v130;
      return result;
    case 1u:
      v169._countAndFlagsBits = v9;
      *v171 = v10;
      v65 = v166._countAndFlagsBits;
      v56 = *v167;
      v57 = named;
      (*(named + 32))(v166._countAndFlagsBits, __src, *v167);
      v66 = *v161;
      static UTType.movie.getter();
      v67 = v160;
      v68 = static _FileUtilities.collectFilesLabeledByDirectoryName(at:type:)(v65, v66);
      if (v67)
      {
        (*(*v171 + 8))(*v161, v169._countAndFlagsBits);
        v61 = v166._countAndFlagsBits;
        return (*(v57 + 8))(v61, v56);
      }

      v100 = v68;
      (*(*v171 + 8))(*v161, v169._countAndFlagsBits);
      static _VideoUtilities.generateVideoTable(_:)(v100);
      v100;
      v111 = v138;
      v169._object = v137;
      LOBYTE(v170) = v138 & 1;
      LOBYTE(v138) = v138 & 1;
      outlined copy of Result<_DataTable, Error>(v137, v111);
      static _VideoUtilities.validateVideoInput(trainingData:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(&v137, 0x7461506F65646976, 0xE900000000000068, 0x6C6562616CLL, 0xE500000000000000, 0, 0, 0, 0);
      outlined consume of Result<_DataTable, Error>(v137, v138);
      v112 = v166._countAndFlagsBits;
      goto LABEL_29;
    case 2u:
      v169._countAndFlagsBits = v9;
      *v171 = v10;
      v55 = *v163;
      v56 = *v167;
      v57 = named;
      (*(named + 32))(*v163, __src, *v167);
      v58 = v162._countAndFlagsBits;
      static UTType.movie.getter();
      v59 = v160;
      v60 = static _FileUtilities.collectFilesLabeledByFileName(at:type:)(v55, v58);
      if (v59)
      {
        (*(*v171 + 8))(v162._countAndFlagsBits, v169._countAndFlagsBits);
        v61 = *v163;
        return (*(v57 + 8))(v61, v56);
      }

      v80 = v60;
      (*(*v171 + 8))(v162._countAndFlagsBits, v169._countAndFlagsBits);
      static _VideoUtilities.generateVideoTable(_:)(v80);
      v80;
      v110 = v138;
      v169._object = v137;
      LOBYTE(v170) = v138 & 1;
      LOBYTE(v138) = v138 & 1;
      outlined copy of Result<_DataTable, Error>(v137, v110);
      static _VideoUtilities.validateVideoInput(trainingData:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(&v137, 0x7461506F65646976, 0xE900000000000068, 0x6C6562616CLL, 0xE500000000000000, 0, 0, 0, 0);
      outlined consume of Result<_DataTable, Error>(v137, v138);
      v112 = *v163;
LABEL_29:
      (*(named + 8))(v112, v56);
      goto LABEL_36;
    case 3u:
      v62 = *(&__src[1] + 1);
      v63 = *(&__src[2] + 1);
      v64 = *(&__src[3] + 1);
      outlined consume of Result<_DataTable, Error>(*&__src[0], SBYTE8(__src[0]));
      v64;
      v63;
      v62;
      return MLDataTable.init()();
    case 4u:
      *v165 = *(&__src[1] + 1);
      *v167 = *&__src[1];
      v48 = *(&__src[2] + 1);
      v166._object = *&__src[2];
      v49 = *(&__src[3] + 1);
      *v164 = *&__src[3];
      v50 = *(&__src[4] + 1);
      v169._countAndFlagsBits = *&__src[4];
      v169._object = *&__src[0];
      LOBYTE(v170) = BYTE8(__src[0]) & 1;
      *v171 = *&__src[0];
      LODWORD(named) = DWORD2(__src[0]);
      outlined copy of Result<_DataTable, Error>(*&__src[0], SBYTE8(__src[0]));
      v51 = v49;
      v52 = *v165;
      v53 = *v167;
      *v167 = v48;
      v54 = v160;
      v132._object = v50;
      v132._countAndFlagsBits = v169._countAndFlagsBits;
      static _VideoUtilities.renameVideoTableColumns(table:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(&v169._object, v53, *v165, v166._object, v48, *v164, v51, v132);
      if (!v54)
      {
        v52;
        *v167;
        v50;
        v51;
        outlined consume of Result<_DataTable, Error>(*v171, named);
        goto LABEL_36;
      }

      v52;
      *v167;
      v50;
      v51;
      outlined consume of Result<_DataTable, Error>(*v171, named);
      return outlined consume of Result<_DataTable, Error>(v169._object, v170);
    case 5u:
      v69 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      *(__src + v69[12] + 8);
      *(__src + v69[16] + 8);
      *(__src + v69[20] + 8);
      (*(v169._countAndFlagsBits + 8))(__src, v166._object);
      return MLDataTable.init()();
    case 6u:
      v70 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      v71 = v70[12];
      v166._countAndFlagsBits = *(__src + v71);
      *v171 = *(__src + v71 + 8);
      v72 = v70[16];
      *v163 = *(__src + v72);
      *v164 = *(__src + v72 + 8);
      v73 = v70[20];
      *v161 = *(__src + v73);
      named = *(__src + v73 + 8);
      v74 = v70[24];
      v162._countAndFlagsBits = *(__src + v74);
      *v167 = *(__src + v74 + 8);
      v75 = *v165;
      v76 = v166._object;
      v77 = v169._countAndFlagsBits;
      (*(v169._countAndFlagsBits + 32))(*v165, __src, v166._object);
      v78 = ML14_UntypedColumnC_s5Error_pTt1g5;
      *a1.i64 = (*(v77 + 16))(ML14_UntypedColumnC_s5Error_pTt1g5, v75, v76);
      v79 = v160;
      MLDataTable.init(_:convertArraysToShapedArrays:)(v78, 0, a1);
      if (v79)
      {
        (*(v169._countAndFlagsBits + 8))(*v165, v166._object);
        *v164;
        *v171;
        named;
        return *v167;
      }

      v169._object = v137;
      LOBYTE(v170) = v138;
      v101 = *v164;
      v102 = *v167;
      v133._object = *v167;
      v133._countAndFlagsBits = v162._countAndFlagsBits;
      v103 = named;
      static _VideoUtilities.renameVideoTableColumns(table:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(&v169._object, v166._countAndFlagsBits, *v171, *v163, *v164, *v161, named, v133);
      (*(v169._countAndFlagsBits + 8))(*v165, v166._object);
      *v171;
      v101;
      v102;
      v103;
      goto LABEL_36;
  }
}

uint64_t type metadata accessor for MLActionClassifier.DataSource(uint64_t a1)
{
  result = type metadata singleton initialization cache for MLActionClassifier.DataSource;
  if (!type metadata singleton initialization cache for MLActionClassifier.DataSource)
  {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLActionClassifier.DataSource);
  }

  return result;
}

uint64_t outlined init with copy of MLActionClassifier.DataSource(uint64_t a1, uint64_t a2)
{
  v2 = type metadata accessor for MLActionClassifier.DataSource(0);
  (*(*(v2 - 8) + 16))(a2, a1, v2);
  return a2;
}

uint64_t _s11TabularData0B5FrameV8CreateMLE9expanding14keysColumnName06valueshI0ACSDySSSayxGG_S2StclufCSS_Tt3g5(uint64_t a1, uint64_t a2, uint64_t *a3, char *a4, uint64_t a5)
{
  v51 = a5;
  v52 = a4;
  v54 = a3;
  v53 = a2;
  v6 = a1;
  v46 = v5;
  v50 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  v47 = *(v50 - 8);
  v7 = *(v47 + 64);
  v8 = alloca(v7);
  v9 = alloca(v7);
  v10 = alloca(v7);
  v11 = alloca(v7);
  v55[0] = _swiftEmptyArrayStorage;
  v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for [String]);
  v13 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type [String] and conformance [A], &demangling cache variable for type metadata for [String], &protocol conformance descriptor for [A]);
  v49 = &v41;
  Column.init<A>(name:contents:)(v53, v54, v55, &type metadata for String, v12, v13);
  v55[0] = _swiftEmptyArrayStorage;
  v54 = &v41;
  v53 = v12;
  v42 = v13;
  Column.init<A>(name:contents:)(v52, v51, v55, &type metadata for String, v12, v13);
  swift_bridgeObjectRetain_n(a1, 2);
  v14 = specialized _copyCollectionToContiguousArray<A>(_:)(a1);
  a1;
  v55[0] = v14;
  specialized MutableCollection<>.sort(by:)(v55);
  a1;
  v15 = v55[0];
  v43 = *(v55[0] + 2);
  if (v43)
  {
    v48 = v55[0];
    v45 = v55[0] + 32;
    v16 = 0;
    v44 = a1;
    do
    {
      v17 = *&v45[16 * v16];
      v18 = *&v45[16 * v16 + 8];
      v19 = *(v6 + 16);
      v18;
      v20 = _swiftEmptyArrayStorage;
      if (v19)
      {
        v18;
        v21 = specialized __RawDictionaryStorage.find<A>(_:)(v17, v18);
        v22 = _swiftEmptyArrayStorage;
        if (v23)
        {
          v22 = *(*(v6 + 56) + 8 * v21);
          v22;
        }

        v18;
        v20 = v22;
      }

      v51 = v16;
      v52 = v20;
      v24 = *(v20 + 2);
      if (v24)
      {
        v25 = static Array._allocateBufferUninitialized(minimumCapacity:)(*(v20 + 2), &type metadata for String);
        v26 = v25;
        v25[2] = v24;
        v25[4] = v17;
        v25[5] = v18;
        if (v24 != 1)
        {
          v27 = v25;
          v28 = v25 + 6;
          v29 = v24 - 2;
          while (1)
          {
            *v28 = v17;
            v28[1] = v18;
            if (v29-- == 0)
            {
              break;
            }

            v28 += 2;
            v18;
          }

          v18;
          v26 = v27;
        }
      }

      else
      {
        v18;
        v26 = _swiftEmptyArrayStorage;
      }

      v16 = v51 + 1;
      v55[0] = v26;
      v31 = v53;
      v32 = v42;
      Column.append<A>(contentsOf:)(v55, v50, v53, v42);
      v26;
      v33 = v52;
      v55[0] = v52;
      Column.append<A>(contentsOf:)(v55, v50, v31, v32);
      v33;
      v6 = v44;
    }

    while (v16 != v43);
    v44;
    v34 = v48;
  }

  else
  {
    a1;
    v34 = v15;
  }

  DataFrame.init()(v34);
  v35 = v49;
  DataFrame.append<A>(column:)(v49, &type metadata for String);
  v36 = v54;
  DataFrame.append<A>(column:)(v54, &type metadata for String);
  v37 = *(v47 + 8);
  v38 = v36;
  v39 = v50;
  v37(v38, v50);
  return (v37)(v35, v39);
}

uint64_t MLActionClassifier.DataSource.keypointsWithAnnotations(targetFrameRate:)(__m128 a1)
{
  v85 = v2;
  v83 = a1.i64[0];
  v65 = v1;
  v71 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  v70 = *(v71 - 8);
  v4 = *(v70 + 64);
  v5 = alloca(v4);
  v6 = alloca(v4);
  v66 = &v64;
  v7 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?) - 8) + 64);
  v8 = alloca(v7);
  v9 = alloca(v7);
  v78 = &v64;
  v84 = type metadata accessor for AnyColumn(0);
  v77 = *(v84 - 1);
  v10 = v77[8];
  v11 = alloca(v10);
  v12 = alloca(v10);
  v72 = &v64;
  v13 = alloca(v10);
  v14 = alloca(v10);
  v81 = &v64;
  v15 = type metadata accessor for DataFrame(0);
  v86 = *(v15 - 8);
  v16 = *(v86 + 64);
  v17 = alloca(v16);
  v18 = alloca(v16);
  v74 = &v64;
  v19 = alloca(v16);
  v20 = alloca(v16);
  v87 = &v64;
  v21 = type metadata accessor for MLActionClassifier.DataSource(0);
  v22 = *(*(v21 - 8) + 64);
  v23 = alloca(v22);
  v24 = alloca(v22);
  outlined init with copy of MLActionClassifier.DataSource(v3, &v64);
  EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v64, v21);
  if (EnumCaseMultiPayload == 5)
  {
    v30 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
    v31 = v30[12];
    v68 = *(&v64 + v31);
    v82 = *(&v64 + v31 + 8);
    v32 = v30[16];
    v67 = *(&v64 + v32);
    v76 = *(&v64 + v32 + 8);
    v33 = v30[20];
    v34 = *(&v64 + v33);
    v83 = *(&v64 + v33 + 8);
    v75 = v15;
    (*(v86 + 32))(v87, &v64, v15);
    v35 = v81;
    v73 = v34;
    DataFrame.subscript.getter(v34, v83);
    v36 = AnyColumn.wrappedElementType.getter();
    v37 = v77[1];
    (v37)(v35, v84);
    if (v36 == &type metadata for String)
    {
      v69 = v37;
      v41 = v66;
      v42 = v73;
      v43 = v83;
      DataFrame.subscript.getter(v73, v83, &type metadata for String);
      v44 = v85;
      Column<A>.parseAsJSONArrays()();
      if (v44)
      {
        v38 = v87;
        v44;
        (*(v70 + 8))(v41, v71);
        v45 = v78;
        __swift_storeEnumTagSinglePayload(v78, 1, 1, v84);
        outlined destroy of AnyColumn?(v45);
        v85 = 0;
      }

      else
      {
        v85 = 0;
        (*(v70 + 8))(v41, v71);
        v46 = v84;
        __swift_storeEnumTagSinglePayload(v78, 0, 1, v84);
        v47 = v72;
        v48 = v46;
        v49 = v77;
        (v77[4])(v72, v78, v48);
        v50 = v47;
        v51 = v84;
        (v49[2])(v81, v50, v84);
        v43;
        v52 = v42;
        v38 = v87;
        DataFrame.subscript.setter(v81, v52, v43);
        (v69)(v72, v51);
      }
    }

    else
    {
      v38 = v87;
    }

    v53 = v74;
    v54 = v75;
    v55 = v86;
    *a1.i64 = (*(v86 + 16))(v74, v38, v75);
    v56 = v85;
    MLDataTable.init(_:convertArraysToShapedArrays:)(v53, 0, a1);
    if (v56)
    {
      (*(v55 + 8))(v38, v54);
      v83;
      v76;
      return v82;
    }

    v88 = v79;
    LOBYTE(v89) = v80;
    v57 = v73;
    v58 = v83;
    static MLActionClassifier.reformatKeypointsDataTable(table:featureColumn:)(&v88, v73, v83);
    v60 = v57;
    v61 = v76;
    static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)(&v88, v68, v82, v60, v58, v67, v76);
    v85 = 0;
    (*(v86 + 8))(v87, v75);
    v82;
    v61;
    v58;
  }

  else if (EnumCaseMultiPayload == 3)
  {
    v26 = v65;
    v77 = v66;
    v87 = v67;
    v81 = v68;
    v84 = v69;
    v27 = v70;
    v28 = v71;
    v88 = v64;
    LOBYTE(v89) = v65 & 1;
    v86 = v64;
    outlined copy of Result<_DataTable, Error>(v64, v65);
    v74 = v27;
    v29 = v85;
    static MLActionClassifier.reformatKeypointsDataTable(table:featureColumn:)(&v88, v27, v28);
    if (v29)
    {
      outlined consume of Result<_DataTable, Error>(v88, v89);
      v87;
      v84;
      v28;
      return outlined consume of Result<_DataTable, Error>(v86, v26);
    }

    v40 = v84;
    static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)(&v88, v77, v87, v74, v28, v81, v84);
    v87;
    v40;
    v28;
    outlined consume of Result<_DataTable, Error>(v86, v26);
  }

  else
  {
    type metadata accessor for MLActionClassifier.FeatureExtractor();
    v39 = v85;
    static MLActionClassifier.FeatureExtractor.extractFeatures(from:targetFrameRate:)(v3, v83);
    if (v39)
    {
      return outlined destroy of MLActionClassifier.DataSource(&v64);
    }

    v88 = v79;
    LOBYTE(v89) = v80;
    outlined destroy of MLActionClassifier.DataSource(&v64);
  }

  result = v88;
  v62 = v89;
  v63 = v65;
  *v65 = v88;
  *(v63 + 8) = v62;
  return result;
}

uint64_t MLActionClassifier.DataSource.extractKeypoints(targetFrameRate:)(double a1)
{
  v108 = v2;
  in._object = v3;
  *&in._countAndFlagsBits = a1;
  v101 = v1;
  v94 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<Data>);
  v93 = *(v94 - 8);
  v4 = *(v93 + 64);
  v5 = alloca(v4);
  v6 = alloca(v4);
  v85 = &v81;
  v91 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  v90 = *(v91 - 8);
  v7 = *(v90 + 64);
  v8 = alloca(v7);
  v9 = alloca(v7);
  v84 = &v81;
  v10 = *(*(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for AnyColumn?) - 8) + 64);
  v11 = alloca(v10);
  v12 = alloca(v10);
  v86 = &v81;
  v13 = alloca(v10);
  v14 = alloca(v10);
  v83 = &v81;
  v105 = type metadata accessor for AnyColumn(0);
  v99 = *(v105 - 1);
  v15 = *(v99 + 64);
  v16 = alloca(v15);
  v17 = alloca(v15);
  v95 = &v81;
  v18 = alloca(v15);
  v19 = alloca(v15);
  v92 = &v81;
  v20 = alloca(v15);
  v21 = alloca(v15);
  v100 = &v81;
  v22 = type metadata accessor for DataFrame(0);
  v23 = *(v22 - 8);
  v24 = *(v23 + 64);
  v25 = alloca(v24);
  v26 = alloca(v24);
  v104 = &v81;
  v27 = type metadata accessor for MLActionClassifier.DataSource(0);
  v28 = *(*(v27 - 8) + 64);
  v29 = alloca(v28);
  v30 = alloca(v28);
  outlined init with copy of MLActionClassifier.DataSource(in._object, &v81);
  EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v81, v27);
  if (EnumCaseMultiPayload == 5)
  {
    v37 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
    v38 = v37[12];
    v88 = *(&v81 + v38);
    v103 = *(&v81 + v38 + 8);
    v39 = v37[16];
    v87 = *(&v81 + v39);
    v98 = *(&v81 + v39 + 8);
    v40 = v37[20];
    v41 = *(&v81 + v40);
    in._object = *(&v81 + v40 + 8);
    v97 = v23;
    v42 = *(v23 + 32);
    v96 = v22;
    v89 = v42;
    v42(v104, &v81, v22);
    v43 = v100;
    in._countAndFlagsBits = v41;
    DataFrame.subscript.getter(v41, in._object);
    v44 = AnyColumn.wrappedElementType.getter();
    v45 = *(v99 + 8);
    v46 = v105;
    v45(v43, v105);
    if (v44 == &type metadata for String)
    {
      v102 = v45;
      v50 = v84;
      DataFrame.subscript.getter(in._countAndFlagsBits, in._object, &type metadata for String);
      v51 = v83;
      v52 = v108;
      Column<A>.parseAsJSONArrays()();
      if (!v52)
      {
        v108 = 0;
        (*(v90 + 8))(v50, v91);
        v67 = v51;
        v68 = v51;
        v69 = v105;
        __swift_storeEnumTagSinglePayload(v68, 0, 1, v105);
        v70 = v92;
        v71 = v67;
        v72 = v99;
        (*(v99 + 32))(v92, v71, v69);
        (*(v72 + 16))(v43, v70, v69);
        object = in._object;
        in._object;
        v74 = v43;
        countAndFlagsBits = in._countAndFlagsBits;
        v48 = object;
        DataFrame.subscript.setter(v74, in._countAndFlagsBits, object);
        v102(v92, v69);
        v57 = countAndFlagsBits;
        goto LABEL_18;
      }

      v48 = in._object;
      v52;
      (*(v90 + 8))(v50, v91);
      __swift_storeEnumTagSinglePayload(v51, 1, 1, v105);
      v53 = v51;
    }

    else
    {
      DataFrame.subscript.getter(in._countAndFlagsBits, in._object);
      v47 = AnyColumn.wrappedElementType.getter();
      v45(v43, v46);
      if (v47 != &type metadata for Data)
      {
        v48 = in._object;
LABEL_17:
        v57 = in._countAndFlagsBits;
LABEL_18:
        v58._countAndFlagsBits = v57;
        v58._object = v48;
        v59 = v104;
        DataFrame.flattenNestedArrays(in:shape:)(v58, &outlined read-only object #0 of MLActionClassifier.DataSource.extractKeypoints(targetFrameRate:));
        if (v60)
        {
          (*(v97 + 8))(v59, v96);
          v103;
          v61 = v98;
        }

        else
        {
          v62 = v57;
          v63 = v98;
          static _VideoUtilities.renameFeatureColumns(dataFrame:sessionIdColumn:featureColumn:labelColumn:)(v59, v88, v103, v62, v48, v87, v98);
          v89(v101, v59, v96);
          v103;
          v61 = v63;
        }

        v61;
        v36 = v48;
        return v36;
      }

      v102 = v45;
      v54 = v85;
      DataFrame.subscript.getter(in._countAndFlagsBits, in._object, &type metadata for Data);
      v55 = v86;
      v56 = v108;
      Column<A>.parseAsJSONArrays()();
      if (!v56)
      {
        v108 = 0;
        (*(v93 + 8))(v54, v94);
        v76 = v105;
        __swift_storeEnumTagSinglePayload(v55, 0, 1, v105);
        v77 = v95;
        v78 = v55;
        v79 = v99;
        (*(v99 + 32))(v95, v78, v76);
        (*(v79 + 16))(v100, v77, v76);
        v80 = in._object;
        in._object;
        v57 = in._countAndFlagsBits;
        v48 = v80;
        DataFrame.subscript.setter(v100, in._countAndFlagsBits, v80);
        v102(v95, v105);
        goto LABEL_18;
      }

      v48 = in._object;
      v56;
      (*(v93 + 8))(v54, v94);
      __swift_storeEnumTagSinglePayload(v55, 1, 1, v105);
      v53 = v55;
    }

    outlined destroy of AnyColumn?(v53);
    goto LABEL_17;
  }

  if (EnumCaseMultiPayload == 3)
  {
    v105 = v83;
    in._object = v84;
    v104 = v85;
    v32 = v86;
    v33 = v87;
    v34 = v88;
    v106 = v81;
    LOBYTE(v107) = v82;
    v35 = v108;
    static MLActionClassifier.reformatKeypointsDataTable(table:featureColumn:)(&v106, v87, v88);
    if (!v35)
    {
      static _VideoUtilities.renameFeatureTableColumns(table:sessionIdColumn:featureColumn:labelColumn:)(&v106, v105, in._object, v33, v34, v104, v32);
      v34;
      v32;
      in._object;
      v64 = v106;
      v65 = v107;
      v81 = v106;
      v82 = v107;
      outlined copy of Result<_DataTable, Error>(v106, v107);
      DataFrame.init(_:)(&v81);
      return outlined consume of Result<_DataTable, Error>(v64, v65);
    }

    outlined consume of Result<_DataTable, Error>(v106, v107);
    in._object;
    v32;
    v36 = v34;
    return v36;
  }

  type metadata accessor for MLActionClassifier.FeatureExtractor();
  v49 = v108;
  static MLActionClassifier.FeatureExtractor.extractFeatures(from:targetFrameRate:)(in._object, in._countAndFlagsBits);
  if (!v49)
  {
    v81 = v106;
    v82 = v107;
    DataFrame.init(_:)(&v81);
  }

  return outlined destroy of MLActionClassifier.DataSource(&v81);
}

uint64_t MLActionClassifier.DataSource.gatherAnnotatedFileNames()()
{
  v98 = v1;
  v97 = v0;
  v105 = type metadata accessor for DataFrame(0);
  v100 = *(v105 - 1);
  v3 = *(v100 + 64);
  v4 = alloca(v3);
  v5 = alloca(v3);
  v103 = &v93;
  v6 = alloca(v3);
  v7 = alloca(v3);
  v106 = &v93;
  v107 = type metadata accessor for UTType(0);
  v8 = *(v107 - 1);
  v9 = *(v8 + 64);
  v10 = alloca(v9);
  v11 = alloca(v9);
  v104 = &v93;
  v12 = alloca(v9);
  v13 = alloca(v9);
  v102 = &v93;
  v109 = type metadata accessor for URL(0);
  v110 = *(v109 - 1);
  v14 = v110[8];
  v15 = alloca(v14);
  v16 = alloca(v14);
  v99 = &v93;
  v17 = alloca(v14);
  v18 = alloca(v14);
  v108 = &v93;
  v19 = alloca(v14);
  v20 = alloca(v14);
  v101 = &v93;
  v21 = alloca(v14);
  v22 = alloca(v14);
  v96 = &v93;
  v23 = type metadata accessor for MLActionClassifier.DataSource(0);
  v24 = *(*(v23 - 8) + 64);
  v25 = alloca(v24);
  v26 = alloca(v24);
  v95 = v2;
  outlined init with copy of MLActionClassifier.DataSource(v2, &v93);
  switch(swift_getEnumCaseMultiPayload(&v93, v23))
  {
    case 0u:
      v27 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      v28 = &v93 + v27[12];
      v29 = v27[16];
      v103 = *(&v93 + v29);
      v107 = *(&v93 + v29 + 8);
      v30 = v27[20];
      v106 = *(&v93 + v30);
      v101 = *(&v93 + v30 + 8);
      v31 = v27[24];
      v100 = *(&v93 + v31);
      v102 = *(&v93 + v31 + 8);
      v32 = v27[28];
      v104 = *(&v93 + v32);
      v105 = *(&v93 + v32 + 8);
      v33 = v110[4];
      v34 = v109;
      v33(v108, &v93, v109);
      v35 = v99;
      v36 = v34;
      v37 = v107;
      v33(v99, v28, v36);
      v38 = v102;
      v39 = v35;
      v40 = v101;
      MLActionClassifier.DataSource.gatherAnnotatedFileNamesForDirectory(url:annotationFile:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(v108, v39, v103, v37, v106, v101, v100, v102, v104, v105);
      v40;
      v37;
      v38;
      v105;
      v41 = v110[1];
      v42 = v109;
      v41(v99, v109);
      return (v41)(v108, v42);
    case 1u:
      v64 = v101;
      (v110[4])(v101, &v93, v109);
      v65 = v104;
      static UTType.movie.getter();
      v66 = v98;
      v67 = static _FileUtilities.collectFilesLabeledByDirectoryName(at:type:)(v64, v65);
      if (v66)
      {
        (*(v8 + 8))(v104, v107);
        v59 = v101;
        return (v110[1])(v59, v109);
      }

      v86 = v67;
      (*(v8 + 8))(v104, v107);
      v87 = specialized _NativeDictionary.mapValues<A>(_:)(v86);
      v86;
      v84 = v97;
      _s11TabularData0B5FrameV8CreateMLE9expanding14keysColumnName06valueshI0ACSDySSSayxGG_S2StclufCSS_Tt3g5(v87, 0x6C6562616CLL, 0xE500000000000000, 0x7461506F65646976, 0xE900000000000068);
      v85 = v101;
      goto LABEL_20;
    case 2u:
      v55 = v96;
      (v110[4])(v96, &v93, v109);
      v56 = v102;
      static UTType.movie.getter();
      v57 = v98;
      v58 = static _FileUtilities.collectFilesLabeledByFileName(at:type:)(v55, v56);
      if (v57)
      {
        (*(v8 + 8))(v102, v107);
        v59 = v96;
        return (v110[1])(v59, v109);
      }

      v82 = v58;
      (*(v8 + 8))(v102, v107);
      v83 = specialized _NativeDictionary.mapValues<A>(_:)(v82);
      v82;
      v84 = v97;
      _s11TabularData0B5FrameV8CreateMLE9expanding14keysColumnName06valueshI0ACSDySSSayxGG_S2StclufCSS_Tt3g5(v83, 0x6C6562616CLL, 0xE500000000000000, 0x7461506F65646976, 0xE900000000000068);
      v85 = v96;
LABEL_20:
      (v110[1])(v85, v109);
      v90 = v84;
      v91 = v105;
      return __swift_storeEnumTagSinglePayload(v90, 0, 1, v91);
    case 3u:
      v60 = v96;
      v61 = v98;
      v62 = v100;
      outlined consume of Result<_DataTable, Error>(v93, v94);
      v62;
      v61;
      v60;
      v63 = v105;
      return __swift_storeEnumTagSinglePayload(v97, 1, 1, v63);
    case 4u:
      v44 = v94;
      v99 = v95;
      v101 = v96;
      v45 = v97;
      v46 = v98;
      v104 = v95;
      v110 = v100;
      v103 = v96;
      v109 = v102;
      LOBYTE(v94) = v94 & 1;
      v107 = v93;
      LODWORD(v102) = v44;
      outlined copy of Result<_DataTable, Error>(v93, v44);
      v47 = v106;
      DataFrame.init(_:)(&v93);
      v48 = v47;
      v49 = v101;
      v50 = v99;
      v96 = v45;
      v51 = v45;
      v108 = v46;
      v52 = v104;
      v53 = v98;
      static _VideoUtilities.validateVideoInput(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(v48, v99, v101, v51, v46, v104, v110, v103, v109);
      if (!v53)
      {
        static _VideoUtilities.renameVideoColumns(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(v106, v50, v49, v96, v108, v52, v110, v103, v109);
        outlined consume of Result<_DataTable, Error>(v107, v102);
        v108;
        v49;
        v110;
        v109;
        v88 = v97;
        v89 = v105;
        (*(v100 + 32))(v97, v106, v105);
        v90 = v88;
        v91 = v89;
        return __swift_storeEnumTagSinglePayload(v90, 0, 1, v91);
      }

      (*(v100 + 8))(v106, v105);
      outlined consume of Result<_DataTable, Error>(v107, v102);
      v108;
      v49;
      v110;
      v54 = v109;
      return v54;
    case 5u:
      v68 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
      *(&v93 + v68[12] + 8);
      *(&v93 + v68[16] + 8);
      *(&v93 + v68[20] + 8);
      v69 = v105;
      (*(v100 + 8))(&v93, v105);
      v63 = v69;
      return __swift_storeEnumTagSinglePayload(v97, 1, 1, v63);
    case 6u:
      v70 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
      v71 = v70[12];
      v99 = *(&v93 + v71);
      v109 = *(&v93 + v71 + 8);
      v72 = v70[16];
      v104 = *(&v93 + v72);
      v73 = *(&v93 + v72 + 8);
      v74 = v70[20];
      v101 = *(&v93 + v74);
      v110 = *(&v93 + v74 + 8);
      v75 = v70[24];
      v76 = *(&v93 + v75);
      v108 = *(&v93 + v75 + 8);
      v77 = v103;
      v78 = v105;
      v107 = *(v100 + 32);
      (v107)(v103, &v93, v105);
      v79 = v77;
      v80 = v101;
      v106 = v73;
      v81 = v98;
      v98 = v76;
      static _VideoUtilities.validateVideoInput(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(v79, v99, v109, v104, v73, v101, v110, v76, v108);
      if (v81)
      {
        (*(v100 + 8))(v103, v78);
        v109;
        v106;
        v108;
        v54 = v110;
        return v54;
      }

      else
      {
        static _VideoUtilities.renameVideoColumns(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(v103, v99, v109, v104, v106, v80, v110, v98, v108);
        v106;
        v109;
        v110;
        v108;
        v92 = v97;
        (v107)(v97, v103, v78);
        v90 = v92;
        v91 = v78;
        return __swift_storeEnumTagSinglePayload(v90, 0, 1, v91);
      }
  }
}

uint64_t MLActionClassifier.DataSource.gatherAnnotatedFileNamesForDirectory(url:annotationFile:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(uint64_t a1, void *a2, uint64_t a3, void *a4, uint64_t a5, void *a6, uint64_t a7, void *a8, uint64_t a9, void *a10)
{
  v150 = v10;
  v173 = a2;
  v152 = v11;
  v144 = a1;
  v145 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Column<String>);
  v146 = *(v145 - 8);
  v16 = *(v146 + 64);
  v17 = alloca(v16);
  v18 = alloca(v16);
  v147 = &v141;
  v156 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for FilledColumn<Column<String>>);
  v155 = *(v156 - 8);
  v19 = *(v155 + 64);
  v20 = alloca(v19);
  v21 = alloca(v19);
  v160 = &v141;
  v22 = *(*(type metadata accessor for CSVReadingOptions(0) - 8) + 64);
  v23 = alloca(v22);
  v24 = alloca(v22);
  v148 = &v141;
  v172 = type metadata accessor for CSVType(0);
  v163 = *(v172 - 8);
  v25 = *(v163 + 64);
  v26 = alloca(v25);
  v27 = alloca(v25);
  v157 = &v141;
  v28 = alloca(v25);
  v29 = alloca(v25);
  v170 = &v141;
  v30 = *(*(type metadata accessor for JSONReadingOptions(0) - 8) + 64);
  v31 = alloca(v30);
  v32 = alloca(v30);
  v161 = &v141;
  v153 = type metadata accessor for URL(0);
  v165 = *(v153 - 8);
  v33 = v165[8];
  v34 = alloca(v33);
  v35 = alloca(v33);
  v167 = &v141;
  v36 = alloca(v33);
  v37 = alloca(v33);
  v141 = &v141;
  v143 = type metadata accessor for JSONType(0);
  v175 = *(v143 - 8);
  v38 = *(v175 + 64);
  v39 = alloca(v38);
  v40 = alloca(v38);
  v174 = &v141;
  v41 = alloca(v38);
  v42 = alloca(v38);
  v171 = &v141;
  v166 = type metadata accessor for DataFrame(0);
  v162 = *(v166 - 8);
  v43 = *(v162 + 64);
  v44 = alloca(v43);
  v45 = alloca(v43);
  v149 = &v141;
  v46 = alloca(v43);
  v47 = alloca(v43);
  v142 = &v141;
  v48 = alloca(v43);
  v49 = alloca(v43);
  v154 = &v141;
  v50 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  v51 = swift_allocObject(v50, 64, 7);
  v51[2] = 2;
  v51[3] = 4;
  v164 = a3;
  v51[4] = a3;
  v51[5] = a4;
  v159 = a5;
  v51[6] = a5;
  v52 = v51;
  v51[7] = a6;
  v158 = a6;
  a4;
  a6;
  if (a8)
  {
    a8;
    v53 = 3;
    v52 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(1, 3, 1, v52);
    v52[2] = 3;
    v52[8] = a7;
    v52[9] = a8;
  }

  else
  {
    v53 = 2;
  }

  v168 = a4;
  if (a10)
  {
    v169 = v52;
    v54 = v52[3];
    a10;
    if (v54 >> 1 <= v53)
    {
      v52 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v54 >= 2, v53 + 1, 1, v169);
    }

    else
    {
      v52 = v169;
    }

    v52[2] = v53 + 1;
    v55 = 2 * v53;
    v52[v55 + 4] = a9;
    v52[v55 + 5] = a10;
  }

  v169 = v52;
  v56 = URL.pathExtension.getter();
  v58 = v57;
  if (!(v56 ^ 0x6E6F736A | v57 ^ 0xE400000000000000))
  {
    v57;
    goto LABEL_11;
  }

  v59 = _stringCompareWithSmolCheck(_:_:expecting:)(v56, v57, 1852797802, 0xE400000000000000, 0);
  v58;
  if (v59)
  {
LABEL_11:
    v60 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, JSONType)>);
    v61 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, JSONType));
    v62 = *(v61 - 8);
    v170 = v61;
    v172 = *(v62 + 72);
    v63 = *(v62 + 80);
    v64 = (v63 + 32) & ~*(v62 + 80);
    v65 = swift_allocObject(v60, v64 + 2 * v172, v63 | 7);
    *(v65 + 16) = 2;
    *(v65 + 24) = 4;
    v66 = v65 + v64;
    v67 = v65 + v64 + *(v61 + 48);
    *(v65 + v64) = v164;
    *(v65 + v64 + 8) = v168;
    LODWORD(v167) = enum case for JSONType.string(_:);
    v68 = *(v175 + 104);
    v69 = v143;
    v68(v67, enum case for JSONType.string(_:), v143);
    v70 = v172;
    v71 = v66 + v172 + *(v170 + 12);
    *(v172 + v66) = v159;
    v72 = v158;
    *(v70 + v66 + 8) = v158;
    LOBYTE(v66) = v72;
    v172 = v68;
    v68(v71, v167, v69);
    v168;
    v66;
    v73 = Dictionary.init(dictionaryLiteral:)(v65, &type metadata for String, v69, &protocol witness table for String);
    if (a8)
    {
      v74 = v171;
      v75 = v73;
      (v172)(v171, enum case for JSONType.double(_:), v69);
      v76 = v174;
      (*(v175 + 32))(v174, v74, v69);
      a8;
      isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(v75);
      v151[0] = v75;
      specialized _NativeDictionary.setValue(_:forKey:isUnique:)(v76, a7, a8, isUniquelyReferenced_nonNull_native);
      a8;
      v73 = v151[0];
      v78 = a10;
    }

    else
    {
      v78 = a10;
      v76 = v174;
    }

    v174 = v73;
    if (v78)
    {
      v79 = v171;
      (v172)(v171, enum case for JSONType.double(_:), v69);
      (*(v175 + 32))(v76, v79, v69);
      v78;
      v80 = v174;
      v81 = swift_isUniquelyReferenced_nonNull_native(v174);
      v151[0] = v80;
      specialized _NativeDictionary.setValue(_:forKey:isUnique:)(v76, a9, v78, v81);
      v78;
      v174 = v151[0];
    }

    v82 = v141;
    (v165[2])(v141, v173, v153);
    v83 = v169;
    v169;
    v84 = v161;
    JSONReadingOptions.init()();
    v85 = v142;
    v86 = v152;
    DataFrame.init(contentsOfJSONFile:columns:types:options:)(v82, v83, v174, v84);
    if (!v86)
    {
      v173 = 0;
      v87 = v162;
      v88 = v166;
      goto LABEL_27;
    }

    return v83;
  }

  v89 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<(String, CSVType)>);
  v90 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (String, CSVType));
  v91 = *(v90 - 8);
  v92 = v90;
  v171 = v90;
  v175 = *(v91 + 72);
  v93 = *(v91 + 80);
  v94 = (v93 + 32) & ~*(v91 + 80);
  v95 = swift_allocObject(v89, v94 + 2 * v175, v93 | 7);
  *(v95 + 16) = 2;
  *(v95 + 24) = 4;
  v96 = v95 + v94;
  v97 = v95 + v94 + *(v92 + 48);
  *(v95 + v94) = v164;
  *(v95 + v94 + 8) = v168;
  LODWORD(v161) = enum case for CSVType.string(_:);
  v98 = *(v163 + 104);
  v99 = v172;
  (v98)(v97, enum case for CSVType.string(_:), v172);
  v100 = v98;
  v101 = v175;
  v102 = v96 + v175 + *(v171 + 12);
  *(v175 + v96) = v159;
  LOBYTE(v98) = v158;
  *(v101 + v96 + 8) = v158;
  v103 = v99;
  v104 = v100;
  (v100)(v102, v161, v103);
  v168;
  LOBYTE(v102) = v98;
  v105 = v103;
  v102;
  v106 = Dictionary.init(dictionaryLiteral:)(v95, &type metadata for String, v103, &protocol witness table for String);
  v174 = v104;
  LODWORD(v171) = enum case for CSVType.double(_:);
  if (a8)
  {
    v107 = v170;
    v175 = v106;
    (v104)(v170, enum case for CSVType.double(_:), v105);
    v108 = v157;
    v109 = v163;
    (*(v163 + 32))(v157, v107, v105);
    a8;
    v110 = v175;
    v111 = swift_isUniquelyReferenced_nonNull_native(v175);
    v151[0] = v110;
    specialized _NativeDictionary.setValue(_:forKey:isUnique:)(v108, a7, a8, v111);
    a8;
    v106 = v151[0];
    v112 = a10;
  }

  else
  {
    v112 = a10;
    v109 = v163;
  }

  v175 = v106;
  v113 = v170;
  if (v112)
  {
    v114 = v172;
    (v174)(v170, v171, v172);
    v115 = v109;
    v116 = v157;
    (*(v115 + 32))(v157, v113, v114);
    v112;
    v117 = v175;
    v118 = swift_isUniquelyReferenced_nonNull_native(v175);
    v151[0] = v117;
    v119 = v116;
    v120 = v174;
    specialized _NativeDictionary.setValue(_:forKey:isUnique:)(v119, a9, v112, v118);
    v112;
    v175 = v151[0];
    v113 = v170;
  }

  else
  {
    v120 = v174;
  }

  (v165[2])(v167, v173, v153);
  v83 = v169;
  v169;
  v173 = _sSh21_nonEmptyArrayLiteralShyxGSayxG_tcfCSS_Tt0gq5(&outlined read-only object #0 of default argument 1 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
  v165 = _sSh21_nonEmptyArrayLiteralShyxGSayxG_tcfCSS_Tt0gq5(&outlined read-only object #0 of default argument 2 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
  v121 = _sSh21_nonEmptyArrayLiteralShyxGSayxG_tcfCSS_Tt0gq5(&outlined read-only object #0 of default argument 3 of CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:));
  (v120)(v113, v171, v172);
  v122 = v148;
  CSVReadingOptions.init(hasHeaderRow:nilEncodings:trueEncodings:falseEncodings:floatingPointType:ignoresEmptyLines:usesQuoting:usesEscaping:delimiter:escapeCharacter:)(1, v173, v165, v121, v113, 1, 1, 0, 44, 0xE100000000000000, 92, 0xE100000000000000);
  v85 = v149;
  v123 = v152;
  DataFrame.init(contentsOfCSVFile:columns:rows:types:options:)(v167, v83, 0, 0, 1, v175, v122);
  if (v123)
  {
    return v83;
  }

  v173 = 0;
  v88 = v166;
  v87 = v162;
LABEL_27:
  v175 = *(v87 + 32);
  (v175)(v154, v85, v88);
  v125 = v147;
  DataFrame.subscript.getter(v164, v168, &type metadata for String);
  v151[0] = 0;
  v151[1] = 0xE000000000000000;
  v126 = lazy protocol witness table accessor for type FullyConnectedNetworkClassifier<Float, String> and conformance FullyConnectedNetworkClassifier<A, B>(&lazy protocol witness table cache variable for type Column<String> and conformance Column<A>, &demangling cache variable for type metadata for Column<String>, &protocol conformance descriptor for Column<A>);
  v127 = v145;
  OptionalColumnProtocol.filled(with:)(v151, v145, v126);
  v128 = v127;
  v129 = v154;
  (*(v146 + 8))(v125, v128);
  v130 = alloca(24);
  v131 = alloca(32);
  v143 = v144;
  v132 = v173;
  v133 = _sSlsE3mapySayqd__Gqd__7ElementQzqd_0_YKXEqd_0_YKs5ErrorRd_0_r0_lF11TabularData12FilledColumnVyAF0G0VySSGG_SSSgs5NeverOTg5(partial apply for closure #1 in MLActionClassifier.DataSource.gatherAnnotatedFileNamesForDirectory(url:annotationFile:videoColumn:labelColumn:startTimeColumn:endTimeColumn:), &v141);
  v173 = v132;
  v169;
  v134 = v168;
  v168;
  v135 = v133;
  v136 = v164;
  DataFrame.subscript.setter(v135, v164, v134, &type metadata for String, &type metadata for String);
  v137 = v173;
  static _VideoUtilities.renameVideoColumns(dataFrame:videoColumn:labelColumn:startTimeColumn:endTimeColumn:)(v129, v136, v134, v159, v158, a7, a8, a9, a10);
  (*(v155 + 8))(v160, v156);
  if (v137)
  {
    return (*(v162 + 8))(v129, v166);
  }

  v138 = v150;
  v139 = v129;
  v140 = v166;
  (v175)(v150, v139, v166);
  return __swift_storeEnumTagSinglePayload(v138, 0, 1, v140);
}

uint64_t MLActionClassifier.DataSource.stratifiedSplit(proportions:seed:labelColumn:)(void *a1, uint64_t a2, uint64_t a3, void *a4, __m128 a5)
{
  v8 = v6;
  v35 = a4;
  v36._countAndFlagsBits = a3;
  v40 = a2;
  v36._object = a1;
  v37 = v5;
  v9 = type metadata accessor for MLActionClassifier.DataSource(0);
  v10 = *(*(v9 - 8) + 64);
  v11 = alloca(v10);
  v12 = alloca(v10);
  outlined init with copy of MLActionClassifier.DataSource(v7, &v33);
  EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(&v33, v9);
  if (EnumCaseMultiPayload == 5)
  {
    v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
    v18 = v17[12];
    *v38 = *(&v33 + v18);
    *v43 = *(&v33 + v18 + 8);
    *(&v33 + v17[16] + 8);
    *(&v33 + v17[20] + 8);
    v19 = type metadata accessor for DataFrame(0);
    (*(*(v19 - 8) + 8))(&v33, v19);
LABEL_5:
    MLActionClassifier.DataSource.keypointsWithAnnotations(targetFrameRate:)(0x403E000000000000uLL);
    if (v8)
    {
      return *v43;
    }

    v21 = v40;
    if (v40 < 0)
    {
      BUG();
    }

    v22 = v41;
    v34 = v41;
    LOBYTE(v39) = v42;
    v23 = type metadata accessor for MersenneTwisterGenerator();
    swift_allocObject(v23, 136, 7);
    v41 = MersenneTwisterGenerator.init(seed:)(v21);
    v24 = v39;
    v25 = v22;
    v26 = *v43;
    v32._object = v35;
    v32._countAndFlagsBits = v36._countAndFlagsBits;
    specialized stratifiedSplitBySequenceGenerator<A>(proportions:generator:dataTable:by:on:)(v36._object, &v41, v25, v39, *v38, *v43, 30.0, v32);
    v26;

    return outlined consume of Result<_DataTable, Error>(v34, v24);
  }

  if (EnumCaseMultiPayload == 3)
  {
    v39 = v33;
    *v38 = v35;
    *v43 = v36._countAndFlagsBits;
    v14 = v33;
    v15 = v34;
    v37;
    v16 = v14;
    v8 = v6;
    v16;
    outlined consume of Result<_DataTable, Error>(v39, v15);
    goto LABEL_5;
  }

  MLActionClassifier.DataSource.videosWithAnnotations()(a5);
  if (v6)
  {
    return outlined destroy of MLActionClassifier.DataSource(&v33);
  }

  v27 = v40;
  if (v40 < 0)
  {
    BUG();
  }

  *v43 = v41;
  v28 = v42;
  v29 = type metadata accessor for MersenneTwisterGenerator();
  swift_allocObject(v29, 136, 7);
  v41 = MersenneTwisterGenerator.init(seed:)(v27);
  v30 = v28;
  LODWORD(v40) = v28;
  v31 = *v43;
  specialized stratifiedSplitGenerator<A>(proportions:generator:dataTable:on:)(v36._object, &v41, *v43, v30, v36._countAndFlagsBits, v35, *a5.i64);

  outlined consume of Result<_DataTable, Error>(v31, v40);
  return outlined destroy of MLActionClassifier.DataSource(&v33);
}

uint64_t outlined destroy of MLActionClassifier.DataSource(uint64_t a1)
{
  v1 = type metadata accessor for MLActionClassifier.DataSource(0);
  (*(*(v1 - 8) + 8))(a1, v1);
  return a1;
}

uint64_t assignWithCopy for MLActionClassifier.DataSource(uint64_t a1, uint64_t a2, uint64_t a3)
{
  if (a1 != a2)
  {
    outlined destroy of MLActionClassifier.DataSource(a1);
    EnumCaseMultiPayload = swift_getEnumCaseMultiPayload(a2, a3);
    switch(EnumCaseMultiPayload)
    {
      case 0u:
        v43 = EnumCaseMultiPayload;
        v13 = type metadata accessor for URL(0);
        v40 = *(*(v13 - 8) + 16);
        v40(a1, a2, v13);
        v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v40(a1 + v14[12], a2 + v14[12], v13);
        v15 = v14[16];
        *(a1 + v15) = *(a2 + v15);
        v16 = *(a2 + v15 + 8);
        *(a1 + v15 + 8) = v16;
        v17 = v14[20];
        *(a1 + v17) = *(a2 + v17);
        v41 = *(a2 + v17 + 8);
        *(a1 + v17 + 8) = v41;
        v18 = v14[24];
        *(a1 + v18) = *(a2 + v18);
        v19 = *(a2 + v18 + 8);
        *(a1 + v18 + 8) = v19;
        v20 = v14[28];
        *(a1 + v20) = *(a2 + v20);
        v21 = *(a2 + v20 + 8);
        *(a1 + v20 + 8) = v21;
        v16;
        v41;
        LOBYTE(v16) = v19;
        EnumCaseMultiPayload = v43;
        v16;
        v22 = v21;
        goto LABEL_12;
      case 1u:
      case 2u:
        v6 = type metadata accessor for URL(0);
        (*(*(v6 - 8) + 16))(a1, a2, v6);
        goto LABEL_13;
      case 3u:
        v23 = *a2;
        v44 = EnumCaseMultiPayload;
        v24 = *(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*a2, v24);
        *a1 = v23;
        *(a1 + 8) = v24;
        EnumCaseMultiPayload = v44;
        *(a1 + 16) = *(a2 + 16);
        v25 = *(a2 + 24);
        *(a1 + 24) = v25;
        *(a1 + 32) = *(a2 + 32);
        v26 = *(a2 + 40);
        *(a1 + 40) = v26;
        *(a1 + 48) = *(a2 + 48);
        v12 = *(a2 + 56);
        *(a1 + 56) = v12;
        goto LABEL_8;
      case 4u:
        v7 = *a2;
        v42 = EnumCaseMultiPayload;
        v8 = *(a2 + 8);
        outlined copy of Result<_DataTable, Error>(*a2, v8);
        *a1 = v7;
        *(a1 + 8) = v8;
        *(a1 + 16) = *(a2 + 16);
        v9 = *(a2 + 24);
        *(a1 + 24) = v9;
        *(a1 + 32) = *(a2 + 32);
        v10 = *(a2 + 40);
        *(a1 + 40) = v10;
        *(a1 + 48) = *(a2 + 48);
        v11 = *(a2 + 56);
        *(a1 + 56) = v11;
        *(a1 + 64) = *(a2 + 64);
        v12 = *(a2 + 72);
        *(a1 + 72) = v12;
        goto LABEL_10;
      case 5u:
        v27 = type metadata accessor for DataFrame(0);
        (*(*(v27 - 8) + 16))(a1, a2, v27);
        v28 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        v29 = v28[12];
        *(a1 + v29) = *(a2 + v29);
        v25 = *(a2 + v29 + 8);
        *(a1 + v29 + 8) = v25;
        v30 = v28[16];
        *(a1 + v30) = *(a2 + v30);
        v26 = *(a2 + v30 + 8);
        *(a1 + v30 + 8) = v26;
        v31 = v28[20];
        *(a1 + v31) = *(a2 + v31);
        v12 = *(a2 + v31 + 8);
        *(a1 + v31 + 8) = v12;
LABEL_8:
        v25;
        v32 = v26;
        break;
      case 6u:
        v33 = type metadata accessor for DataFrame(0);
        (*(*(v33 - 8) + 16))(a1, a2, v33);
        v34 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v35 = v34[12];
        *(a1 + v35) = *(a2 + v35);
        v9 = *(a2 + v35 + 8);
        *(a1 + v35 + 8) = v9;
        v36 = v34[16];
        *(a1 + v36) = *(a2 + v36);
        v10 = *(a2 + v36 + 8);
        *(a1 + v36 + 8) = v10;
        v37 = v34[20];
        *(a1 + v37) = *(a2 + v37);
        v42 = EnumCaseMultiPayload;
        v11 = *(a2 + v37 + 8);
        *(a1 + v37 + 8) = v11;
        v38 = v34[24];
        *(a1 + v38) = *(a2 + v38);
        v12 = *(a2 + v38 + 8);
        *(a1 + v38 + 8) = v12;
LABEL_10:
        v9;
        v10;
        v32 = v11;
        EnumCaseMultiPayload = v42;
        break;
    }

    v32;
    v22 = v12;
LABEL_12:
    v22;
LABEL_13:
    swift_storeEnumTagMultiPayload(a1, a3, EnumCaseMultiPayload);
  }

  return a1;
}

char *assignWithTake for MLActionClassifier.DataSource(char *__dst, char *__src, uint64_t a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActionClassifier.DataSource(__dst);
    switch(swift_getEnumCaseMultiPayload(__src, a3))
    {
      case 0u:
        v4 = type metadata accessor for URL(0);
        v16 = *(*(v4 - 8) + 32);
        v16(__dst, __src, v4);
        v5 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (at: URL, annotationFile: URL, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        v16(&__dst[v5[12]], &__src[v5[12]], v4);
        *&__dst[v5[16]] = *&__src[v5[16]];
        *&__dst[v5[20]] = *&__src[v5[20]];
        *&__dst[v5[24]] = *&__src[v5[24]];
        *&__dst[v5[28]] = *&__src[v5[28]];
        v6 = a3;
        v7 = 0;
        goto LABEL_10;
      case 1u:
        v10 = type metadata accessor for URL(0);
        (*(*(v10 - 8) + 32))(__dst, __src, v10);
        v15 = 1;
        goto LABEL_9;
      case 2u:
        v9 = type metadata accessor for URL(0);
        (*(*(v9 - 8) + 32))(__dst, __src, v9);
        v15 = 2;
        goto LABEL_9;
      case 5u:
        v11 = type metadata accessor for DataFrame(0);
        (*(*(v11 - 8) + 32))(__dst, __src, v11);
        v12 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, sessionIdColumn: String, labelColumn: String, featureColumn: String));
        *&__dst[v12[12]] = *&__src[v12[12]];
        *&__dst[v12[16]] = *&__src[v12[16]];
        *&__dst[v12[20]] = *&__src[v12[20]];
        v15 = 5;
        goto LABEL_9;
      case 6u:
        v13 = type metadata accessor for DataFrame(0);
        (*(*(v13 - 8) + 32))(__dst, __src, v13);
        v14 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (DataFrame, videoColumn: String, labelColumn: String, startTimeColumn: String?, endTimeColumn: String?));
        *&__dst[v14[12]] = *&__src[v14[12]];
        *&__dst[v14[16]] = *&__src[v14[16]];
        *&__dst[v14[20]] = *&__src[v14[20]];
        *&__dst[v14[24]] = *&__src[v14[24]];
        v15 = 6;
LABEL_9:
        v7 = v15;
        v6 = a3;
LABEL_10:
        swift_storeEnumTagMultiPayload(__dst, v6, v7);
        return __dst;
      default:
        return memcpy(__dst, __src, *(*(a3 - 8) + 64));
    }
  }

  return __dst;
}

uint64_t type metadata completion function for MLActionClassifier.DataSource(uint64_t a1)
{
  v1 = type metadata accessor for URL(319);
  v2 = v1;
  if (v3 <= 0x3F)
  {
    v21 = a1;
    v4 = *(v1 - 8) + 64;
    v13 = v4;
    v14 = v4;
    v15 = &unk_348D80;
    v16 = &unk_348D80;
    v17 = &unk_348D98;
    v18 = &unk_348D98;
    swift_getTupleTypeLayout(v11, 0, 6);
    v20[0] = v11;
    v20[1] = v4;
    v20[2] = v4;
    v20[3] = &unk_348DB0;
    v20[4] = &unk_348DC8;
    v5 = type metadata accessor for DataFrame(319);
    v2 = v5;
    if (v6 <= 0x3F)
    {
      v13 = *(v5 - 8) + 64;
      v7 = v13;
      v14 = &unk_348D80;
      v15 = &unk_348D80;
      v16 = &unk_348D80;
      v2 = 0;
      swift_getTupleTypeLayout(v19, 0, 4);
      v20[5] = v19;
      v13 = v7;
      v14 = &unk_348D80;
      v15 = &unk_348D80;
      v16 = &unk_348D98;
      v17 = &unk_348D98;
      swift_getTupleTypeLayout(v12, 0, 5);
      v20[6] = v12;
      swift_initEnumMetadataMultiPayload(v21, 256, 7, v20, v8, v9);
    }
  }

  return v2;
}

uint64_t BlobMetadata.dataType.getter()
{
  v1 = *(v0 + 4);
  v2 = 0x2010003u >> (8 * v1);
  v3 = v1 < 4;
  result = 3;
  if (v3)
  {
    return v2;
  }

  return result;
}

uint64_t getEnumTagSinglePayload for BlobMetadata(uint64_t a1, int a2)
{
  result = 0;
  if (a2)
  {
    if (*(a1 + 64))
    {
      return (*a1 + 1);
    }
  }

  return result;
}

void storeEnumTagSinglePayload for BlobMetadata(uint64_t a1, int a2, int a3)
{
  if (!a2)
  {
    if (!a3)
    {
      return;
    }

    v3 = 0;
    goto LABEL_6;
  }

  *(a1 + 56) = 0;
  *(a1 + 40) = 0;
  *(a1 + 24) = 0;
  *(a1 + 8) = 0;
  *a1 = (a2 - 1);
  v3 = 1;
  if (a3)
  {
LABEL_6:
    *(a1 + 64) = v3;
  }
}

uint64_t MLTextClassifier.ModelParameters.maxIterations.getter()
{
  v1 = *(type metadata accessor for MLTextClassifier.ModelParameters(0) + 36);
  result = *(v0 + v1);
  v3 = *(v0 + v1 + 8);
  return result;
}

uint64_t type metadata accessor for MLTextClassifier.ModelParameters(uint64_t a1)
{
  result = type metadata singleton initialization cache for MLTextClassifier.ModelParameters;
  if (!type metadata singleton initialization cache for MLTextClassifier.ModelParameters)
  {
    return swift_getSingletonMetadata(a1, &nominal type descriptor for MLTextClassifier.ModelParameters);
  }

  return result;
}

uint64_t MLTextClassifier.ModelParameters.init(validation:algorithm:language:)(uint64_t a1, uint64_t a2, uint64_t a3)
{
  v13[0] = a3;
  v4 = v3;
  v5 = *(*(type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0) - 8) + 64);
  v6 = alloca(v5);
  v7 = alloca(v5);
  v8 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  v9 = v8[5];
  v10 = v8[6];
  *(v4 + v10 + 16) = 0;
  *(v4 + v10) = 0;
  *(v4 + v8[7]) = 0;
  *(v4 + v8[8]) = 0;
  v11 = v8[9];
  *(v4 + v11) = 0;
  *(v4 + v11 + 8) = 1;
  outlined init with copy of MLTrainingSessionParameters(a2, v4, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  *(v4 + v9) = v13[0];
  outlined init with copy of MLTrainingSessionParameters(a1, v13, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
  MLTextClassifier.ModelParameters.validation.setter(v13);
  outlined destroy of MLActivityClassifier.ModelParameters(a2, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  return outlined destroy of MLActivityClassifier.ModelParameters(a1, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
}

uint64_t MLTextClassifier.ModelParameters.validation.getter()
{
  v2 = v0;
  v3 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  outlined init with copy of Any?(v1 + *(v3 + 24), &v7);
  if (!v8)
  {
    BUG();
  }

  outlined init with take of Any(&v7, v6);
  v4 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  return swift_dynamicCast(v2, v6, &type metadata for Any + 8, v4, 7);
}

uint64_t MLTextClassifier.ModelParameters.init(validationData:algorithm:language:textColumnValidationData:labelColumnValidationData:)(uint64_t *a1, uint64_t a2, void *a3, uint64_t a4, unint64_t a5, uint64_t a6, unint64_t a7)
{
  v27 = a4;
  v9 = v7;
  v10 = a2;
  v28 = a6;
  v32 = a5;
  v30 = *a1;
  v11 = *(a1 + 8);
  v12 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  v13 = v12[6];
  *(v9 + v13 + 16) = 0;
  *(v9 + v13) = 0;
  *(v9 + v12[7]) = 0;
  *(v9 + v12[8]) = 0;
  v14 = v12[9];
  *(v9 + v14) = 0;
  v29 = v9 + v13;
  *(v9 + v14 + 8) = 1;
  v33 = a2;
  if (v11 != -1)
  {
    v31 = a3;
    if (!v32)
    {
      v15 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
      v16 = swift_allocObject(v15, 64, 7);
      v16[2] = 1;
      v16[3] = 2;
      v16[7] = &type metadata for String;
      v16[4] = 0xD00000000000005CLL;
      v16[5] = "Missing event metric for key " + 0x8000000000000000;
      print(_:separator:terminator:)(v16, 32, 0xE100000000000000, 10, 0xE100000000000000);
      v17 = v16;
      v10 = v33;
      v17;
    }

    a3 = v31;
    if (!a7)
    {
      v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Any>);
      v19 = swift_allocObject(v18, 64, 7);
      v19[2] = 1;
      v19[3] = 2;
      v19[7] = &type metadata for String;
      v19[4] = 0xD00000000000005ELL;
      v19[5] = "ified, default to use 'text'" + 0x8000000000000000;
      print(_:separator:terminator:)(v19, 32, 0xE100000000000000, 10, 0xE100000000000000);
      v20 = v19;
      v10 = v33;
      v20;
    }
  }

  v21 = v12[5];
  outlined init with copy of MLTrainingSessionParameters(v10, v9, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  *(v9 + v21) = a3;
  v25 = v30;
  v26 = v11;
  v24[3] = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  __swift_allocate_boxed_opaque_existential_0(v24);
  v22 = a3;
  MLTextClassifier.ModelParameters.ValidationData.init(_:textColumn:labelColumn:)(&v25, 1954047348, 0xE400000000000000, 0x6C6562616CLL, 0xE500000000000000);
  outlined assign with take of Any?(v24, v29);
  MLTextClassifier.ModelParameters.textColumnValidationData.setter(v27, v32);
  MLTextClassifier.ModelParameters.labelColumnValidationData.setter(v28, a7);

  return outlined destroy of MLActivityClassifier.ModelParameters(v33, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
}

id MLTextClassifier.ModelParameters.description.getter()
{
  v1._countAndFlagsBits = MLTextClassifier.ModelAlgorithmType.description.getter();
  object = v1._object;
  v9 = 0xD000000000000010;
  v10 = "than the trained model." + 0x8000000000000000;
  String.append(_:)(v1);
  object;
  ("than the trained model." + 0x8000000000000000);
  v3._countAndFlagsBits = 0x676175676E614C0ALL;
  v3._object = 0xEB00000000203A65;
  String.append(_:)(v3);
  "than the trained model." + 0x8000000000000000;
  v9 = *(v0 + *(type metadata accessor for MLTextClassifier.ModelParameters(0) + 20));
  v9;
  v4 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for NLLanguage?);
  v9 = String.init<A>(describing:)(&v9, v4);
  v10 = v5;
  v3._countAndFlagsBits = 10;
  v3._object = 0xE100000000000000;
  String.append(_:)(v3);
  v6 = v9;
  v7 = v10;
  v9 = 0xD000000000000010;
  v10 = "than the trained model." + 0x8000000000000000;
  ("than the trained model." + 0x8000000000000000);
  v3._countAndFlagsBits = v6;
  v3._object = v7;
  String.append(_:)(v3);
  "than the trained model." + 0x8000000000000000;
  v7;
  return v9;
}

void *MLTextClassifier.ModelParameters.language.getter()
{
  v1 = *(v0 + *(type metadata accessor for MLTextClassifier.ModelParameters(0) + 20));
  v1;
  return v1;
}

void MLTextClassifier.ModelParameters.language.setter(uint64_t a1)
{
  v2 = *(type metadata accessor for MLTextClassifier.ModelParameters(0) + 20);

  *(v1 + v2) = a1;
}

uint64_t key path setter for MLTextClassifier.ModelParameters.validation : MLTextClassifier.ModelParameters(uint64_t a1)
{
  v6[0] = v1;
  v2 = *(*(type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0) - 8) + 64);
  v3 = alloca(v2);
  v4 = alloca(v2);
  outlined init with copy of MLTrainingSessionParameters(a1, v6, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
  return MLTextClassifier.ModelParameters.validation.setter(v6);
}

uint64_t MLTextClassifier.ModelParameters.validation.setter(uint64_t a1)
{
  v2 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  v3 = *(v2 + 28);
  *(v1 + v3 + 8);
  *(v1 + v3) = 0;
  v6[3] = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  boxed_opaque_existential_0 = __swift_allocate_boxed_opaque_existential_0(v6);
  outlined init with take of MLClassifierMetrics(a1, boxed_opaque_existential_0, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
  return outlined assign with take of Any?(v6, v1 + *(v2 + 24));
}

void (*MLTextClassifier.ModelParameters.validation.modify(void *a1))(uint64_t a1, char a2)
{
  v2 = malloc(0x58uLL);
  *a1 = v2;
  *(v2 + 8) = v1;
  v3 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  v4 = *(*(v3 - 8) + 64);
  *(v2 + 9) = malloc(v4);
  v5 = malloc(v4);
  *(v2 + 10) = v5;
  v6 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  outlined init with copy of Any?(v1 + *(v6 + 24), (v2 + 2));
  if (!*(v2 + 7))
  {
    BUG();
  }

  outlined init with take of Any(v2 + 2, v2);
  swift_dynamicCast(v5, v2, &type metadata for Any + 8, v3, 7);
  return MLTextClassifier.ModelParameters.validation.modify;
}

void MLTextClassifier.ModelParameters.validation.modify(uint64_t a1, char a2)
{
  v2 = *a1;
  v3 = *(*a1 + 80);
  v4 = *(*a1 + 64);
  v5 = *(*a1 + 72);
  if (a2)
  {
    outlined init with copy of MLTrainingSessionParameters(*(*a1 + 80), v5, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
    MLTextClassifier.ModelParameters.validation.setter(v5);
    outlined destroy of MLActivityClassifier.ModelParameters(v3, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
  }

  else
  {
    MLTextClassifier.ModelParameters.validation.setter(*(*a1 + 80));
  }

  free(v3);
  free(v5);
  free(v2);
}

uint64_t MLTextClassifier.ModelParameters.maxIterations.setter(uint64_t a1, char a2)
{
  result = *(type metadata accessor for MLTextClassifier.ModelParameters(0) + 36);
  *(v2 + result) = a1;
  *(v2 + result + 8) = a2 & 1;
  return result;
}

uint64_t (*MLTextClassifier.ModelParameters.maxIterations.modify(uint64_t a1))(uint64_t a1)
{
  *(a1 + 16) = v1;
  v2 = *(type metadata accessor for MLTextClassifier.ModelParameters(0) + 36);
  *(a1 + 12) = v2;
  v3 = *(v1 + v2);
  LOBYTE(v2) = *(v1 + v2 + 8);
  *a1 = v3;
  *(a1 + 8) = v2;
  return MLTextClassifier.ModelParameters.maxIterations.modify;
}

uint64_t MLTextClassifier.ModelParameters.maxIterations.modify(uint64_t a1)
{
  result = *(a1 + 12);
  v2 = *(a1 + 16);
  v3 = *(a1 + 8);
  *(v2 + result) = *a1;
  *(v2 + result + 8) = v3;
  return result;
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> MLTextClassifier.ModelParameters.validateRevision()()
{
  v1 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  v2 = *(*(v1 - 8) + 64);
  v3 = alloca(v2);
  v4 = alloca(v2);
  outlined init with copy of MLTrainingSessionParameters(v0, &v16, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  if (swift_getEnumCaseMultiPayload(&v16, v1) > 1)
  {
    v10 = *(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLTextClassifier.FeatureExtractorType, revision: Int?)) + 48);
    if (!*(&v16 + v10 + 8))
    {
      v11 = *(&v16 + v10);
      if (!NLPClassifierModelIsRevisionSupported(v11))
      {
        *&v17 = 0;
        *(&v17 + 1) = 0xE000000000000000;
        _StringGuts.grow(_:)(29);
        *(&v17 + 1);
        *&v17 = 0x6E6F697369766552;
        *(&v17 + 1) = 0xE900000000000020;
        v18 = v11;
        v12._countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
        object = v12._object;
        String.append(_:)(v12);
        object;
        v14._object = "und in the model." + 0x8000000000000000;
        v14._countAndFlagsBits = 0xD000000000000012;
        String.append(_:)(v14);
        v19 = v17;
        v14._object = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
        swift_allocError(&type metadata for MLCreateError, v14._object, 0, 0);
        *v15 = v19;
        *(v15 + 16) = 0;
        *(v15 + 32) = 0;
        *(v15 + 48) = 0;
        swift_willThrow(&type metadata for MLCreateError, v14._object);
      }
    }

    outlined destroy of MLActivityClassifier.ModelParameters(&v16, type metadata accessor for MLTextClassifier.FeatureExtractorType);
  }

  else if (!v17)
  {
    v5 = v16;
    if (!NLPClassifierModelIsRevisionSupported(v16))
    {
      *&v17 = 0;
      *(&v17 + 1) = 0xE000000000000000;
      _StringGuts.grow(_:)(29);
      *(&v17 + 1);
      *&v17 = 0x6E6F697369766552;
      *(&v17 + 1) = 0xE900000000000020;
      v18 = v5;
      v6._countAndFlagsBits = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
      v7 = v6._object;
      String.append(_:)(v6);
      v7;
      v8._object = "und in the model." + 0x8000000000000000;
      v8._countAndFlagsBits = 0xD000000000000012;
      String.append(_:)(v8);
      v19 = v17;
      v8._object = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
      swift_allocError(&type metadata for MLCreateError, v8._object, 0, 0);
      *v9 = v19;
      *(v9 + 16) = 0;
      *(v9 + 32) = 0;
      *(v9 + 48) = 0;
      swift_willThrow(&type metadata for MLCreateError, v8._object);
    }
  }
}

Swift::Void __swiftcall __spoils<cf,zf,sf,of,pf,rax,rdx,rcx,rdi,rsi,r8,r9,r10,r11,r12,xmm0,xmm1,xmm2,xmm3,xmm4,xmm5,xmm6,xmm7> MLTextClassifier.ModelParameters.validateCustomEmbeddingURL()()
{
  *&v31 = v0;
  v34 = v1;
  v35 = type metadata accessor for URL(0);
  v33 = *(v35 - 8);
  v2 = *(v33 + 64);
  v3 = alloca(v2);
  v4 = alloca(v2);
  v32 = v29;
  v5 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  v6 = *(*(v5 - 8) + 64);
  v7 = alloca(v6);
  v8 = alloca(v6);
  v9 = *(*(type metadata accessor for MLTextClassifier.FeatureExtractorType(0) - 8) + 64);
  v10 = alloca(v9);
  v11 = alloca(v9);
  v12 = alloca(v9);
  v13 = alloca(v9);
  outlined init with copy of MLTrainingSessionParameters(v34, v29, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  if (swift_getEnumCaseMultiPayload(v29, v5) != 2)
  {
    v16 = type metadata accessor for MLTextClassifier.ModelAlgorithmType;
    v15 = v29;
    goto LABEL_5;
  }

  outlined init with take of MLClassifierMetrics(v29, v29, type metadata accessor for MLTextClassifier.FeatureExtractorType);
  outlined init with copy of MLTrainingSessionParameters(v29, v29, type metadata accessor for MLTextClassifier.FeatureExtractorType);
  v14 = v35;
  if (__swift_getEnumTagSinglePayload(v29, 4, v35))
  {
    outlined destroy of MLActivityClassifier.ModelParameters(v29, type metadata accessor for MLTextClassifier.FeatureExtractorType);
    v15 = v29;
    v16 = type metadata accessor for MLTextClassifier.FeatureExtractorType;
LABEL_5:
    outlined destroy of MLActivityClassifier.ModelParameters(v15, v16);
    return;
  }

  v34 = v29;
  (*(v33 + 32))(v32, v29, v14);
  v17 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<String>);
  inited = swift_initStackObject(v17, v29);
  inited[2] = 3;
  inited[3] = 6;
  inited[4] = 0x6C65646F6D6C6DLL;
  inited[5] = 0xE700000000000000;
  inited[6] = 0x636C65646F6D6C6DLL;
  inited[7] = 0xE800000000000000;
  inited[8] = 7627108;
  inited[9] = 0xE300000000000000;
  if (URL.isFileURL.getter())
  {
    *&v19 = URL.pathExtension.getter();
    v20 = *(&v19 + 1);
    v21 = specialized Sequence<>.contains(_:)(v19, inited);
    v20;
    swift_setDeallocating(inited);
    v22 = v32;
    specialized _ContiguousArrayStorage.__deallocating_deinit();
    if (v21)
    {
      (*(v33 + 8))(v22, v35);
      v16 = type metadata accessor for MLTextClassifier.FeatureExtractorType;
      v15 = v34;
      goto LABEL_5;
    }
  }

  else
  {
    swift_setDeallocating(inited);
    specialized _ContiguousArrayStorage.__deallocating_deinit();
  }

  *&v30 = 0;
  *(&v30 + 1) = 0xE000000000000000;
  _StringGuts.grow(_:)(52);
  v23._object = "cified, default to use 'label'" + 0x8000000000000000;
  v23._countAndFlagsBits = 0xD000000000000015;
  String.append(_:)(v23);
  v24 = lazy protocol witness table accessor for type URL and conformance URL();
  v25 = dispatch thunk of CustomStringConvertible.description.getter(v35, v24);
  v27 = v26;
  v23._countAndFlagsBits = v25;
  v23._object = v26;
  String.append(_:)(v23);
  v27;
  v23._object = "The custom embedding " + 0x8000000000000000;
  v23._countAndFlagsBits = 0xD00000000000001DLL;
  String.append(_:)(v23);
  v31 = v30;
  v23._object = lazy protocol witness table accessor for type MLCreateError and conformance MLCreateError();
  swift_allocError(&type metadata for MLCreateError, v23._object, 0, 0);
  *v28 = v31;
  *(v28 + 16) = 0;
  *(v28 + 32) = 0;
  *(v28 + 48) = 0;
  swift_willThrow(&type metadata for MLCreateError, v23._object);
  (*(v33 + 8))(v32, v35);
  outlined destroy of MLActivityClassifier.ModelParameters(v34, type metadata accessor for MLTextClassifier.FeatureExtractorType);
}

id MLTextClassifier.ModelParameters.playgroundDescription.getter()
{
  v1 = v0;
  result = MLTextClassifier.ModelParameters.description.getter();
  v1[3] = &type metadata for String;
  *v1 = result;
  v1[1] = v3;
  return result;
}

uint64_t MLTextClassifier.ModelParameters.validationData.getter(__m128 a1)
{
  v2 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  v3 = *(*(v2 - 8) + 64);
  v4 = alloca(v3);
  v5 = alloca(v3);
  v6 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  outlined init with copy of Any?(v1 + *(v6 + 24), &v10);
  if (!v11)
  {
    BUG();
  }

  outlined init with take of Any(&v10, v9);
  swift_dynamicCast(&v8, v9, &type metadata for Any + 8, v2, 7);
  MLTextClassifier.ModelParameters.ValidationData.table.getter(a1);
  return outlined destroy of MLActivityClassifier.ModelParameters(&v8, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
}

uint64_t key path getter for MLTextClassifier.ModelParameters.validationData : MLTextClassifier.ModelParameters(__m128 a1)
{
  v2 = v1;
  MLTextClassifier.ModelParameters.validationData.getter(a1);
  result = v4;
  *v2 = v4;
  *(v2 + 8) = v5;
  return result;
}

uint64_t key path setter for MLTextClassifier.ModelParameters.validationData : MLTextClassifier.ModelParameters(uint64_t a1)
{
  v1 = *(a1 + 8);
  v3 = *a1;
  v4 = v1;
  outlined copy of MLDataTable?(v3, v1);
  return MLTextClassifier.ModelParameters.validationData.setter(&v3);
}

uint64_t MLTextClassifier.ModelParameters.validationData.setter(uint64_t *a1)
{
  v2 = *(a1 + 8);
  v6 = *a1;
  v7 = v2;
  v5[3] = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  __swift_allocate_boxed_opaque_existential_0(v5);
  MLTextClassifier.ModelParameters.ValidationData.init(_:textColumn:labelColumn:)(&v6, 1954047348, 0xE400000000000000, 0x6C6562616CLL, 0xE500000000000000);
  v3 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  return outlined assign with take of Any?(v5, v1 + *(v3 + 24));
}

void (*MLTextClassifier.ModelParameters.validationData.modify(void *a1, __m128 a2))(uint64_t *a1, char a2)
{
  v3 = malloc(0x38uLL);
  *a1 = v3;
  v3[6] = v2;
  MLTextClassifier.ModelParameters.validationData.getter(a2);
  return MLTextClassifier.ModelParameters.validationData.modify;
}

void MLTextClassifier.ModelParameters.validationData.modify(uint64_t *a1, char a2)
{
  v2 = *a1;
  v3 = *(*a1 + 32);
  v4 = *(*a1 + 40);
  v5 = *(*a1 + 48);
  v8 = v3;
  v9 = v4;
  *(v2 + 24) = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  __swift_allocate_boxed_opaque_existential_0(v2);
  if (a2)
  {
    outlined copy of MLDataTable?(v3, v4);
    MLTextClassifier.ModelParameters.ValidationData.init(_:textColumn:labelColumn:)(&v8, 1954047348, 0xE400000000000000, 0x6C6562616CLL, 0xE500000000000000);
    v6 = type metadata accessor for MLTextClassifier.ModelParameters(0);
    outlined assign with take of Any?(v2, *(v6 + 24) + v5);
    outlined consume of MLDataTable?(*(v2 + 32), *(v2 + 40));
  }

  else
  {
    MLTextClassifier.ModelParameters.ValidationData.init(_:textColumn:labelColumn:)(&v8, 1954047348, 0xE400000000000000, 0x6C6562616CLL, 0xE500000000000000);
    v7 = type metadata accessor for MLTextClassifier.ModelParameters(0);
    outlined assign with take of Any?(v2, *(v7 + 24) + v5);
  }

  free(v2);
}

uint64_t MLTextClassifier.ModelParameters.textColumnValidationData.getter()
{
  v1 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  v2 = *(*(v1 - 8) + 64);
  v3 = alloca(v2);
  v4 = alloca(v2);
  v5 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  outlined init with copy of Any?(v0 + *(v5 + 24), &v13);
  if (!v14)
  {
    BUG();
  }

  outlined init with take of Any(&v13, &v11);
  swift_dynamicCast(&v11, &v11, &type metadata for Any + 8, v1, 7);
  if (swift_getEnumCaseMultiPayload(&v11, v1) == 1)
  {
    v6 = v11;
    v7 = v12;
    v8 = BYTE8(v11);
    *(&v13 + 1);
    outlined consume of Result<_DataTable, Error>(v6, v8);
  }

  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters(&v11, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
    v9 = *(v5 + 28);
    v7 = *(v0 + v9);
    *(v0 + v9 + 8);
  }

  return v7;
}

uint64_t MLTextClassifier.ModelParameters.textColumnValidationData.setter(uint64_t a1, unint64_t a2)
{
  v26 = a2;
  v25 = a1;
  v3 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  v4 = *(*(v3 - 8) + 64);
  v5 = alloca(v4);
  v6 = alloca(v4);
  v7 = alloca(v4);
  v8 = alloca(v4);
  v27 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  v9 = *(v27 + 24);
  v24 = v2;
  outlined init with copy of Any?(v2 + v9, &v21);
  if (!v22)
  {
    BUG();
  }

  outlined init with take of Any(&v21, &v18);
  swift_dynamicCast(&v18, &v18, &type metadata for Any + 8, v3, 7);
  if (swift_getEnumCaseMultiPayload(&v18, v3) == 1)
  {
    v10 = v18;
    v28 = BYTE8(v18);
    v23 = v21;
    v20;
    v11 = *(v27 + 28);
    v12 = v24;
    *(v24 + v11 + 8);
    v13 = v25;
    if (!v26)
    {
      v13 = 1954047348;
    }

    v14 = 0xE400000000000000;
    if (v26)
    {
      v14 = v26;
    }

    *(v12 + v11) = 0;
    *&v18 = v10;
    BYTE8(v18) = v28;
    v19 = v13;
    v20 = v14;
    v21 = v23;
    swift_storeEnumTagMultiPayload(&v18, v3, 1);
    return MLTextClassifier.ModelParameters.validation.setter(&v18);
  }

  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters(&v18, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
    v16 = *(v27 + 28);
    v17 = v24;
    *(v24 + v16 + 8);
    *(v17 + v16) = v25;
    result = v26;
    *(v17 + v16 + 8) = v26;
  }

  return result;
}

uint64_t (*MLTextClassifier.ModelParameters.textColumnValidationData.modify(void *a1))(uint64_t *a1, char a2)
{
  a1[2] = v1;
  *a1 = MLTextClassifier.ModelParameters.textColumnValidationData.getter(a1);
  a1[1] = v2;
  return MLTextClassifier.ModelParameters.textColumnValidationData.modify;
}

uint64_t MLTextClassifier.ModelParameters.init(validationData:algorithm:language:)(uint64_t a1, uint64_t a2, void *a3)
{
  v5 = v3;
  v6 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  v7 = v6[5];
  v8 = (v6[6] + v5);
  v19 = v8;
  v8[1] = 0;
  *v8 = 0;
  *(v5 + v6[7]) = 0;
  *(v5 + v6[8]) = 0;
  v9 = v6[9];
  *(v5 + v9) = 0;
  *(v5 + v9 + 8) = 1;
  v18 = a2;
  outlined init with copy of MLTrainingSessionParameters(a2, v5, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  *(v5 + v7) = a3;
  v20 = a3;
  v17 = a1;
  v10 = static _TextUtilities.getTextLabeledDictionary(from:)(a1, 0.0);
  specialized generateTextTable<A>(_:textColumn:labelColumn:using:)(v10, 1954047348, 0xE400000000000000, 0x6C6562616CLL, 0xE500000000000000);
  v10;
  v12 = v14;
  v13 = v15;
  v16 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  __swift_allocate_boxed_opaque_existential_0(&v14);
  MLTextClassifier.ModelParameters.ValidationData.init(_:textColumn:labelColumn:)(&v12, 1954047348, 0xE400000000000000, 0x6C6562616CLL, 0xE500000000000000);
  outlined assign with take of Any?(&v14, v19);
  MLTextClassifier.ModelParameters.textColumnValidationData.setter(1954047348, 0xE400000000000000);
  MLTextClassifier.ModelParameters.labelColumnValidationData.setter(0x6C6562616CLL, 0xE500000000000000);

  outlined destroy of MLActivityClassifier.ModelParameters(v18, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  return outlined destroy of MLActivityClassifier.ModelParameters(v17, type metadata accessor for MLTextClassifier.DataSource);
}

{
  v5 = v3;
  v6 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  v7 = v6[5];
  v8 = (v6[6] + v5);
  v17 = v8;
  v8[1] = 0;
  *v8 = 0;
  *(v5 + v6[7]) = 0;
  *(v5 + v6[8]) = 0;
  v9 = v6[9];
  *(v5 + v9) = 0;
  *(v5 + v9 + 8) = 1;
  v16 = a2;
  outlined init with copy of MLTrainingSessionParameters(a2, v5, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
  *(v5 + v7) = a3;
  v18 = a3;
  specialized generateTextTable<A>(_:textColumn:labelColumn:using:)(a1, 1954047348, 0xE400000000000000, 0x6C6562616CLL, 0xE500000000000000);
  a1;
  v11 = v13;
  v12 = v14;
  v15 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  __swift_allocate_boxed_opaque_existential_0(&v13);
  MLTextClassifier.ModelParameters.ValidationData.init(_:textColumn:labelColumn:)(&v11, 1954047348, 0xE400000000000000, 0x6C6562616CLL, 0xE500000000000000);
  outlined assign with take of Any?(&v13, v17);
  MLTextClassifier.ModelParameters.textColumnValidationData.setter(1954047348, 0xE400000000000000);
  MLTextClassifier.ModelParameters.labelColumnValidationData.setter(0x6C6562616CLL, 0xE500000000000000);

  return outlined destroy of MLActivityClassifier.ModelParameters(v16, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
}

uint64_t MLTextClassifier.ModelParameters.labelColumnValidationData.setter(uint64_t a1, unint64_t a2)
{
  v25 = a2;
  v24 = a1;
  v3 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  v4 = *(*(v3 - 8) + 64);
  v5 = alloca(v4);
  v6 = alloca(v4);
  v7 = alloca(v4);
  v8 = alloca(v4);
  v26 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  v9 = *(v26 + 24);
  v23 = v2;
  outlined init with copy of Any?(v2 + v9, &v20);
  if (!v21)
  {
    BUG();
  }

  outlined init with take of Any(&v20, &v18);
  swift_dynamicCast(&v18, &v18, &type metadata for Any + 8, v3, 7);
  if (swift_getEnumCaseMultiPayload(&v18, v3) == 1)
  {
    v10 = v18;
    v27 = BYTE8(v18);
    v22 = v19;
    *(&v20 + 1);
    v11 = *(v26 + 32);
    v12 = v23;
    *(v23 + v11 + 8);
    v13 = v24;
    if (!v25)
    {
      v13 = 0x6C6562616CLL;
    }

    v14 = 0xE500000000000000;
    if (v25)
    {
      v14 = v25;
    }

    *(v12 + v11) = 0;
    *&v18 = v10;
    BYTE8(v18) = v27;
    v19 = v22;
    *&v20 = v13;
    *(&v20 + 1) = v14;
    swift_storeEnumTagMultiPayload(&v18, v3, 1);
    return MLTextClassifier.ModelParameters.validation.setter(&v18);
  }

  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters(&v18, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
    v16 = *(v26 + 32);
    v17 = v23;
    *(v23 + v16 + 8);
    *(v17 + v16) = v24;
    result = v25;
    *(v17 + v16 + 8) = v25;
  }

  return result;
}

uint64_t outlined assign with take of MLTextClassifier.ModelAlgorithmType(uint64_t a1, uint64_t a2)
{
  v2 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  (*(*(v2 - 8) + 40))(a2, a1, v2);
  return a2;
}

uint64_t MLTextClassifier.ModelParameters.labelColumnValidationData.getter()
{
  v1 = type metadata accessor for MLTextClassifier.ModelParameters.ValidationData(0);
  v2 = *(*(v1 - 8) + 64);
  v3 = alloca(v2);
  v4 = alloca(v2);
  v5 = type metadata accessor for MLTextClassifier.ModelParameters(0);
  outlined init with copy of Any?(v0 + *(v5 + 24), &v13);
  if (!v14)
  {
    BUG();
  }

  outlined init with take of Any(&v13, &v11);
  swift_dynamicCast(&v11, &v11, &type metadata for Any + 8, v1, 7);
  if (swift_getEnumCaseMultiPayload(&v11, v1) == 1)
  {
    v6 = v11;
    v7 = v13;
    v8 = BYTE8(v11);
    v12;
    outlined consume of Result<_DataTable, Error>(v6, v8);
  }

  else
  {
    outlined destroy of MLActivityClassifier.ModelParameters(&v11, type metadata accessor for MLTextClassifier.ModelParameters.ValidationData);
    v9 = *(v5 + 32);
    v7 = *(v0 + v9);
    *(v0 + v9 + 8);
  }

  return v7;
}

uint64_t (*MLTextClassifier.ModelParameters.labelColumnValidationData.modify(void *a1))(uint64_t *a1, char a2)
{
  a1[2] = v1;
  *a1 = MLTextClassifier.ModelParameters.labelColumnValidationData.getter(a1);
  a1[1] = v2;
  return MLTextClassifier.ModelParameters.labelColumnValidationData.modify;
}

uint64_t sub_2B6E7E()
{
  v1 = v0;
  result = MLTextClassifier.ModelParameters.maxIterations.getter();
  *v1 = result;
  *(v1 + 8) = v3 & 1;
  return result;
}

uint64_t sub_2B6EBC(uint64_t a1)
{
  v2 = v1;
  result = MLTextClassifier.ModelParameters.textColumnValidationData.getter(a1);
  *v2 = result;
  v2[1] = v4;
  return result;
}

uint64_t sub_2B6EEC(uint64_t a1)
{
  v2 = v1;
  result = MLTextClassifier.ModelParameters.labelColumnValidationData.getter(a1);
  *v2 = result;
  v2[1] = v4;
  return result;
}

void *initializeBufferWithCopyOfBuffer for MLTextClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  v3 = __dst;
  v4 = *(*(a3 - 1) + 80);
  if ((v4 & 0x20000) != 0)
  {
    v9 = *__src;
    *v3 = *__src;
    v3 = (v9 + ((v4 + 16) & ~v4));
  }

  else
  {
    v6 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
    if (swift_getEnumCaseMultiPayload(__src, v6) == 2)
    {
      v7 = type metadata accessor for URL(0);
      if (__swift_getEnumTagSinglePayload(__src, 4, v7))
      {
        v8 = type metadata accessor for MLTextClassifier.FeatureExtractorType(0);
        memcpy(__dst, __src, *(*(v8 - 8) + 64));
      }

      else
      {
        (*(*(v7 - 8) + 16))(__dst, __src, v7);
        __swift_storeEnumTagSinglePayload(__dst, 0, 4, v7);
      }

      v10 = *(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLTextClassifier.FeatureExtractorType, revision: Int?)) + 48);
      __dst[v10 + 8] = __src[v10 + 8];
      *&__dst[v10] = *&__src[v10];
      swift_storeEnumTagMultiPayload(__dst, v6, 2);
    }

    else
    {
      memcpy(__dst, __src, *(*(v6 - 8) + 64));
    }

    v11 = a3[5];
    v12 = *&__src[v11];
    *(v3 + v11) = v12;
    v24 = a3;
    v13 = a3[6];
    v14 = v3 + v13;
    v15 = &__src[v13];
    v16 = *&__src[v13 + 24];
    v12;
    if (v16)
    {
      *(v14 + 3) = v16;
      (**(v16 - 8))(v14, v15, v16);
    }

    else
    {
      v17 = *v15;
      *(v14 + 1) = *(v15 + 1);
      *v14 = v17;
    }

    v18 = v24[7];
    *(v3 + v18) = *&__src[v18];
    v19 = *&__src[v18 + 8];
    *(v3 + v18 + 8) = v19;
    v20 = v24[8];
    *(v3 + v20) = *&__src[v20];
    v21 = *&__src[v20 + 8];
    *(v3 + v20 + 8) = v21;
    v22 = v24[9];
    *(v3 + v22 + 8) = __src[v22 + 8];
    *(v3 + v22) = *&__src[v22];
    v19;
    v21;
  }

  return v3;
}

uint64_t destroy for MLTextClassifier.ModelParameters(uint64_t a1, int *a2)
{
  v3 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  if (swift_getEnumCaseMultiPayload(a1, v3) == 2)
  {
    v4 = type metadata accessor for URL(0);
    if (!__swift_getEnumTagSinglePayload(a1, 4, v4))
    {
      (*(*(v4 - 8) + 8))(a1, v4);
    }
  }

  v5 = a2[6];
  if (*(a1 + v5 + 24))
  {
    __swift_destroy_boxed_opaque_existential_1Tm((a1 + v5));
  }

  *(a1 + a2[7] + 8);
  return *(a1 + a2[8] + 8);
}

char *initializeWithCopy for MLTextClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  v4 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  if (swift_getEnumCaseMultiPayload(__src, v4) == 2)
  {
    v5 = type metadata accessor for URL(0);
    if (__swift_getEnumTagSinglePayload(__src, 4, v5))
    {
      v6 = type metadata accessor for MLTextClassifier.FeatureExtractorType(0);
      memcpy(__dst, __src, *(*(v6 - 8) + 64));
    }

    else
    {
      (*(*(v5 - 8) + 16))(__dst, __src, v5);
      __swift_storeEnumTagSinglePayload(__dst, 0, 4, v5);
    }

    v7 = *(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLTextClassifier.FeatureExtractorType, revision: Int?)) + 48);
    __dst[v7 + 8] = __src[v7 + 8];
    *&__dst[v7] = *&__src[v7];
    swift_storeEnumTagMultiPayload(__dst, v4, 2);
  }

  else
  {
    memcpy(__dst, __src, *(*(v4 - 8) + 64));
  }

  v8 = a3[5];
  v9 = *&__src[v8];
  *&__dst[v8] = v9;
  v10 = a3[6];
  v11 = &__dst[v10];
  v12 = &__src[v10];
  v13 = *&__src[v10 + 24];
  v9;
  if (v13)
  {
    *(v11 + 3) = v13;
    (**(v13 - 8))(v11, v12, v13);
  }

  else
  {
    v14 = *v12;
    *(v11 + 1) = *(v12 + 1);
    *v11 = v14;
  }

  v15 = a3[7];
  *&__dst[v15] = *&__src[v15];
  v16 = *&__src[v15 + 8];
  *&__dst[v15 + 8] = v16;
  v17 = a3[8];
  *&__dst[v17] = *&__src[v17];
  v18 = *&__src[v17 + 8];
  *&__dst[v17 + 8] = v18;
  v19 = a3[9];
  __dst[v19 + 8] = __src[v19 + 8];
  *&__dst[v19] = *&__src[v19];
  v16;
  v18;
  return __dst;
}

char *assignWithCopy for MLTextClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(__dst, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
    v5 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
    if (swift_getEnumCaseMultiPayload(__src, v5) == 2)
    {
      v6 = type metadata accessor for URL(0);
      if (__swift_getEnumTagSinglePayload(__src, 4, v6))
      {
        v7 = type metadata accessor for MLTextClassifier.FeatureExtractorType(0);
        memcpy(__dst, __src, *(*(v7 - 8) + 64));
      }

      else
      {
        (*(*(v6 - 8) + 16))(__dst, __src, v6);
        __swift_storeEnumTagSinglePayload(__dst, 0, 4, v6);
      }

      v8 = *(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLTextClassifier.FeatureExtractorType, revision: Int?)) + 48);
      __dst[v8 + 8] = __src[v8 + 8];
      *&__dst[v8] = *&__src[v8];
      swift_storeEnumTagMultiPayload(__dst, v5, 2);
    }

    else
    {
      memcpy(__dst, __src, *(*(v5 - 8) + 64));
    }
  }

  v9 = a3[5];
  v10 = *&__dst[v9];
  v11 = *&__src[v9];
  *&__dst[v9] = v11;
  v11;

  v12 = a3[6];
  v13 = &__dst[v12];
  v14 = &__src[v12];
  v15 = *&__src[v12 + 24];
  if (!*&__dst[v12 + 24])
  {
    if (v15)
    {
      *(v13 + 3) = v15;
      (**(v15 - 8))(v13, v14);
      goto LABEL_15;
    }

LABEL_14:
    v16 = *v14;
    *(v13 + 1) = *(v14 + 1);
    *v13 = v16;
    goto LABEL_15;
  }

  if (!v15)
  {
    __swift_destroy_boxed_opaque_existential_1Tm(&__dst[v12]);
    goto LABEL_14;
  }

  __swift_assign_boxed_opaque_existential_0(&__dst[v12], &__src[v12]);
LABEL_15:
  v17 = a3[7];
  *&__dst[v17] = *&__src[v17];
  v18 = *&__src[v17 + 8];
  v19 = *&__dst[v17 + 8];
  *&__dst[v17 + 8] = v18;
  v18;
  v19;
  v20 = a3[8];
  *&__dst[v20] = *&__src[v20];
  v21 = *&__src[v20 + 8];
  v22 = *&__dst[v20 + 8];
  *&__dst[v20 + 8] = v21;
  v21;
  v22;
  v23 = a3[9];
  __dst[v23 + 8] = __src[v23 + 8];
  *&__dst[v23] = *&__src[v23];
  return __dst;
}

char *initializeWithTake for MLTextClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  v4 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  if (swift_getEnumCaseMultiPayload(__src, v4) == 2)
  {
    v5 = type metadata accessor for URL(0);
    if (__swift_getEnumTagSinglePayload(__src, 4, v5))
    {
      v6 = type metadata accessor for MLTextClassifier.FeatureExtractorType(0);
      memcpy(__dst, __src, *(*(v6 - 8) + 64));
    }

    else
    {
      (*(*(v5 - 8) + 32))(__dst, __src, v5);
      __swift_storeEnumTagSinglePayload(__dst, 0, 4, v5);
    }

    v7 = *(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLTextClassifier.FeatureExtractorType, revision: Int?)) + 48);
    __dst[v7 + 8] = __src[v7 + 8];
    *&__dst[v7] = *&__src[v7];
    swift_storeEnumTagMultiPayload(__dst, v4, 2);
  }

  else
  {
    memcpy(__dst, __src, *(*(v4 - 8) + 64));
  }

  *&__dst[a3[5]] = *&__src[a3[5]];
  v8 = a3[6];
  v9 = *&__src[v8];
  *&__dst[v8 + 16] = *&__src[v8 + 16];
  *&__dst[v8] = v9;
  *&__dst[a3[7]] = *&__src[a3[7]];
  *&__dst[a3[8]] = *&__src[a3[8]];
  v10 = a3[9];
  *&__dst[v10] = *&__src[v10];
  __dst[v10 + 8] = __src[v10 + 8];
  return __dst;
}

char *assignWithTake for MLTextClassifier.ModelParameters(char *__dst, char *__src, int *a3)
{
  if (__dst != __src)
  {
    outlined destroy of MLActivityClassifier.ModelParameters(__dst, type metadata accessor for MLTextClassifier.ModelAlgorithmType);
    v5 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
    if (swift_getEnumCaseMultiPayload(__src, v5) == 2)
    {
      v6 = type metadata accessor for URL(0);
      if (__swift_getEnumTagSinglePayload(__src, 4, v6))
      {
        v7 = type metadata accessor for MLTextClassifier.FeatureExtractorType(0);
        memcpy(__dst, __src, *(*(v7 - 8) + 64));
      }

      else
      {
        (*(*(v6 - 8) + 32))(__dst, __src, v6);
        __swift_storeEnumTagSinglePayload(__dst, 0, 4, v6);
      }

      v8 = *(__swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for (MLTextClassifier.FeatureExtractorType, revision: Int?)) + 48);
      __dst[v8 + 8] = __src[v8 + 8];
      *&__dst[v8] = *&__src[v8];
      swift_storeEnumTagMultiPayload(__dst, v5, 2);
    }

    else
    {
      memcpy(__dst, __src, *(*(v5 - 8) + 64));
    }
  }

  v9 = a3[5];
  v10 = *&__dst[v9];
  *&__dst[v9] = *&__src[v9];

  v11 = a3[6];
  v12 = &__dst[v11];
  if (*&__dst[v11 + 24])
  {
    __swift_destroy_boxed_opaque_existential_1Tm(&__dst[v11]);
  }

  v13 = *&__src[v11];
  *(v12 + 1) = *&__src[v11 + 16];
  *v12 = v13;
  v14 = a3[7];
  *&__dst[v14] = *&__src[v14];
  v15 = *&__dst[v14 + 8];
  *&__dst[v14 + 8] = *&__src[v14 + 8];
  v15;
  v16 = a3[8];
  *&__dst[v16] = *&__src[v16];
  v17 = *&__dst[v16 + 8];
  *&__dst[v16 + 8] = *&__src[v16 + 8];
  v17;
  v18 = a3[9];
  __dst[v18 + 8] = __src[v18 + 8];
  *&__dst[v18] = *&__src[v18];
  return __dst;
}

uint64_t sub_2B77B7(uint64_t a1, unsigned int a2, uint64_t a3)
{
  v4 = 0;
  v5 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  if (*(*(v5 - 8) + 84) == a2)
  {
    return __swift_getEnumTagSinglePayload(a1, a2, v5);
  }

  v7 = -1;
  if (((*(a1 + *(a3 + 20)) >> 1) - 1) >= 0)
  {
    v7 = (*(a1 + *(a3 + 20)) >> 1) - 1;
  }

  v8 = v7 + 1;
  if ((*(a1 + *(a3 + 20)) & 0xFFFFFFFF00000001) == 0)
  {
    return v8;
  }

  return v4;
}

uint64_t sub_2B7839(uint64_t a1, unsigned int a2, int a3, uint64_t a4)
{
  v6 = type metadata accessor for MLTextClassifier.ModelAlgorithmType(0);
  if (*(*(v6 - 8) + 84) == a3)
  {
    return __swift_storeEnumTagSinglePayload(a1, a2, a2, v6);
  }

  result = *(a4 + 20);
  *(a1 + result) = 2 * a2;
  return result;
}

uint64_t type metadata completion function for MLTextClassifier.ModelParameters(uint64_t a1)
{
  result = type metadata accessor for MLTextClassifier.ModelAlgorithmType(319);
  if (v2 <= 0x3F)
  {
    v3[0] = *(result - 8) + 64;
    v3[1] = "\b";
    v3[2] = &unk_348ED0;
    v3[3] = &unk_348EE8;
    v3[4] = &unk_348EE8;
    v3[5] = &unk_348F00;
    swift_initStructMetadata(a1, 256, 6, v3, a1 + 16);
    return 0;
  }

  return result;
}

uint64_t MLHandActionClassifier.GraphCNN.compile()()
{
  v1[2] = v0;
  v2 = type metadata accessor for Model(0);
  v1[3] = v2;
  v3 = *(v2 - 8);
  v1[4] = v3;
  v1[5] = swift_task_alloc((*(v3 + 64) + 15) & 0xFFFFFFFFFFFFFFF0);
  return swift_task_switch(MLHandActionClassifier.GraphCNN.compile(), 0, 0);
}

{
  v6[12] = v0 | 0x1000000000000000;
  v6[11] = v1;
  v2 = v1[2];
  v3 = v1[5];
  memset(v6, 0, 72);
  MLHandActionClassifier.GraphCNN.export(metadata:)(v6);
  type metadata accessor for MLModel();
  v4 = swift_task_alloc(208);
  v1[6] = v4;
  *v4 = v1;
  v4[1] = MLHandActionClassifier.GraphCNN.compile();
  return static MLModel.compile(_:)(v1[5]);
}

{
  v1 = *(v0 + 40);
  (*(*(v0 + 32) + 8))(v1, *(v0 + 24));
  v1;
  return (*(v0 + 8))(*(v0 + 64));
}

{
  v1 = *(v0 + 40);
  (*(*(v0 + 32) + 8))(v1, *(v0 + 24));
  v1;
  v2 = *(v0 + 56);
  return (*(v0 + 8))();
}

uint64_t MLHandActionClassifier.GraphCNN.compile()(uint64_t a1)
{
  v5 = *(*v2 + 48);
  v4 = *v2;
  *(*v2 + 56) = v1;
  v5;
  if (v1)
  {
    v6 = MLHandActionClassifier.GraphCNN.compile();
  }

  else
  {
    *(v4 + 64) = a1;
    v6 = MLHandActionClassifier.GraphCNN.compile();
  }

  return swift_task_switch(v6, 0, 0);
}

void *MLHandActionClassifier.GraphCNN.trainableSublayers()()
{
  v49 = type metadata accessor for BatchNorm(0);
  v52 = *(v49 - 8);
  v1 = *(v52 + 64);
  v2 = alloca(v1);
  v3 = alloca(v1);
  v50 = &v35;
  v46 = type metadata accessor for Dense(0);
  v51 = *(v46 - 8);
  v4 = *(v51 + 64);
  v5 = alloca(v4);
  v6 = alloca(v4);
  v47 = &v35;
  v44 = type metadata accessor for Conv2D(0);
  v48 = *(v44 - 8);
  v7 = *(v48 + 64);
  v8 = alloca(v7);
  v9 = alloca(v7);
  v45 = &v35;
  v10 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  v11 = *(*(v10 - 8) + 64);
  v12 = alloca(v11);
  v13 = alloca(v11);
  v14 = OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model + v0;
  swift_beginAccess(v14, v37, 0, 0);
  outlined init with copy of MLTrainingSessionParameters(v14, &v35, type metadata accessor for MLHandActionClassifier.GraphCNNModel);
  v15 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, &protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  v16 = Layer.sublayers(recursively:)(1, v10, v15);
  outlined destroy of MLHandActionClassifier.GraphCNNModel(&v35, type metadata accessor for MLHandActionClassifier.GraphCNNModel);

  v57 = dispatch thunk of _AnySequenceBox._makeIterator()(v16);
  v53 = v16;
  v17 = v16;

  v58 = _swiftEmptyArrayStorage;
  while (1)
  {
    dispatch thunk of _AnyIteratorBoxBase.next()(v17);
    if (!v40)
    {
      break;
    }

    outlined init with take of TabularRegressionTask(&v39, v41);
    outlined init with copy of TabularRegressionTask(v41, v38);
    v18 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for Layer);
    v19 = v45;
    v20 = v44;
    if (swift_dynamicCast(v45, v38, v18, v44, 0))
    {
      outlined init with copy of TabularRegressionTask(v41, &v54);
      v21 = v19;
      v22 = v20;
      v23 = v48;
    }

    else
    {
      v24 = v47;
      v25 = v46;
      if (!swift_dynamicCast(v47, v38, v18, v46, 0))
      {
        v26 = v50;
        v27 = v49;
        if (swift_dynamicCast(v50, v38, v18, v49, 0))
        {
          outlined init with copy of TabularRegressionTask(v41, &v54);
          (*(v52 + 8))(v26, v27);
        }

        else
        {
          v28 = v42;
          v29 = v43;
          __swift_project_boxed_opaque_existential_0Tm(v41, v42);
          v30 = Layer.parameters(recursively:)(0, v28, v29);
          v31 = *(v30 + 16);
          v30;
          if (v31)
          {
            outlined init with copy of TabularRegressionTask(v41, &v54);
          }

          else
          {
            v55 = 0;
            v54 = 0;
            v56 = 0;
          }
        }

        goto LABEL_13;
      }

      outlined init with copy of TabularRegressionTask(v41, &v54);
      v21 = v24;
      v22 = v25;
      v23 = v51;
    }

    (*(v23 + 8))(v21, v22);
LABEL_13:
    __swift_destroy_boxed_opaque_existential_1Tm(v38);
    __swift_destroy_boxed_opaque_existential_1Tm(v41);
    if (*(&v55 + 1))
    {
      outlined init with take of TabularRegressionTask(&v54, v36);
      outlined init with take of TabularRegressionTask(v36, &v54);
      if (!swift_isUniquelyReferenced_nonNull_native(v58))
      {
        v58 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(0, v58[2] + 1, 1, v58);
      }

      v32 = v58[2];
      if (v58[3] >> 1 <= v32)
      {
        v58 = specialized _ArrayBuffer._consumeAndCreateNew(bufferIsUnique:minimumCapacity:growForAppend:)(v58[3] >= 2uLL, v32 + 1, 1, v58);
      }

      v33 = v58;
      v58[2] = v32 + 1;
      v17 = &v54;
      outlined init with take of TabularRegressionTask(&v54, &v33[5 * v32 + 4]);
    }

    else
    {
      v17 = &v54;
      outlined destroy of Either<LogisticRegressionClassifier<Float, String>, FullyConnectedNetworkClassifier<Float, String>>(&v54, &demangling cache variable for type metadata for Layer?);
    }
  }

  return v58;
}

uint64_t MLHandActionClassifier.GraphCNN.export(metadata:)(uint64_t *a1)
{
  v115 = v2;
  v123 = v1;
  v86 = type metadata accessor for ModelKind(0);
  v87 = *(v86 - 8);
  v3 = *(v87 + 64);
  v4 = alloca(v3);
  v5 = alloca(v3);
  v88 = &v83;
  v89 = type metadata accessor for NeuralNetworkClassifier.ClassLabels(0);
  v90 = *(v89 - 8);
  v6 = *(v90 + 64);
  v7 = alloca(v6);
  v8 = alloca(v6);
  v92 = &v83;
  v94 = type metadata accessor for NeuralNetwork.ArrayShapeMapping(0);
  v95 = *(v94 - 8);
  v9 = *(v95 + 64);
  v10 = alloca(v9);
  v11 = alloca(v9);
  v96 = &v83;
  v91 = type metadata accessor for NeuralNetworkClassifier(0);
  v116 = *(v91 - 8);
  v12 = *(v116 + 64);
  v13 = alloca(v12);
  v14 = alloca(v12);
  v93 = &v83;
  v118 = type metadata accessor for FeatureType.ShapedArrayParameters.DataType(0);
  v117 = *(v118 - 8);
  v15 = *(v117 + 64);
  v16 = alloca(v15);
  v17 = alloca(v15);
  v106 = &v83;
  v98 = type metadata accessor for FeatureType(0);
  v99 = *(v98 - 8);
  v18 = *(v99 + 64);
  v19 = alloca(v18);
  v20 = alloca(v18);
  v124 = &v83;
  v21 = alloca(v18);
  v22 = alloca(v18);
  v100 = &v83;
  v23 = alloca(v18);
  v24 = alloca(v18);
  v126 = &v83;
  v25 = type metadata accessor for LearningPhase(0);
  v127 = *(v25 - 8);
  v121 = v25;
  v26 = *(v127 + 64);
  v27 = alloca(v26);
  v28 = alloca(v26);
  v110 = *a1;
  v97 = a1[1];
  v113 = a1[2];
  v114 = a1[3];
  v108 = a1[4];
  v109 = a1[5];
  v111 = a1[6];
  v112 = a1[7];
  v107 = a1[8];
  v29 = v2 + OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model;
  swift_beginAccess(v2 + OBJC_IVAR____TtCV8CreateML22MLHandActionClassifier8GraphCNN_model, &v119, 33, 0);
  v30 = type metadata accessor for MLHandActionClassifier.GraphCNNModel(0);
  v31 = *(v30 + 36);
  v122 = v30;
  *(v31 + v29) = 1;
  v125 = v29;
  v32 = v25;
  v33 = v127;
  (*(v127 + 104))(&v83, enum case for LearningPhase.inference(_:), v32);
  v34 = lazy protocol witness table accessor for type VNImageOption and conformance VNImageOption(&lazy protocol witness table cache variable for type MLHandActionClassifier.GraphCNNModel and conformance MLHandActionClassifier.GraphCNNModel, type metadata accessor for MLHandActionClassifier.GraphCNNModel, &protocol conformance descriptor for MLHandActionClassifier.GraphCNNModel);
  Layer.prepare(for:)(&v83, v30, v34);
  swift_endAccess(&v119);
  (*(v33 + 8))(&v83, v121);
  v121 = MLHandActionClassifier.GraphCNN.updatedCoreMLLayers()();
  Model.init()();
  Model.specificationVersion.setter(4);
  v35 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<FeatureDescription>);
  v101 = v35;
  v36 = *(type metadata accessor for FeatureDescription(0) - 8);
  v127 = *(v36 + 72);
  v37 = *(v36 + 80);
  v38 = (v37 + 32) & ~v37;
  v103 = v38;
  v102 = v37 | 7;
  v39 = swift_allocObject(v35, v38 + v127, v37 | 7);
  v104 = v39;
  *(v39 + 16) = 1;
  *(v39 + 24) = 2;
  v105 = v38 + v39;
  v40 = v106;
  (*(v117 + 104))(v106, enum case for FeatureType.ShapedArrayParameters.DataType.float32(_:), v118);
  v41 = __swift_instantiateConcreteTypeFromMangledName(&demangling cache variable for type metadata for _ContiguousArrayStorage<Int>);
  v42 = swift_allocObject(v41, 56, 7);
  v42[2] = 3;
  v42[3] = 6;
  v43 = v122;
  v44 = v125;
  v42[4] = *(*(v122 + 40) + v125);
  v42[5] = 3;
  v42[6] = 21;
  static FeatureType.shapedArray(dataType:shape:optional:)(v40, v42, 0);
  v42;
  (*(v117 + 8))(v40, v118);
  v119 = 0;
  v120 = 0xE000000000000000;
  _StringGuts.grow(_:)(446);
  v48._object = 0xE200000000000000;
  v48._countAndFlagsBits = 8257;
  String.append(_:)(v48);
  v45 = *(v43 + 40);
  v46 = v43;
  v47 = *(v45 + v44) < 2;
  v48._countAndFlagsBits = 0x736F7020646E6168;
  if (*(v45 + v44) >= 2)
  {
    v48._countAndFlagsBits = 0xD000000000000016;
  }

  v49 = 0xE900000000000065;
  if (!v47)
  {
    v49 = "Most likely hand " + 0x8000000000000000;
  }

  v48._object = v49;
  String.append(_:)(v48);
  v49;
  v50._object = " channels, but coreml has " + 0x8000000000000000;
  v50._countAndFlagsBits = 0xD000000000000052;
  String.append(_:)(v50);
  v51 = v125;
  v84 = *(*(v46 + 40) + v125);
  v52 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  v54 = v53;
  v50._countAndFlagsBits = v52;
  v50._object = v53;
  String.append(_:)(v50);
  v54;
  v50._countAndFlagsBits = 0x656D61726620;
  v56._object = 0xE600000000000000;
  String.append(_:)(v56);
  v55 = *(v46 + 40);
  v56._countAndFlagsBits = 115;
  if (*(v55 + v51) < 2)
  {
    v56._countAndFlagsBits = 0;
  }

  v56._object = (((*(v55 + v51) >= 2) | 0xFFFFFFFFFFFFFFE0) << 56);
  String.append(_:)(v56);
  v56._object;
  v61._object = "o index time over " + 0x8000000000000000;
  v61._countAndFlagsBits = 0xD00000000000015ELL;
  String.append(_:)(v61);
  FeatureDescription.init(name:type:description:)(0x7365736F70, 0xE500000000000000, v126, v119, v120);
  Model.inputs.setter(v104);
  v57 = swift_allocObject(v101, v103 + 2 * v127, v102);
  v126 = v57;
  *(v57 + 16) = 2;
  *(v57 + 24) = 4;
  v58 = v100;
  static FeatureType.dictionaryWithStringKeys(optional:)(0);
  FeatureDescription.init(name:type:description:)(0xD000000000000012, "shape does not match." + 0x8000000000000000, v58, 0xD000000000000039, "ttlePIP, littleDIP, littleTip." + 0x8000000000000000);
  v59 = v124;
  FeatureType.StringParameters.init(optional:)(0);
  (*(v99 + 104))(v59, enum case for FeatureType.string(_:), v98);
  v119 = 0;
  v120 = 0xE000000000000000;
  _StringGuts.grow(_:)(29);
  v120;
  v84 = 0xD000000000000011;
  v85 = "orresponding confidences." + 0x8000000000000000;
  v60 = *(v122 + 40);
  v61._countAndFlagsBits = 1702063984;
  if (*(v60 + v125) >= 2)
  {
    v61._countAndFlagsBits = 0x6E6F69746361;
  }

  v62 = ((*(v60 + v125) >= 2) | 0xFFFFFFFFFFFFFFF2) << 57;
  v61._object = v62;
  String.append(_:)(v61);
  v62;
  v63._countAndFlagsBits = 0x726F676574616320;
  v63._object = 0xEA00000000002E79;
  String.append(_:)(v63);
  FeatureDescription.init(name:type:description:)(0x6C6562616CLL, 0xE500000000000000, v124, v84, v85);
  Model.outputs.setter(v126);
  v64 = v97;
  Model.predictedFeatureName.setter(0x6C6562616CLL, 0xE500000000000000);
  v124 = "shape does not match." + 0x8000000000000000;
  Model.predictedProbabilitiesName.setter(0xD000000000000012, "shape does not match." + 0x8000000000000000);
  if (v64)
  {
    v65 = v114;
    v114;
    Model.modelDescription.setter(v113, v65);
    v66 = v112;
    v112;
    Model.versionString.setter(v111, v66);
    v64;
    Model.author.setter(v110, v64);
    v67 = v108;
    if (!v109)
    {
      v67 = 0;
    }

    v68 = 0xE000000000000000;
    if (v109)
    {
      v68 = v109;
    }

    v109;
    Model.license.setter(v67, v68);
    v69 = v107;
    if (v107)
    {
      v70 = v107;
    }

    else
    {
      v70 = Dictionary.init(dictionaryLiteral:)(_swiftEmptyArrayStorage, &type metadata for String, &type metadata for String, &protocol witness table for String);
      v69 = 0;
    }

    v69;
    Model.metadata.setter(v70);
  }

  v119 = *(v125 + *(v122 + 40));
  v71 = dispatch thunk of CustomStringConvertible.description.getter(&type metadata for Int, &protocol witness table for Int);
  v127 = v72;
  v126 = Model.metadata.modify(&v119);
  v74 = v73;
  isUniquelyReferenced_nonNull_native = swift_isUniquelyReferenced_nonNull_native(*v73);
  v83 = *v74;
  *v74 = 0x8000000000000000;
  specialized _NativeDictionary.setValue(_:forKey:isUnique:)(v71, v127, 0xD000000000000016, ("Number of Labels" + 0x8000000000000000), isUniquelyReferenced_nonNull_native);
  *v74 = v83;
  (v126)(&v119, 0);
  v76 = v93;
  NeuralNetworkClassifier.init(layers:preprocessors:)(v121, _swiftEmptyArrayStorage);
  v77 = v96;
  (*(v95 + 104))(v96, enum case for NeuralNetwork.ArrayShapeMapping.exactArrayMapping(_:), v94);
  NeuralNetworkClassifier.arrayInputShapeMapping.setter(v77);
  NeuralNetworkClassifier.labelProbabilityLayerName.setter(0xD000000000000012, v124);
  v78 = *(v115 + 16);
  v79 = v92;
  *v92 = v78;
  (*(v90 + 104))(v79, enum case for NeuralNetworkClassifier.ClassLabels.string(_:), v89);
  v78;
  NeuralNetworkClassifier.classLabels.setter(v79);
  v80 = v88;
  v81 = v91;
  (*(v116 + 16))(v88, v76, v91);
  (*(v87 + 104))(v80, enum case for ModelKind.neuralNetworkClassifier(_:), v86);
  Model.kind.setter(v80);
  (*(v116 + 8))(v76, v81);
  result = *(v122 + 36);
  *(v125 + result) = 0;
  return result;
}