uint64_t vt_Copy_420vITU601_24RGB_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = *a4;
  v7 = a4[1];
  v8 = v7 + 1;
  v9 = *a6;
  v124 = a1;
  v117 = a2;
  if (a2 >= 2)
  {
    v11 = 0;
    v12 = a2 >> 1;
    v13 = a3[1];
    v14 = *a5;
    v15 = 4 * (a1 >> 3);
    v125 = 2 * *a3;
    v121 = *a3;
    v122 = a2 >> 1;
    v16 = &v6[*a3];
    v123 = a1 >> 3;
    v118 = (a1 >> 1) - v15;
    v119 = v15;
    v17.i64[0] = 0xFF000000FFLL;
    v17.i64[1] = 0xFF000000FFLL;
    v18.i64[0] = 0x7F0000007FLL;
    v18.i64[1] = 0x7F0000007FLL;
    v19 = vdupq_n_s32(0xFFFFCDDC);
    v20 = vdupq_n_s32(0xFFFF97F2);
    v21 = vdupq_n_s32(0x10235u);
    v22 = vdupq_n_s32(0xCC4Bu);
    v23 = vdupq_n_s16(0x950Bu);
    v24 = vdupq_n_s32(0xFFF6AF50);
    v10 = a1 >> 1;
    v120 = v13;
    do
    {
      if (a1 >= 8)
      {
        v31 = 0;
        v32 = v123;
        v27 = v9;
        do
        {
          v33 = *&v7[v31];
          v34 = &v27[v14];
          v35 = vaddw_u16(v18, *&vmovl_u8(vuzp1_s8(v33, 0xFF000000FFLL)));
          v36 = vaddw_u16(v18, *&vmovl_u8(vuzp2_s8(v33, 0xFF000000FFLL)));
          v37 = vmlaq_s32(vmulq_s32(v35, v19), v36, v20);
          v38 = vmulq_s32(v35, v21);
          v39 = vmulq_s32(v36, v22);
          v40 = vzip1q_s32(v38, v38);
          v41 = vzip2q_s32(v38, v38);
          v42 = vzip1q_s32(v39, v39);
          v43 = vzip1q_s32(v37, v37);
          v44 = vmovl_u8(*&v6[v31]);
          v45 = vmovl_u8(*&v16[v31]);
          v46 = vmlal_u16(v24, *v44.i8, *v23.i8);
          v47 = vzip2q_s32(v39, v39);
          v48 = vmlal_high_u16(v24, v44, v23);
          v49 = vmlal_u16(v24, *v45.i8, *v23.i8);
          v50 = vzip2q_s32(v37, v37);
          v51 = vmlal_high_u16(v24, v45, v23);
          v126.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v46), 0xFuLL), vaddq_s32(v47, v48), 0xFuLL));
          v126.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v46), 0xFuLL), vaddq_s32(v50, v48), 0xFuLL));
          v127.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v49), 0xFuLL), vaddq_s32(v47, v51), 0xFuLL));
          v126.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v46), 0xFuLL), vaddq_s32(v41, v48), 0xFuLL));
          v127.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v49), 0xFuLL), vaddq_s32(v50, v51), 0xFuLL));
          vst3_s8(v27, v126);
          v27 += 24;
          v127.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v49), 0xFuLL), vaddq_s32(v41, v51), 0xFuLL));
          vst3_s8(v34, v127);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v6[v31];
        v25 = &v16[v31];
        v29 = &v7[v31];
        v28 = &v7[v31 + 1];
        v26 = &v27[v14];
      }

      else
      {
        v25 = &v6[v121];
        v26 = &v9[v14];
        v27 = v9;
        v28 = v8;
        v29 = v7;
        v30 = v6;
      }

      if (v10 > v15)
      {
        v52 = v118;
        do
        {
          v54 = *v29;
          v29 += 2;
          v53 = v54;
          v55 = *v28;
          v28 += 2;
          v56 = v53 - 128;
          v57 = -12836 * (v53 - 128) - 26638 * (v55 - 128);
          v58 = 66101 * v56;
          v59 = 52299 * (v55 - 128);
          v60 = 38155 * v30[1] - 610480;
          v61 = (v60 + v57) >> 15;
          if (v61 >= 255)
          {
            v61 = 255;
          }

          v62 = (v60 + v58) >> 15;
          v63 = v61 & ~(v61 >> 31);
          if (v62 >= 255)
          {
            v62 = 255;
          }

          v64.i32[0] = 38155 * *v30 - 610480;
          v64.i32[1] = v57;
          v64.i64[1] = __PAIR64__(v60, v64.u32[0]);
          v65.i32[0] = v59;
          v66.i64[0] = __PAIR64__(v64.u32[0], v59);
          v66.i64[1] = __PAIR64__(v59, v58);
          v30 += 2;
          *v27 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v64, v66), 0xFuLL), v17), 0)), *v17.i8).u32[0];
          v27[4] = v63;
          v27[5] = v62 & ~(v62 >> 31);
          v27 += 6;
          v67 = *v25;
          v68 = v25[1];
          v25 += 2;
          v69 = 38155 * v67 - 610480;
          v70 = 38155 * v68 - 610480;
          v71 = (v70 + v57) >> 15;
          if (v71 >= 255)
          {
            v71 = 255;
          }

          v65.i32[1] = v69;
          v72 = vdupq_lane_s32(*v65.i8, 1);
          v65.i64[1] = __PAIR64__(v59, v58);
          v72.i32[1] = v57;
          v72.i32[3] = v70;
          if ((v70 + v58) >> 15 >= 255)
          {
            v73 = 255;
          }

          else
          {
            v73 = (v70 + v58) >> 15;
          }

          *v26 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v65, v72), 0xFuLL), v17), 0)), *v17.i8).u32[0];
          v26[4] = v71 & ~(v71 >> 31);
          v26[5] = v73 & ~(v73 >> 31);
          v26 += 6;
          --v52;
        }

        while (v52);
        a1 = v124;
        v12 = v122;
        v15 = v119;
        v13 = v120;
      }

      if (a1)
      {
        v74 = *v29 - 128;
        v75 = *v28 - 128;
        v76 = 38155 * *v30 - 610480;
        v77 = -12836 * v74 - 26638 * v75;
        v78 = 66101 * v74;
        v79 = 52299 * v75;
        v80 = (v76 + v79) >> 15;
        if (v80 >= 255)
        {
          v80 = 255;
        }

        v81 = v80 & ~(v80 >> 31);
        v82 = (v77 + v76) >> 15;
        if (v82 >= 255)
        {
          v82 = 255;
        }

        v83 = v82 & ~(v82 >> 31);
        v84 = (v76 + v78) >> 15;
        if (v84 >= 255)
        {
          v84 = 255;
        }

        *v27 = v81;
        v27[1] = v83;
        v27[2] = v84 & ~(v84 >> 31);
        v85 = 38155 * *v25 - 610480;
        v86 = (v85 + v79) >> 15;
        if (v86 >= 255)
        {
          v86 = 255;
        }

        v87 = v86 & ~(v86 >> 31);
        v88 = (v85 + v77) >> 15;
        if (v88 >= 255)
        {
          v88 = 255;
        }

        v89 = v88 & ~(v88 >> 31);
        v90 = (v85 + v78) >> 15;
        if (v90 >= 255)
        {
          v90 = 255;
        }

        *v26 = v87;
        v26[1] = v89;
        v26[2] = v90 & ~(v90 >> 31);
      }

      v6 += v125;
      v7 += v13;
      v8 += v13;
      v9 += 2 * v14;
      ++v11;
      v16 += v125;
    }

    while (v11 != v12);
  }

  else
  {
    v10 = a1 >> 1;
  }

  if (v117)
  {
    if (a1 >= 2)
    {
      v91.i64[0] = 0xFF000000FFLL;
      v91.i64[1] = 0xFF000000FFLL;
      do
      {
        v92 = *v7;
        v7 += 2;
        v93 = v92 - 128;
        v94 = *v8;
        v8 += 2;
        v95 = *v6;
        v96 = v6[1];
        v6 += 2;
        v97 = 38155 * v95 - 610480;
        v98 = -12836 * v93 - 26638 * (v94 - 128);
        v99 = 52299 * (v94 - 128);
        v100 = 66101 * v93;
        v101 = 38155 * v96 - 610480;
        v102 = (v101 + v98) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = v102 & ~(v102 >> 31);
        v104.i64[0] = __PAIR64__(v98, v97);
        v104.i64[1] = __PAIR64__(v101, v97);
        v105.i64[0] = __PAIR64__(v97, v99);
        v105.i64[1] = __PAIR64__(v99, v100);
        if ((v101 + v100) >> 15 >= 255)
        {
          v106 = 255;
        }

        else
        {
          v106 = (v101 + v100) >> 15;
        }

        *v9 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v104, v105), 0xFuLL), v91), 0)), *v91.i8).u32[0];
        v9[4] = v103;
        v9[5] = v106 & ~(v106 >> 31);
        v9 += 6;
        --v10;
      }

      while (v10);
      LOBYTE(a1) = v124;
    }

    if (a1)
    {
      v107 = *v7 - 128;
      v108 = *v8 - 128;
      v109 = 38155 * *v6 - 610480;
      v110 = -12836 * v107 - 26638 * v108;
      v111 = (v109 + 52299 * v108) >> 15;
      if (v111 >= 255)
      {
        v111 = 255;
      }

      v112 = v111 & ~(v111 >> 31);
      v113 = (v110 + v109) >> 15;
      if (v113 >= 255)
      {
        v113 = 255;
      }

      v114 = v113 & ~(v113 >> 31);
      v115 = (v109 + 66101 * v107) >> 15;
      if (v115 >= 255)
      {
        v115 = 255;
      }

      *v9 = v112;
      v9[1] = v114;
      v9[2] = v115 & ~(v115 >> 31);
    }
  }

  return 0;
}

uint64_t vt_Copy_420fITU601F_32BGRA_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = a1 >> 1;
  v7 = *a4;
  v8 = a4[1];
  v9 = v8 + 1;
  v10 = *a6;
  v134 = a2;
  if (a2 >= 2)
  {
    v12 = 0;
    v13 = a2 >> 1;
    v14 = *a3;
    v15 = a3[1];
    v16 = *a5;
    v17 = 4 * (a1 >> 3);
    v141 = 2 * v14;
    v142 = v15;
    v137 = v14;
    v138 = a2 >> 1;
    v18 = &v7[v14];
    v139 = a1 >> 3;
    v135 = v6 - v17;
    v136 = v17;
    v19 = vdupq_n_s32(0xFFFFD3F4);
    v20 = vdupq_n_s32(0xFFFFA498);
    v21.i64[0] = 0x7F0000007FLL;
    v21.i64[1] = 0x7F0000007FLL;
    v22 = vdupq_n_s32(0xE2D1u);
    v23 = vdupq_n_s32(0xB375u);
    v24 = -1;
    v11 = a1;
    do
    {
      if (v11 >= 8)
      {
        v31 = 0;
        v32 = v139;
        v27 = v10;
        do
        {
          v33 = &v27[v16];
          v34 = *&v8[v31];
          v35 = vaddw_u16(v21, *&vmovl_u8(vuzp1_s8(v34, *v19.i8)));
          v36 = vaddw_u16(v21, *&vmovl_u8(vuzp2_s8(v34, *v19.i8)));
          v37 = vmulq_s32(v35, v19);
          v38 = vmulq_s32(v35, v22);
          v39 = vmulq_s32(v36, v23);
          v40 = vmlaq_s32(v37, v36, v20);
          v41 = vzip1q_s32(v38, v38);
          v42 = vzip2q_s32(v38, v38);
          v43 = vzip1q_s32(v39, v39);
          v44 = vzip1q_s32(v40, v40);
          v45 = vmovl_u8(*&v7[v31]);
          v46 = vmovl_u8(*&v18[v31]);
          v47 = vshll_n_u16(*v45.i8, 0xFuLL);
          v48 = vzip2q_s32(v39, v39);
          v49 = vshll_high_n_u16(v45, 0xFuLL);
          v50 = vshll_n_u16(*v46.i8, 0xFuLL);
          v51 = vshll_high_n_u16(v46, 0xFuLL);
          v52 = vzip2q_s32(v40, v40);
          v53 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v47), 0xFuLL), vaddq_s32(v48, v49), 0xFuLL));
          v54 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v47), 0xFuLL), vaddq_s32(v52, v49), 0xFuLL));
          v143.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v50), 0xFuLL), vaddq_s32(v48, v51), 0xFuLL));
          v55 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v47), 0xFuLL), vaddq_s32(v42, v49), 0xFuLL));
          v143.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v50), 0xFuLL), vaddq_s32(v52, v51), 0xFuLL));
          vst4_s8(v27, *(&v24 - 3));
          v27 += 32;
          v143.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v50), 0xFuLL), vaddq_s32(v42, v51), 0xFuLL));
          v143.val[3] = -1;
          vst4_s8(v33, v143);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v7[v31];
        v25 = &v18[v31];
        v29 = &v8[v31];
        v28 = &v8[v31 + 1];
        v26 = &v27[v16];
      }

      else
      {
        v25 = &v7[v137];
        v26 = &v10[v16];
        v27 = v10;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v6 > v17)
      {
        v56 = v135;
        do
        {
          v58 = *v29;
          v29 += 2;
          v57 = v58;
          v59 = *v28;
          v28 += 2;
          v60 = v57 - 128;
          v61 = *v30;
          v62 = v30[1];
          v30 += 2;
          v63 = -11276 * (v57 - 128) - 23400 * (v59 - 128);
          v64 = 45941 * (v59 - 128);
          v65 = 58065 * v60;
          v66 = (v64 + (v61 << 15)) >> 15;
          if (v66 >= 255)
          {
            v66 = 255;
          }

          v67 = v66 & ~(v66 >> 31);
          v68 = (v63 + (v61 << 15)) >> 15;
          if (v68 >= 255)
          {
            v68 = 255;
          }

          v69 = v68 & ~(v68 >> 31);
          v70 = (v65 + (v61 << 15)) >> 15;
          if (v70 >= 255)
          {
            v70 = 255;
          }

          v71 = v70 & ~(v70 >> 31);
          v72 = (v64 + (v62 << 15)) >> 15;
          if (v72 >= 255)
          {
            v72 = 255;
          }

          v73 = (v63 + (v62 << 15)) >> 15;
          v74 = v72 & ~(v72 >> 31);
          if (v73 >= 255)
          {
            v73 = 255;
          }

          v75 = (v65 + (v62 << 15)) >> 15;
          v76 = v73 & ~(v73 >> 31);
          if (v75 >= 255)
          {
            v75 = 255;
          }

          v27[1] = v69;
          v27[2] = v67;
          v27[3] = -1;
          *v27 = v71;
          v27[4] = v75 & ~(v75 >> 31);
          v27[5] = v76;
          v27[6] = v74;
          v27[7] = -1;
          v77 = *v25;
          v27 += 8;
          v78 = v25[1];
          v25 += 2;
          v79 = (v64 + (v77 << 15)) >> 15;
          if (v79 >= 255)
          {
            v79 = 255;
          }

          v80 = v79 & ~(v79 >> 31);
          v81 = (v63 + (v77 << 15)) >> 15;
          if (v81 >= 255)
          {
            v81 = 255;
          }

          v82 = v81 & ~(v81 >> 31);
          v83 = (v65 + (v77 << 15)) >> 15;
          if (v83 >= 255)
          {
            v83 = 255;
          }

          v84 = v83 & ~(v83 >> 31);
          v85 = (v64 + (v78 << 15)) >> 15;
          if (v85 >= 255)
          {
            v85 = 255;
          }

          v86 = (v63 + (v78 << 15)) >> 15;
          if (v86 >= 255)
          {
            v86 = 255;
          }

          v87 = v86 & ~(v86 >> 31);
          v88 = (v65 + (v78 << 15)) >> 15;
          *v26 = v84;
          v26[1] = v82;
          if (v88 >= 255)
          {
            v89 = 255;
          }

          else
          {
            v89 = v88;
          }

          v26[2] = v80;
          v26[3] = -1;
          v26[4] = v89 & ~(v89 >> 31);
          v26[5] = v87;
          v26[6] = v85 & ~(v85 >> 31);
          v26[7] = -1;
          v26 += 8;
          --v56;
        }

        while (v56);
        v11 = a1;
        v13 = v138;
        v17 = v136;
      }

      if (v11)
      {
        v90 = *v29 - 128;
        v91 = *v28 - 128;
        v92 = *v30;
        v93 = -11276 * v90 - 23400 * v91;
        v94 = 58065 * v90;
        v95 = 45941 * v91;
        v96 = (v95 + (v92 << 15)) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        v97 = v96 & ~(v96 >> 31);
        v98 = (v93 + (v92 << 15)) >> 15;
        if (v98 >= 255)
        {
          v98 = 255;
        }

        v99 = v98 & ~(v98 >> 31);
        v100 = (v94 + (v92 << 15)) >> 15;
        if (v100 >= 255)
        {
          v100 = 255;
        }

        *v27 = v100 & ~(v100 >> 31);
        v27[1] = v99;
        v27[2] = v97;
        v27[3] = -1;
        v101 = *v25;
        v102 = (v95 + (v101 << 15)) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = (v93 + (v101 << 15)) >> 15;
        if (v103 >= 255)
        {
          v103 = 255;
        }

        v104 = v103 & ~(v103 >> 31);
        v105 = (v94 + (v101 << 15)) >> 15;
        if (v105 >= 255)
        {
          v105 = 255;
        }

        *v26 = v105 & ~(v105 >> 31);
        v26[1] = v104;
        v26[2] = v102 & ~(v102 >> 31);
        v26[3] = -1;
      }

      v7 += v141;
      v8 += v142;
      v9 += v142;
      v10 += 2 * v16;
      ++v12;
      v18 += v141;
    }

    while (v12 != v13);
  }

  else
  {
    v11 = a1;
  }

  if (v134)
  {
    if (v11 >= 2)
    {
      do
      {
        v106 = *v8;
        v8 += 2;
        v107 = v106 - 128;
        v108 = *v9;
        v9 += 2;
        v109 = *v7;
        v110 = v7[1];
        v7 += 2;
        v111 = -11276 * v107 - 23400 * (v108 - 128);
        v112 = 45941 * (v108 - 128);
        v113 = (v112 + (v109 << 15)) >> 15;
        if (v113 >= 255)
        {
          v113 = 255;
        }

        v114 = v113 & ~(v113 >> 31);
        v115 = (v111 + (v109 << 15)) >> 15;
        v116 = 58065 * v107;
        if (v115 >= 255)
        {
          v115 = 255;
        }

        v117 = v115 & ~(v115 >> 31);
        v118 = (v116 + (v109 << 15)) >> 15;
        if (v118 >= 255)
        {
          v118 = 255;
        }

        v119 = v118 & ~(v118 >> 31);
        v120 = (v112 + (v110 << 15)) >> 15;
        if (v120 >= 255)
        {
          v120 = 255;
        }

        v121 = (v111 + (v110 << 15)) >> 15;
        if (v121 >= 255)
        {
          v121 = 255;
        }

        v122 = v121 & ~(v121 >> 31);
        v123 = (v116 + (v110 << 15)) >> 15;
        *v10 = v119;
        v10[1] = v117;
        if (v123 >= 255)
        {
          v123 = 255;
        }

        v10[2] = v114;
        v10[3] = -1;
        v10[4] = v123 & ~(v123 >> 31);
        v10[5] = v122;
        v10[6] = v120 & ~(v120 >> 31);
        v10[7] = -1;
        v10 += 8;
        --v6;
      }

      while (v6);
      LOBYTE(v11) = a1;
    }

    if (v11)
    {
      v124 = *v8 - 128;
      v125 = *v9 - 128;
      v126 = *v7;
      v127 = -11276 * v124 - 23400 * v125;
      v128 = 58065 * v124;
      v129 = (45941 * v125 + (v126 << 15)) >> 15;
      if (v129 >= 255)
      {
        v129 = 255;
      }

      v130 = (v127 + (v126 << 15)) >> 15;
      if (v130 >= 255)
      {
        v130 = 255;
      }

      v131 = v130 & ~(v130 >> 31);
      v132 = (v128 + (v126 << 15)) >> 15;
      if (v132 >= 255)
      {
        v132 = 255;
      }

      *v10 = v132 & ~(v132 >> 31);
      v10[1] = v131;
      v10[2] = v129 & ~(v129 >> 31);
      v10[3] = -1;
    }
  }

  return 0;
}

uint64_t vt_Copy_420fITU601F_32ARGB_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = a1 >> 1;
  v7 = *a4;
  v8 = a4[1];
  v9 = v8 + 1;
  v10 = *a6;
  v137 = a2;
  if (a2 >= 2)
  {
    v12 = 0;
    v13 = a2 >> 1;
    v14 = *a3;
    v15 = a3[1];
    v16 = *a5;
    v17 = 4 * (a1 >> 3);
    v144 = 2 * v14;
    v145 = v15;
    v140 = v14;
    v141 = a2 >> 1;
    v18 = &v7[v14];
    v142 = a1 >> 3;
    v138 = v6 - v17;
    v139 = v17;
    v19 = vdupq_n_s32(0xFFFFD3F4);
    v20 = vdupq_n_s32(0xFFFFA498);
    v21.i64[0] = 0x7F0000007FLL;
    v21.i64[1] = 0x7F0000007FLL;
    v22 = vdupq_n_s32(0xE2D1u);
    v23 = vdupq_n_s32(0xB375u);
    v24 = -1;
    v11 = a1;
    do
    {
      if (v11 >= 8)
      {
        v31 = 0;
        v32 = v142;
        v27 = v10;
        do
        {
          v33 = &v27[v16];
          v34 = *&v8[v31];
          v35 = vaddw_u16(v21, *&vmovl_u8(vuzp1_s8(v34, *v19.i8)));
          v36 = vaddw_u16(v21, *&vmovl_u8(vuzp2_s8(v34, *v19.i8)));
          v37 = vmulq_s32(v35, v19);
          v38 = vmulq_s32(v35, v22);
          v39 = vmulq_s32(v36, v23);
          v40 = vmlaq_s32(v37, v36, v20);
          v41 = vzip1q_s32(v38, v38);
          v42 = vzip2q_s32(v38, v38);
          v43 = vzip1q_s32(v39, v39);
          v44 = vzip1q_s32(v40, v40);
          v45 = vmovl_u8(*&v7[v31]);
          v46 = vmovl_u8(*&v18[v31]);
          v47 = vshll_n_u16(*v45.i8, 0xFuLL);
          v48 = vzip2q_s32(v39, v39);
          v49 = vshll_high_n_u16(v45, 0xFuLL);
          v50 = vshll_n_u16(*v46.i8, 0xFuLL);
          v51 = vshll_high_n_u16(v46, 0xFuLL);
          v52 = vzip2q_s32(v40, v40);
          v53 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v47), 0xFuLL), vaddq_s32(v48, v49), 0xFuLL));
          v54 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v47), 0xFuLL), vaddq_s32(v52, v49), 0xFuLL));
          v146.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v50), 0xFuLL), vaddq_s32(v48, v51), 0xFuLL));
          v55 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v47), 0xFuLL), vaddq_s32(v42, v49), 0xFuLL));
          v146.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v50), 0xFuLL), vaddq_s32(v52, v51), 0xFuLL));
          vst4_s8(v27, *&v24);
          v27 += 32;
          v146.val[3] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v50), 0xFuLL), vaddq_s32(v42, v51), 0xFuLL));
          v146.val[0] = -1;
          vst4_s8(v33, v146);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v7[v31];
        v25 = &v18[v31];
        v29 = &v8[v31];
        v28 = &v8[v31 + 1];
        v26 = &v27[v16];
      }

      else
      {
        v25 = &v7[v140];
        v26 = &v10[v16];
        v27 = v10;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v6 > v17)
      {
        v56 = v138;
        do
        {
          v58 = *v29;
          v29 += 2;
          v57 = v58;
          v59 = *v28;
          v28 += 2;
          v60 = v57 - 128;
          v61 = *v30;
          v62 = v30[1];
          v30 += 2;
          v63 = -11276 * (v57 - 128) - 23400 * (v59 - 128);
          v64 = 45941 * (v59 - 128);
          v65 = 58065 * v60;
          v66 = (v64 + (v61 << 15)) >> 15;
          if (v66 >= 255)
          {
            v66 = 255;
          }

          v67 = v66 & ~(v66 >> 31);
          v68 = (v63 + (v61 << 15)) >> 15;
          if (v68 >= 255)
          {
            v68 = 255;
          }

          v69 = v68 & ~(v68 >> 31);
          v70 = (v65 + (v61 << 15)) >> 15;
          if (v70 >= 255)
          {
            v70 = 255;
          }

          v71 = v70 & ~(v70 >> 31);
          v72 = (v64 + (v62 << 15)) >> 15;
          if (v72 >= 255)
          {
            v72 = 255;
          }

          v73 = (v63 + (v62 << 15)) >> 15;
          v74 = v72 & ~(v72 >> 31);
          if (v73 >= 255)
          {
            v73 = 255;
          }

          v75 = (v65 + (v62 << 15)) >> 15;
          v76 = v73 & ~(v73 >> 31);
          if (v75 >= 255)
          {
            v75 = 255;
          }

          *v27 = -1;
          v27[1] = v67;
          v27[2] = v69;
          v27[3] = v71;
          v27[4] = -1;
          v27[5] = v74;
          v27[6] = v76;
          v27[7] = v75 & ~(v75 >> 31);
          v77 = *v25;
          v27 += 8;
          v78 = v25[1];
          v25 += 2;
          v79 = (v64 + (v77 << 15)) >> 15;
          if (v79 >= 255)
          {
            v79 = 255;
          }

          v80 = v79 & ~(v79 >> 31);
          v81 = (v63 + (v77 << 15)) >> 15;
          if (v81 >= 255)
          {
            v81 = 255;
          }

          v82 = v81 & ~(v81 >> 31);
          v83 = (v65 + (v77 << 15)) >> 15;
          if (v83 >= 255)
          {
            v83 = 255;
          }

          v84 = v83 & ~(v83 >> 31);
          v85 = (v64 + (v78 << 15)) >> 15;
          if (v85 >= 255)
          {
            v85 = 255;
          }

          v86 = (v63 + (v78 << 15)) >> 15;
          v87 = v85 & ~(v85 >> 31);
          if (v86 >= 255)
          {
            v86 = 255;
          }

          v88 = (v65 + (v78 << 15)) >> 15;
          v89 = v86 & ~(v86 >> 31);
          *v26 = -1;
          v26[1] = v80;
          if (v88 >= 255)
          {
            v88 = 255;
          }

          v26[2] = v82;
          v26[4] = -1;
          v26[3] = v84;
          v26[5] = v87;
          v26[6] = v89;
          v26[7] = v88 & ~(v88 >> 31);
          v26 += 8;
          --v56;
        }

        while (v56);
        v11 = a1;
        v13 = v141;
        v17 = v139;
      }

      if (v11)
      {
        v90 = *v29 - 128;
        v91 = *v28 - 128;
        v92 = *v30;
        v93 = -11276 * v90 - 23400 * v91;
        v94 = 58065 * v90;
        v95 = 45941 * v91;
        v96 = (v95 + (v92 << 15)) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        v97 = v96 & ~(v96 >> 31);
        v98 = (v93 + (v92 << 15)) >> 15;
        if (v98 >= 255)
        {
          v98 = 255;
        }

        v99 = v98 & ~(v98 >> 31);
        v100 = (v94 + (v92 << 15)) >> 15;
        if (v100 >= 255)
        {
          v100 = 255;
        }

        *v27 = -1;
        v27[1] = v97;
        v27[2] = v99;
        v27[3] = v100 & ~(v100 >> 31);
        v101 = *v25;
        v102 = (v95 + (v101 << 15)) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = v102 & ~(v102 >> 31);
        v104 = (v93 + (v101 << 15)) >> 15;
        if (v104 >= 255)
        {
          v104 = 255;
        }

        v105 = v104 & ~(v104 >> 31);
        v106 = (v94 + (v101 << 15)) >> 15;
        if (v106 >= 255)
        {
          v106 = 255;
        }

        *v26 = -1;
        v26[1] = v103;
        v26[2] = v105;
        v26[3] = v106 & ~(v106 >> 31);
      }

      v7 += v144;
      v8 += v145;
      v9 += v145;
      v10 += 2 * v16;
      ++v12;
      v18 += v144;
    }

    while (v12 != v13);
  }

  else
  {
    v11 = a1;
  }

  if (v137)
  {
    if (v11 >= 2)
    {
      do
      {
        v107 = *v8;
        v8 += 2;
        v108 = v107 - 128;
        v109 = *v9;
        v9 += 2;
        v110 = *v7;
        v111 = v7[1];
        v7 += 2;
        v112 = -11276 * v108 - 23400 * (v109 - 128);
        v113 = 45941 * (v109 - 128);
        v114 = (v113 + (v110 << 15)) >> 15;
        if (v114 >= 255)
        {
          v114 = 255;
        }

        v115 = v114 & ~(v114 >> 31);
        v116 = (v112 + (v110 << 15)) >> 15;
        v117 = 58065 * v108;
        if (v116 >= 255)
        {
          v116 = 255;
        }

        v118 = v116 & ~(v116 >> 31);
        v119 = (v117 + (v110 << 15)) >> 15;
        if (v119 >= 255)
        {
          v119 = 255;
        }

        v120 = v119 & ~(v119 >> 31);
        v121 = (v113 + (v111 << 15)) >> 15;
        if (v121 >= 255)
        {
          v121 = 255;
        }

        v122 = v121 & ~(v121 >> 31);
        v123 = (v112 + (v111 << 15)) >> 15;
        if (v123 >= 255)
        {
          v123 = 255;
        }

        v124 = v123 & ~(v123 >> 31);
        v125 = (v117 + (v111 << 15)) >> 15;
        *v10 = -1;
        v10[1] = v115;
        if (v125 >= 255)
        {
          v125 = 255;
        }

        v10[2] = v118;
        v10[3] = v120;
        v10[4] = -1;
        v10[5] = v122;
        v10[6] = v124;
        v10[7] = v125 & ~(v125 >> 31);
        v10 += 8;
        --v6;
      }

      while (v6);
      LOBYTE(v11) = a1;
    }

    if (v11)
    {
      v126 = *v8 - 128;
      v127 = *v9 - 128;
      v128 = *v7;
      v129 = -11276 * v126 - 23400 * v127;
      v130 = 58065 * v126;
      v131 = (45941 * v127 + (v128 << 15)) >> 15;
      if (v131 >= 255)
      {
        v131 = 255;
      }

      v132 = v131 & ~(v131 >> 31);
      v133 = (v129 + (v128 << 15)) >> 15;
      if (v133 >= 255)
      {
        v133 = 255;
      }

      v134 = v133 & ~(v133 >> 31);
      v135 = (v130 + (v128 << 15)) >> 15;
      if (v135 >= 255)
      {
        v135 = 255;
      }

      *v10 = -1;
      v10[1] = v132;
      v10[2] = v134;
      v10[3] = v135 & ~(v135 >> 31);
    }
  }

  return 0;
}

uint64_t vt_Copy_420fITU601F_24RGB_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = a1 >> 1;
  v7 = *a4;
  v8 = a4[1];
  v9 = v8 + 1;
  v10 = *a6;
  v130 = a1;
  v125 = a2;
  if (a2 >= 2)
  {
    v11 = 0;
    v12 = a2 >> 1;
    v13 = *a3;
    v14 = a3[1];
    v15 = *a5;
    v16 = 4 * (a1 >> 3);
    v17 = 2 * v13;
    v128 = v13;
    v129 = a1 >> 3;
    v18 = &v7[v13];
    v126 = v6 - v16;
    v19.i64[0] = 0xFF000000FFLL;
    v19.i64[1] = 0xFF000000FFLL;
    v20.i64[0] = 0x7F0000007FLL;
    v20.i64[1] = 0x7F0000007FLL;
    v21 = vdupq_n_s32(0xFFFFD3F4);
    v22 = vdupq_n_s32(0xFFFFA498);
    v23 = vdupq_n_s32(0xE2D1u);
    v24 = vdupq_n_s32(0xB375u);
    v127 = 2 * v13;
    do
    {
      if (a1 >= 8)
      {
        v31 = 0;
        v32 = v129;
        v27 = v10;
        do
        {
          v33 = *&v8[v31];
          v34 = &v27[v15];
          v35 = vaddw_u16(v20, *&vmovl_u8(vuzp1_s8(v33, 0x80000000B375)));
          v36 = vaddw_u16(v20, *&vmovl_u8(vuzp2_s8(v33, 0x80000000B375)));
          v37 = vmlaq_s32(vmulq_s32(v35, v21), v36, v22);
          v38 = vmulq_s32(v35, v23);
          v39 = vmulq_s32(v36, v24);
          v40 = vzip1q_s32(v38, v38);
          v41 = vzip2q_s32(v38, v38);
          v42 = vzip1q_s32(v39, v39);
          v43 = vzip2q_s32(v39, v39);
          v44 = vzip1q_s32(v37, v37);
          v45 = vmovl_u8(*&v7[v31]);
          v46 = vmovl_u8(*&v18[v31]);
          v47 = vshll_n_u16(*v45.i8, 0xFuLL);
          v48 = vshll_high_n_u16(v45, 0xFuLL);
          v49 = vshll_n_u16(*v46.i8, 0xFuLL);
          v50 = vzip2q_s32(v37, v37);
          v51 = vshll_high_n_u16(v46, 0xFuLL);
          v132.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v47), 0xFuLL), vaddq_s32(v43, v48), 0xFuLL));
          v132.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v47), 0xFuLL), vaddq_s32(v50, v48), 0xFuLL));
          v131.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v49), 0xFuLL), vaddq_s32(v43, v51), 0xFuLL));
          v132.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v47), 0xFuLL), vaddq_s32(v41, v48), 0xFuLL));
          v131.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v49), 0xFuLL), vaddq_s32(v50, v51), 0xFuLL));
          vst3_s8(v27, v132);
          v27 += 24;
          v131.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v49), 0xFuLL), vaddq_s32(v41, v51), 0xFuLL));
          vst3_s8(v34, v131);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v7[v31];
        v25 = &v18[v31];
        v29 = &v8[v31];
        v28 = &v8[v31 + 1];
        v26 = &v27[v15];
      }

      else
      {
        v25 = &v7[v128];
        v26 = &v10[v15];
        v27 = v10;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v6 > v16)
      {
        v52 = v14;
        v53 = v16;
        v54 = v12;
        v55 = v126;
        do
        {
          v56 = *v29;
          v29 += 2;
          v57 = v56 - 128;
          v58 = *v28;
          v28 += 2;
          v59 = *v30;
          v60 = v30[1];
          v30 += 2;
          v61 = -11276 * v57 - 23400 * (v58 - 128);
          v62.i32[0] = v58 - 128;
          v62.i32[1] = v59;
          v63 = 58065 * v57;
          v64 = vmul_s32(v62, 0x80000000B375);
          v65 = v60 << 15;
          v66 = (v61 + (v60 << 15)) >> 15;
          if (v66 >= 255)
          {
            v66 = 255;
          }

          v67 = v66 & ~(v66 >> 31);
          v68 = (v63 + (v60 << 15)) >> 15;
          if (v68 >= 255)
          {
            v68 = 255;
          }

          *v69.i8 = v64;
          v69.i64[1] = __PAIR64__(v64.u32[0], v63);
          v70 = vdupq_lane_s32(v64, 1);
          v70.i32[1] = v61;
          v70.i32[3] = v65;
          *v27 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v69, v70), 0xFuLL), v19), 0)), 0x80000000B375).u32[0];
          v27[4] = v67;
          v27[5] = v68 & ~(v68 >> 31);
          v27 += 6;
          v71 = *v25;
          v72 = v25[1];
          v25 += 2;
          v73 = v71 << 15;
          v74 = v72 << 15;
          v75 = (v61 + (v72 << 15)) >> 15;
          if (v75 >= 255)
          {
            v75 = 255;
          }

          v76 = (v63 + (v72 << 15)) >> 15;
          v77.i64[0] = __PAIR64__(v73, v64.u32[0]);
          v78 = vdupq_lane_s32(__PAIR64__(v73, v64.u32[0]), 1);
          v77.i64[1] = __PAIR64__(v64.u32[0], v63);
          v78.i32[1] = v61;
          v78.i32[3] = v74;
          if (v76 >= 255)
          {
            v79 = 255;
          }

          else
          {
            v79 = v76;
          }

          *v26 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v77, v78), 0xFuLL), v19), 0)), 0x80000000B375).u32[0];
          v26[4] = v75 & ~(v75 >> 31);
          v26[5] = v79 & ~(v79 >> 31);
          v26 += 6;
          --v55;
        }

        while (v55);
        v12 = v54;
        v16 = v53;
        a1 = v130;
        v14 = v52;
        v17 = v127;
      }

      if (a1)
      {
        v80 = *v29 - 128;
        v81 = *v28 - 128;
        v82 = *v30;
        v83 = -11276 * v80 - 23400 * v81;
        v84 = 58065 * v80;
        v85 = 45941 * v81;
        v86 = (v85 + (v82 << 15)) >> 15;
        if (v86 >= 255)
        {
          v86 = 255;
        }

        v87 = v86 & ~(v86 >> 31);
        v88 = (v83 + (v82 << 15)) >> 15;
        if (v88 >= 255)
        {
          v88 = 255;
        }

        v89 = v88 & ~(v88 >> 31);
        v90 = (v84 + (v82 << 15)) >> 15;
        if (v90 >= 255)
        {
          v90 = 255;
        }

        *v27 = v87;
        v27[1] = v89;
        v27[2] = v90 & ~(v90 >> 31);
        v91 = *v25;
        v92 = (v85 + (v91 << 15)) >> 15;
        if (v92 >= 255)
        {
          v92 = 255;
        }

        v93 = v92 & ~(v92 >> 31);
        v94 = (v83 + (v91 << 15)) >> 15;
        if (v94 >= 255)
        {
          v94 = 255;
        }

        v95 = v94 & ~(v94 >> 31);
        v96 = (v84 + (v91 << 15)) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        *v26 = v93;
        v26[1] = v95;
        v26[2] = v96 & ~(v96 >> 31);
      }

      v7 += v17;
      v8 += v14;
      v9 += v14;
      v10 += 2 * v15;
      ++v11;
      v18 += v17;
    }

    while (v11 != v12);
  }

  if (v125)
  {
    if (a1 >= 2)
    {
      v97.i64[0] = 0xFF000000FFLL;
      v97.i64[1] = 0xFF000000FFLL;
      do
      {
        v98 = *v8;
        v8 += 2;
        v99 = v98 - 128;
        v100 = *v9;
        v9 += 2;
        v101 = *v7;
        v102 = v7[1];
        v7 += 2;
        v103 = v101 << 15;
        v104 = -11276 * v99 - 23400 * (v100 - 128);
        v105 = 45941 * (v100 - 128);
        v106 = 58065 * v99;
        v107 = v102 << 15;
        v108 = (v104 + (v102 << 15)) >> 15;
        v109 = v106 + (v102 << 15);
        if (v108 >= 255)
        {
          v108 = 255;
        }

        v110.i64[0] = __PAIR64__(v103, v105);
        v110.i64[1] = __PAIR64__(v105, v106);
        v111 = v109 >> 15;
        v112.i64[0] = __PAIR64__(v104, v103);
        v112.i64[1] = __PAIR64__(v107, v103);
        if (v111 >= 255)
        {
          v113 = 255;
        }

        else
        {
          v113 = v111;
        }

        *v10 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v110, v112), 0xFuLL), v97), 0)), *v97.i8).u32[0];
        v10[4] = v108 & ~(v108 >> 31);
        v10[5] = v113 & ~(v113 >> 31);
        v10 += 6;
        --v6;
      }

      while (v6);
      LOBYTE(a1) = v130;
    }

    if (a1)
    {
      v114 = *v8 - 128;
      v115 = *v9 - 128;
      v116 = *v7;
      v117 = -11276 * v114 - 23400 * v115;
      v118 = 58065 * v114;
      v119 = (45941 * v115 + (v116 << 15)) >> 15;
      if (v119 >= 255)
      {
        v119 = 255;
      }

      v120 = v119 & ~(v119 >> 31);
      v121 = (v117 + (v116 << 15)) >> 15;
      if (v121 >= 255)
      {
        v121 = 255;
      }

      v122 = v121 & ~(v121 >> 31);
      v123 = (v118 + (v116 << 15)) >> 15;
      if (v123 >= 255)
      {
        v123 = 255;
      }

      *v10 = v120;
      v10[1] = v122;
      v10[2] = v123 & ~(v123 >> 31);
    }
  }

  return 0;
}

uint64_t vt_Copy_y420ITU709_32ARGB_vec(unint64_t a1, unint64_t a2, uint64_t *a3, uint8x8_t **a4, uint64_t *a5, char **a6)
{
  v6 = a1;
  v7 = *a4;
  v8 = a4[1];
  v9 = a4[2];
  v10 = a1 >> 1;
  v11 = *a6;
  v137 = a2;
  if (a2 >= 2)
  {
    v12 = 0;
    v144 = a2 >> 1;
    v13 = *a3;
    v143 = a3[1];
    v142 = a3[2];
    v14 = *a5;
    v15 = 4 * (a1 >> 3);
    v141 = 2 * *a3;
    v16 = v10 - v15;
    v17.i64[0] = 0x7F0000007FLL;
    v17.i64[1] = 0x7F0000007FLL;
    v18 = vdupq_n_s32(0xFFFFE4B5);
    v19 = vdupq_n_s32(0xFFFFBBCB);
    v20 = vdupq_n_s32(0x10E63u);
    v21 = vdupq_n_s32(0xE579u);
    v22 = vdupq_n_s16(0x950Bu);
    v23 = vdupq_n_s32(0xFFF6AF50);
    v24 = -1;
    v138 = a1 >> 1;
    do
    {
      if (v6 >= 8)
      {
        v31 = 0;
        v30 = v7;
        v27 = v11;
        do
        {
          v32 = &v27[v14];
          v33 = vaddw_u16(v17, *&vmovl_u8(v8->u32[v31 / 4]));
          v34 = vaddw_u16(v17, *&vmovl_u8(v9->u32[v31 / 4]));
          v35 = vmlaq_s32(vmulq_s32(v33, v18), v34, v19);
          v36 = vmulq_s32(v33, v20);
          v37 = vmulq_s32(v34, v21);
          v38 = vzip1q_s32(v36, v36);
          v39 = vzip2q_s32(v36, v36);
          v40 = vzip1q_s32(v37, v37);
          v41 = vmovl_u8(*v30);
          v42 = vmovl_u8(*(v30 + v13));
          v43 = vzip2q_s32(v37, v37);
          v44 = vmlal_u16(v23, *v41.i8, *v22.i8);
          v45 = vmlal_high_u16(v23, v41, v22);
          v46 = vzip1q_s32(v35, v35);
          v47 = vmlal_u16(v23, *v42.i8, *v22.i8);
          v48 = vmlal_high_u16(v23, v42, v22);
          v49 = vzip2q_s32(v35, v35);
          v145.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v44), 0xFuLL), vaddq_s32(v43, v45), 0xFuLL));
          v145.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v46, v44), 0xFuLL), vaddq_s32(v49, v45), 0xFuLL));
          v50 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v47), 0xFuLL), vaddq_s32(v43, v48), 0xFuLL));
          v145.val[3] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v38, v44), 0xFuLL), vaddq_s32(v39, v45), 0xFuLL));
          v51 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v46, v47), 0xFuLL), vaddq_s32(v49, v48), 0xFuLL));
          v52 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v38, v47), 0xFuLL), vaddq_s32(v39, v48), 0xFuLL));
          v145.val[0] = -1;
          vst4_s8(v27, v145);
          v27 += 32;
          vst4_s8(v32, *&v24);
          ++v30;
          v31 += 4;
        }

        while (v15 != v31);
        v25 = v30 + v13;
        v29 = v8 + v31;
        v28 = v9 + v31;
        v26 = &v27[v14];
      }

      else
      {
        v25 = v7 + v13;
        v26 = &v11[v14];
        v27 = v11;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v10 > v15)
      {
        v140 = v12;
        v53 = 0;
        do
        {
          v54 = v29[v53] - 128;
          v55 = v30->u8[0];
          v56 = v30->u8[1];
          v30 = (v30 + 2);
          v57 = 38155 * v55 - 610480;
          v58 = v28[v53] - 128;
          v59 = -6987 * v54 - 17461 * v58;
          v60 = 69219 * v54;
          v61 = 58745 * v58;
          v62 = (v57 + 58745 * v58) >> 15;
          if (v62 >= 255)
          {
            v62 = 255;
          }

          v63 = v62 & ~(v62 >> 31);
          v64 = (v59 + v57) >> 15;
          if (v64 >= 255)
          {
            v64 = 255;
          }

          v65 = v64 & ~(v64 >> 31);
          v66 = (v57 + v60) >> 15;
          if (v66 >= 255)
          {
            v66 = 255;
          }

          v67 = v66 & ~(v66 >> 31);
          v68 = 38155 * v56 - 610480;
          v69 = (v68 + v61) >> 15;
          if (v69 >= 255)
          {
            v69 = 255;
          }

          v70 = v69 & ~(v69 >> 31);
          v71 = (v68 + v59) >> 15;
          if (v71 >= 255)
          {
            v71 = 255;
          }

          v72 = v71 & ~(v71 >> 31);
          v73 = (v68 + v60) >> 15;
          if (v73 >= 255)
          {
            v73 = 255;
          }

          *v27 = -1;
          v27[1] = v63;
          v27[2] = v65;
          v27[3] = v67;
          v27[4] = -1;
          v27[5] = v70;
          v27[6] = v72;
          v27[7] = v73 & ~(v73 >> 31);
          v27 += 8;
          v74 = v25[1];
          v75 = 38155 * *v25 - 610480;
          v25 += 2;
          v76 = (v75 + v61) >> 15;
          if (v76 >= 255)
          {
            v76 = 255;
          }

          v77 = v76 & ~(v76 >> 31);
          v78 = (v75 + v59) >> 15;
          if (v78 >= 255)
          {
            v78 = 255;
          }

          v79 = (v75 + v60) >> 15;
          v80 = v78 & ~(v78 >> 31);
          if (v79 >= 255)
          {
            v79 = 255;
          }

          v81 = 38155 * v74 - 610480;
          v82 = (v81 + v61) >> 15;
          v83 = v79 & ~(v79 >> 31);
          if (v82 >= 255)
          {
            v82 = 255;
          }

          v84 = (v81 + v59) >> 15;
          v85 = v82 & ~(v82 >> 31);
          if (v84 >= 255)
          {
            v84 = 255;
          }

          v86 = (v81 + v60) >> 15;
          *v26 = -1;
          v87 = v84 & ~(v84 >> 31);
          v26[1] = v77;
          if (v86 >= 255)
          {
            v86 = 255;
          }

          v26[2] = v80;
          v26[4] = -1;
          v26[3] = v83;
          v26[5] = v85;
          v26[6] = v87;
          v26[7] = v86 & ~(v86 >> 31);
          v26 += 8;
          ++v53;
        }

        while (v16 != v53);
        v29 += v53;
        v28 += v53;
        v10 = v138;
        v6 = a1;
        v12 = v140;
      }

      if (v6)
      {
        v88 = *v29 - 128;
        v89 = *v28 - 128;
        v90 = 38155 * v30->u8[0] - 610480;
        v91 = -6987 * v88 - 17461 * v89;
        v92 = 69219 * v88;
        v93 = 58745 * v89;
        v94 = (v90 + v93) >> 15;
        if (v94 >= 255)
        {
          v94 = 255;
        }

        v95 = v94 & ~(v94 >> 31);
        v96 = (v91 + v90) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        v97 = v96 & ~(v96 >> 31);
        v98 = (v90 + v92) >> 15;
        if (v98 >= 255)
        {
          v98 = 255;
        }

        *v27 = -1;
        v27[1] = v95;
        v27[2] = v97;
        v27[3] = v98 & ~(v98 >> 31);
        v99 = 38155 * *v25 - 610480;
        v100 = (v99 + v93) >> 15;
        if (v100 >= 255)
        {
          v100 = 255;
        }

        v101 = v100 & ~(v100 >> 31);
        v102 = (v99 + v91) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = v102 & ~(v102 >> 31);
        v104 = (v99 + v92) >> 15;
        if (v104 >= 255)
        {
          v104 = 255;
        }

        *v26 = -1;
        v26[1] = v101;
        v26[2] = v103;
        v26[3] = v104 & ~(v104 >> 31);
      }

      v7 = (v7 + v141);
      v8 = (v8 + v143);
      v9 = (v9 + v142);
      v11 += 2 * v14;
      ++v12;
    }

    while (v12 != v144);
  }

  if (v137)
  {
    if (v6 >= 2)
    {
      do
      {
        v105 = v8->u8[0];
        v8 = (v8 + 1);
        v106 = v105 - 128;
        v107 = v9->u8[0];
        v9 = (v9 + 1);
        v108 = v7->u8[0];
        v109 = v10;
        v110 = v7->u8[1];
        v7 = (v7 + 2);
        v111 = 38155 * v108 - 610480;
        v112 = -6987 * v106 - 17461 * (v107 - 128);
        v113 = 69219 * v106;
        v114 = 58745 * (v107 - 128);
        v115 = (v111 + v114) >> 15;
        if (v115 >= 255)
        {
          v115 = 255;
        }

        v116 = v115 & ~(v115 >> 31);
        v117 = (v112 + v111) >> 15;
        if (v117 >= 255)
        {
          v117 = 255;
        }

        v118 = v117 & ~(v117 >> 31);
        v119 = (v111 + v113) >> 15;
        if (v119 >= 255)
        {
          v119 = 255;
        }

        v120 = v119 & ~(v119 >> 31);
        v121 = 38155 * v110 - 610480;
        v122 = (v121 + v114) >> 15;
        if (v122 >= 255)
        {
          v122 = 255;
        }

        v123 = v122 & ~(v122 >> 31);
        v124 = (v121 + v112) >> 15;
        if (v124 >= 255)
        {
          v124 = 255;
        }

        v125 = v124 & ~(v124 >> 31);
        v126 = (v121 + v113) >> 15;
        *v11 = -1;
        v11[1] = v116;
        if (v126 >= 255)
        {
          v126 = 255;
        }

        v11[2] = v118;
        v11[3] = v120;
        v11[4] = -1;
        v11[5] = v123;
        v11[6] = v125;
        v11[7] = v126 & ~(v126 >> 31);
        v11 += 8;
        v10 = v109 - 1;
      }

      while (v109 != 1);
    }

    if (v6)
    {
      v127 = v8->u8[0] - 128;
      v128 = v9->u8[0] - 128;
      v129 = 38155 * v7->u8[0] - 610480;
      v130 = -6987 * v127 - 17461 * v128;
      v131 = (v129 + 58745 * v128) >> 15;
      if (v131 >= 255)
      {
        v131 = 255;
      }

      v132 = v131 & ~(v131 >> 31);
      v133 = (v130 + v129) >> 15;
      if (v133 >= 255)
      {
        v133 = 255;
      }

      v134 = v133 & ~(v133 >> 31);
      v135 = (v129 + 69219 * v127) >> 15;
      if (v135 >= 255)
      {
        v135 = 255;
      }

      *v11 = -1;
      v11[1] = v132;
      v11[2] = v134;
      v11[3] = v135 & ~(v135 >> 31);
    }
  }

  return 0;
}

uint64_t vt_Copy_420vITU709_32ARGB_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = a1 >> 1;
  v7 = *a4;
  v8 = a4[1];
  v9 = v8 + 1;
  v10 = *a6;
  v138 = a2;
  if (a2 >= 2)
  {
    v11 = a2 >> 1;
    v12 = 0;
    v14 = *a3;
    v13 = a3[1];
    v15 = *a5;
    v146 = 2 * v14;
    v147 = 4 * (a1 >> 3);
    v145 = a1;
    v141 = v14;
    v142 = v11;
    v16 = &v7[v14];
    v143 = a1 >> 3;
    v144 = a1 >> 1;
    v139 = v6 - v147;
    v140 = v13;
    v17 = vdupq_n_s32(0xFFFFE4B5);
    v18 = vdupq_n_s32(0xFFFFBBCB);
    v19 = vdupq_n_s32(0x10E63u);
    v20 = vdupq_n_s32(0xE579u);
    v21.i64[0] = 0x7F0000007FLL;
    v21.i64[1] = 0x7F0000007FLL;
    v22 = vdupq_n_s16(0x950Bu);
    v23 = vdupq_n_s32(0xFFF6AF50);
    v24 = -1;
    do
    {
      if (a1 >= 8)
      {
        v31 = 0;
        v32 = v143;
        v27 = v10;
        do
        {
          v33 = &v27[v15];
          v34 = *&v8[v31];
          v35 = vaddw_u16(v21, *&vmovl_u8(vuzp1_s8(v34, *v17.i8)));
          v36 = vaddw_u16(v21, *&vmovl_u8(vuzp2_s8(v34, *v17.i8)));
          v37 = vmlaq_s32(vmulq_s32(v35, v17), v36, v18);
          v38 = vmulq_s32(v35, v19);
          v39 = vmulq_s32(v36, v20);
          v40 = vzip1q_s32(v38, v38);
          v41 = vzip2q_s32(v38, v38);
          v42 = vzip1q_s32(v39, v39);
          v43 = vmovl_u8(*&v7[v31]);
          v44 = vmovl_u8(*&v16[v31]);
          v45 = vzip1q_s32(v37, v37);
          v46 = vmlal_u16(v23, *v43.i8, *v22.i8);
          v47 = vmlal_high_u16(v23, v43, v22);
          v48 = vzip2q_s32(v39, v39);
          v49 = vmlal_u16(v23, *v44.i8, *v22.i8);
          v50 = vmlal_high_u16(v23, v44, v22);
          v51 = vzip2q_s32(v37, v37);
          v52 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v46), 0xFuLL), vaddq_s32(v48, v47), 0xFuLL));
          v53 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v45, v46), 0xFuLL), vaddq_s32(v51, v47), 0xFuLL));
          v148.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v49), 0xFuLL), vaddq_s32(v48, v50), 0xFuLL));
          v54 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v46), 0xFuLL), vaddq_s32(v41, v47), 0xFuLL));
          v148.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v45, v49), 0xFuLL), vaddq_s32(v51, v50), 0xFuLL));
          vst4_s8(v27, *&v24);
          v27 += 32;
          v148.val[3] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v49), 0xFuLL), vaddq_s32(v41, v50), 0xFuLL));
          v148.val[0] = -1;
          vst4_s8(v33, v148);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v7[v31];
        v25 = &v16[v31];
        v29 = &v8[v31];
        v28 = &v8[v31 + 1];
        v26 = &v27[v15];
      }

      else
      {
        v25 = &v7[v141];
        v26 = &v10[v15];
        v27 = v10;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v6 > v147)
      {
        v55 = v139;
        do
        {
          v56 = *v29;
          v29 += 2;
          v57 = v56 - 128;
          v58 = *v28;
          v28 += 2;
          v59 = 38155 * *v30 - 610480;
          v60 = -6987 * v57 - 17461 * (v58 - 128);
          v61 = 69219 * v57;
          v62 = 58745 * (v58 - 128);
          v63 = (v59 + v62) >> 15;
          if (v63 >= 255)
          {
            v63 = 255;
          }

          v64 = v63 & ~(v63 >> 31);
          v65 = (v60 + v59) >> 15;
          if (v65 >= 255)
          {
            v65 = 255;
          }

          v66 = v65 & ~(v65 >> 31);
          v67 = (v59 + v61) >> 15;
          if (v67 >= 255)
          {
            v67 = 255;
          }

          v68 = v67 & ~(v67 >> 31);
          v69 = 38155 * v30[1] - 610480;
          v70 = (v69 + v62) >> 15;
          if (v70 >= 255)
          {
            v70 = 255;
          }

          v71 = v70 & ~(v70 >> 31);
          v72 = (v69 + v60) >> 15;
          if (v72 >= 255)
          {
            v72 = 255;
          }

          v73 = v72 & ~(v72 >> 31);
          v74 = (v69 + v61) >> 15;
          if (v74 >= 255)
          {
            v74 = 255;
          }

          v30 += 2;
          *v27 = -1;
          v27[1] = v64;
          v27[2] = v66;
          v27[3] = v68;
          v27[4] = -1;
          v27[5] = v71;
          v27[6] = v73;
          v27[7] = v74 & ~(v74 >> 31);
          v27 += 8;
          v75 = *v25;
          v76 = v25[1];
          v25 += 2;
          v77 = 38155 * v75 - 610480;
          v78 = (v77 + v62) >> 15;
          if (v78 >= 255)
          {
            v78 = 255;
          }

          v79 = v78 & ~(v78 >> 31);
          v80 = (v77 + v60) >> 15;
          if (v80 >= 255)
          {
            v80 = 255;
          }

          v81 = v80 & ~(v80 >> 31);
          v82 = (v77 + v61) >> 15;
          if (v82 >= 255)
          {
            v82 = 255;
          }

          v83 = 38155 * v76 - 610480;
          v84 = v82 & ~(v82 >> 31);
          v85 = (v83 + v62) >> 15;
          if (v85 >= 255)
          {
            v85 = 255;
          }

          v86 = (v83 + v60) >> 15;
          v87 = v85 & ~(v85 >> 31);
          if (v86 >= 255)
          {
            v86 = 255;
          }

          v88 = (v83 + v61) >> 15;
          *v26 = -1;
          v26[1] = v79;
          if (v88 >= 255)
          {
            v88 = 255;
          }

          v26[2] = v81;
          v26[4] = -1;
          v26[3] = v84;
          v26[5] = v87;
          v26[6] = v86 & ~(v86 >> 31);
          v26[7] = v88 & ~(v88 >> 31);
          v26 += 8;
          --v55;
        }

        while (v55);
        v6 = v144;
        a1 = v145;
        v11 = v142;
        v13 = v140;
      }

      if (a1)
      {
        v89 = *v29 - 128;
        v90 = *v28 - 128;
        v91 = 38155 * *v30 - 610480;
        v92 = -6987 * v89 - 17461 * v90;
        v93 = 69219 * v89;
        v94 = 58745 * v90;
        v95 = (v91 + v94) >> 15;
        if (v95 >= 255)
        {
          v95 = 255;
        }

        v96 = v95 & ~(v95 >> 31);
        v97 = (v92 + v91) >> 15;
        if (v97 >= 255)
        {
          v97 = 255;
        }

        v98 = v97 & ~(v97 >> 31);
        v99 = (v91 + v93) >> 15;
        if (v99 >= 255)
        {
          v99 = 255;
        }

        *v27 = -1;
        v27[1] = v96;
        v27[2] = v98;
        v27[3] = v99 & ~(v99 >> 31);
        v100 = 38155 * *v25 - 610480;
        v101 = (v100 + v94) >> 15;
        if (v101 >= 255)
        {
          v101 = 255;
        }

        v102 = v101 & ~(v101 >> 31);
        v103 = (v100 + v92) >> 15;
        if (v103 >= 255)
        {
          v103 = 255;
        }

        v104 = v103 & ~(v103 >> 31);
        v105 = (v100 + v93) >> 15;
        if (v105 >= 255)
        {
          v105 = 255;
        }

        *v26 = -1;
        v26[1] = v102;
        v26[2] = v104;
        v26[3] = v105 & ~(v105 >> 31);
      }

      v7 += v146;
      v8 += v13;
      v9 += v13;
      v10 += 2 * v15;
      ++v12;
      v16 += v146;
    }

    while (v12 != v11);
  }

  if (v138)
  {
    if (a1 >= 2)
    {
      do
      {
        v106 = *v8;
        v8 += 2;
        v107 = v106 - 128;
        v108 = *v9;
        v9 += 2;
        v109 = *v7;
        v110 = v7[1];
        v7 += 2;
        v111 = v6;
        v112 = 38155 * v109 - 610480;
        v113 = -6987 * v107 - 17461 * (v108 - 128);
        v114 = 69219 * v107;
        v115 = 58745 * (v108 - 128);
        v116 = (v112 + v115) >> 15;
        if (v116 >= 255)
        {
          v116 = 255;
        }

        v117 = v116 & ~(v116 >> 31);
        v118 = (v113 + v112) >> 15;
        if (v118 >= 255)
        {
          v118 = 255;
        }

        v119 = v118 & ~(v118 >> 31);
        v120 = (v112 + v114) >> 15;
        if (v120 >= 255)
        {
          v120 = 255;
        }

        v121 = v120 & ~(v120 >> 31);
        v122 = 38155 * v110 - 610480;
        v123 = (v122 + v115) >> 15;
        if (v123 >= 255)
        {
          v123 = 255;
        }

        v124 = v123 & ~(v123 >> 31);
        v125 = (v122 + v113) >> 15;
        if (v125 >= 255)
        {
          v125 = 255;
        }

        v126 = v125 & ~(v125 >> 31);
        v127 = (v122 + v114) >> 15;
        *v10 = -1;
        v10[1] = v117;
        if (v127 >= 255)
        {
          v127 = 255;
        }

        v10[2] = v119;
        v10[3] = v121;
        v10[4] = -1;
        v10[5] = v124;
        v10[6] = v126;
        v10[7] = v127 & ~(v127 >> 31);
        v10 += 8;
        v6 = v111 - 1;
      }

      while (v111 != 1);
    }

    if (a1)
    {
      v128 = *v8 - 128;
      v129 = *v9 - 128;
      v130 = 38155 * *v7 - 610480;
      v131 = -6987 * v128 - 17461 * v129;
      v132 = (v130 + 58745 * v129) >> 15;
      if (v132 >= 255)
      {
        v132 = 255;
      }

      v133 = v132 & ~(v132 >> 31);
      v134 = (v131 + v130) >> 15;
      if (v134 >= 255)
      {
        v134 = 255;
      }

      v135 = v134 & ~(v134 >> 31);
      v136 = (v130 + 69219 * v128) >> 15;
      if (v136 >= 255)
      {
        v136 = 255;
      }

      *v10 = -1;
      v10[1] = v133;
      v10[2] = v135;
      v10[3] = v136 & ~(v136 >> 31);
    }
  }

  return 0;
}

uint64_t vt_Copy_y420ITU709_32BGRA_vec(unint64_t a1, unint64_t a2, uint64_t *a3, uint8x8_t **a4, uint64_t *a5, char **a6)
{
  v6 = a1;
  v7 = *a4;
  v8 = a4[1];
  v9 = a4[2];
  v10 = a1 >> 1;
  v11 = *a6;
  v136 = a2;
  if (a2 >= 2)
  {
    v12 = 0;
    v142 = a2 >> 1;
    v13 = *a3;
    v141 = a3[1];
    v14 = a3[2];
    v15 = *a5;
    v16 = 4 * (a1 >> 3);
    v17 = v10 - v16;
    v18.i64[0] = 0x7F0000007FLL;
    v18.i64[1] = 0x7F0000007FLL;
    v19 = vdupq_n_s32(0xFFFFE4B5);
    v20 = vdupq_n_s32(0xFFFFBBCB);
    v21 = vdupq_n_s32(0x10E63u);
    v22 = vdupq_n_s32(0xE579u);
    v23 = vdupq_n_s16(0x950Bu);
    v24 = vdupq_n_s32(0xFFF6AF50);
    v25 = -1;
    v138 = a1 >> 1;
    v137 = v14;
    do
    {
      if (v6 >= 8)
      {
        v32 = 0;
        v31 = v7;
        v28 = v11;
        do
        {
          v33 = &v28[v15];
          v34 = vaddw_u16(v18, *&vmovl_u8(v8->u32[v32 / 4]));
          v35 = vaddw_u16(v18, *&vmovl_u8(v9->u32[v32 / 4]));
          v36 = vmlaq_s32(vmulq_s32(v34, v19), v35, v20);
          v37 = vmulq_s32(v34, v21);
          v38 = vmulq_s32(v35, v22);
          v39 = vzip1q_s32(v37, v37);
          v40 = vzip2q_s32(v37, v37);
          v41 = vzip1q_s32(v38, v38);
          v42 = vmovl_u8(*v31);
          v43 = vmovl_u8(*(v31 + v13));
          v44 = vzip1q_s32(v36, v36);
          v45 = vmlal_u16(v24, *v42.i8, *v23.i8);
          v46 = vmlal_high_u16(v24, v42, v23);
          v47 = vzip2q_s32(v38, v38);
          v48 = vmlal_u16(v24, *v43.i8, *v23.i8);
          v49 = vmlal_high_u16(v24, v43, v23);
          v50 = vzip2q_s32(v36, v36);
          v51 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v45), 0xFuLL), vaddq_s32(v47, v46), 0xFuLL));
          v52 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v45), 0xFuLL), vaddq_s32(v50, v46), 0xFuLL));
          v143.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v48), 0xFuLL), vaddq_s32(v47, v49), 0xFuLL));
          v53 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v39, v45), 0xFuLL), vaddq_s32(v40, v46), 0xFuLL));
          v143.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v48), 0xFuLL), vaddq_s32(v50, v49), 0xFuLL));
          vst4_s8(v28, *(&v25 - 3));
          v28 += 32;
          v143.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v39, v48), 0xFuLL), vaddq_s32(v40, v49), 0xFuLL));
          v143.val[3] = -1;
          vst4_s8(v33, v143);
          ++v31;
          v32 += 4;
        }

        while (v16 != v32);
        v26 = v31 + v13;
        v30 = v8 + v32;
        v29 = v9 + v32;
        v27 = &v28[v15];
      }

      else
      {
        v26 = v7 + v13;
        v27 = &v11[v15];
        v28 = v11;
        v29 = v9;
        v30 = v8;
        v31 = v7;
      }

      if (v10 > v16)
      {
        v140 = v12;
        v54 = 0;
        do
        {
          v55 = v30[v54] - 128;
          v56 = v31->u8[0];
          v57 = v31->u8[1];
          v31 = (v31 + 2);
          v58 = 38155 * v56 - 610480;
          v59 = v29[v54] - 128;
          v60 = -6987 * v55 - 17461 * v59;
          v61 = 69219 * v55;
          v62 = 58745 * v59;
          v63 = (v58 + 58745 * v59) >> 15;
          if (v63 >= 255)
          {
            v63 = 255;
          }

          v64 = v63 & ~(v63 >> 31);
          v65 = (v60 + v58) >> 15;
          if (v65 >= 255)
          {
            v65 = 255;
          }

          v66 = v65 & ~(v65 >> 31);
          v67 = (v58 + v61) >> 15;
          if (v67 >= 255)
          {
            v67 = 255;
          }

          v68 = v67 & ~(v67 >> 31);
          v69 = 38155 * v57 - 610480;
          v70 = (v69 + v62) >> 15;
          if (v70 >= 255)
          {
            v70 = 255;
          }

          v71 = v70 & ~(v70 >> 31);
          v72 = (v69 + v60) >> 15;
          if (v72 >= 255)
          {
            v72 = 255;
          }

          v73 = v72 & ~(v72 >> 31);
          v74 = (v69 + v61) >> 15;
          if (v74 >= 255)
          {
            v74 = 255;
          }

          *v28 = v68;
          v28[1] = v66;
          v28[2] = v64;
          v28[3] = -1;
          v28[5] = v73;
          v28[6] = v71;
          v28[4] = v74 & ~(v74 >> 31);
          v28[7] = -1;
          v28 += 8;
          v75 = v26[1];
          v76 = 38155 * *v26 - 610480;
          v26 += 2;
          v77 = (v76 + v62) >> 15;
          if (v77 >= 255)
          {
            v77 = 255;
          }

          v78 = v77 & ~(v77 >> 31);
          v79 = (v76 + v60) >> 15;
          if (v79 >= 255)
          {
            v79 = 255;
          }

          v80 = (v76 + v61) >> 15;
          v81 = v79 & ~(v79 >> 31);
          if (v80 >= 255)
          {
            v80 = 255;
          }

          v82 = 38155 * v75 - 610480;
          v83 = (v82 + v62) >> 15;
          v84 = v80 & ~(v80 >> 31);
          if (v83 >= 255)
          {
            v83 = 255;
          }

          v85 = (v82 + v60) >> 15;
          v86 = v83 & ~(v83 >> 31);
          if (v85 >= 255)
          {
            v85 = 255;
          }

          v87 = v85 & ~(v85 >> 31);
          v88 = (v82 + v61) >> 15;
          *v27 = v84;
          v27[1] = v81;
          if (v88 >= 255)
          {
            v89 = 255;
          }

          else
          {
            v89 = v88;
          }

          v27[2] = v78;
          v27[3] = -1;
          v27[4] = v89 & ~(v89 >> 31);
          v27[5] = v87;
          v27[6] = v86;
          v27[7] = -1;
          v27 += 8;
          ++v54;
        }

        while (v17 != v54);
        v30 += v54;
        v29 += v54;
        v10 = v138;
        v6 = a1;
        v12 = v140;
        v14 = v137;
      }

      if (v6)
      {
        v90 = *v30 - 128;
        v91 = *v29 - 128;
        v92 = 38155 * v31->u8[0] - 610480;
        v93 = -6987 * v90 - 17461 * v91;
        v94 = 69219 * v90;
        v95 = 58745 * v91;
        v96 = (v92 + v95) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        v97 = v96 & ~(v96 >> 31);
        v98 = (v93 + v92) >> 15;
        if (v98 >= 255)
        {
          v98 = 255;
        }

        v99 = v98 & ~(v98 >> 31);
        v100 = (v92 + v94) >> 15;
        if (v100 >= 255)
        {
          v100 = 255;
        }

        *v28 = v100 & ~(v100 >> 31);
        v28[1] = v99;
        v28[2] = v97;
        v28[3] = -1;
        v101 = 38155 * *v26 - 610480;
        v102 = (v101 + v95) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = (v101 + v93) >> 15;
        if (v103 >= 255)
        {
          v103 = 255;
        }

        v104 = v103 & ~(v103 >> 31);
        v105 = (v101 + v94) >> 15;
        if (v105 >= 255)
        {
          v105 = 255;
        }

        *v27 = v105 & ~(v105 >> 31);
        v27[1] = v104;
        v27[2] = v102 & ~(v102 >> 31);
        v27[3] = -1;
      }

      v7 = (v7 + 2 * v13);
      v8 = (v8 + v141);
      v9 = (v9 + v14);
      v11 += 2 * v15;
      ++v12;
    }

    while (v12 != v142);
  }

  if (v136)
  {
    if (v6 >= 2)
    {
      do
      {
        v106 = v8->u8[0];
        v8 = (v8 + 1);
        v107 = v106 - 128;
        v108 = v9->u8[0];
        v9 = (v9 + 1);
        v109 = v7->u8[0];
        v110 = v10;
        v111 = v7->u8[1];
        v7 = (v7 + 2);
        v112 = 38155 * v109 - 610480;
        v113 = -6987 * v107 - 17461 * (v108 - 128);
        v114 = 69219 * v107;
        v115 = 58745 * (v108 - 128);
        v116 = (v112 + v115) >> 15;
        if (v116 >= 255)
        {
          v116 = 255;
        }

        v117 = v116 & ~(v116 >> 31);
        v118 = (v113 + v112) >> 15;
        if (v118 >= 255)
        {
          v118 = 255;
        }

        v119 = v118 & ~(v118 >> 31);
        v120 = (v112 + v114) >> 15;
        if (v120 >= 255)
        {
          v120 = 255;
        }

        v121 = v120 & ~(v120 >> 31);
        v122 = 38155 * v111 - 610480;
        v123 = (v122 + v115) >> 15;
        if (v123 >= 255)
        {
          v123 = 255;
        }

        v124 = (v122 + v113) >> 15;
        if (v124 >= 255)
        {
          v124 = 255;
        }

        v125 = v124 & ~(v124 >> 31);
        v126 = (v122 + v114) >> 15;
        *v11 = v121;
        v11[1] = v119;
        if (v126 >= 255)
        {
          v126 = 255;
        }

        v11[2] = v117;
        v11[3] = -1;
        v11[4] = v126 & ~(v126 >> 31);
        v11[5] = v125;
        v11[6] = v123 & ~(v123 >> 31);
        v11[7] = -1;
        v11 += 8;
        v10 = v110 - 1;
      }

      while (v110 != 1);
    }

    if (v6)
    {
      v127 = v8->u8[0] - 128;
      v128 = v9->u8[0] - 128;
      v129 = 38155 * v7->u8[0] - 610480;
      v130 = -6987 * v127 - 17461 * v128;
      v131 = (v129 + 58745 * v128) >> 15;
      if (v131 >= 255)
      {
        v131 = 255;
      }

      v132 = (v130 + v129) >> 15;
      if (v132 >= 255)
      {
        v132 = 255;
      }

      v133 = v132 & ~(v132 >> 31);
      v134 = (v129 + 69219 * v127) >> 15;
      if (v134 >= 255)
      {
        v134 = 255;
      }

      *v11 = v134 & ~(v134 >> 31);
      v11[1] = v133;
      v11[2] = v131 & ~(v131 >> 31);
      v11[3] = -1;
    }
  }

  return 0;
}

uint64_t vt_Copy_420vITU709_32BGRA_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = a1 >> 1;
  v7 = *a4;
  v8 = a4[1];
  v9 = v8 + 1;
  v10 = *a6;
  v136 = a2;
  if (a2 >= 2)
  {
    v11 = a2 >> 1;
    v12 = 0;
    v14 = *a3;
    v13 = a3[1];
    v15 = *a5;
    v144 = 2 * v14;
    v145 = 4 * (a1 >> 3);
    v143 = a1;
    v139 = v14;
    v140 = v11;
    v16 = &v7[v14];
    v141 = a1 >> 3;
    v142 = a1 >> 1;
    v137 = v6 - v145;
    v138 = v13;
    v17 = vdupq_n_s32(0xFFFFE4B5);
    v18 = vdupq_n_s32(0xFFFFBBCB);
    v19 = vdupq_n_s32(0x10E63u);
    v20 = vdupq_n_s32(0xE579u);
    v21.i64[0] = 0x7F0000007FLL;
    v21.i64[1] = 0x7F0000007FLL;
    v22 = vdupq_n_s16(0x950Bu);
    v23 = vdupq_n_s32(0xFFF6AF50);
    v24 = -1;
    do
    {
      if (a1 >= 8)
      {
        v31 = 0;
        v32 = v141;
        v27 = v10;
        do
        {
          v33 = &v27[v15];
          v34 = *&v8[v31];
          v35 = vaddw_u16(v21, *&vmovl_u8(vuzp1_s8(v34, *v17.i8)));
          v36 = vaddw_u16(v21, *&vmovl_u8(vuzp2_s8(v34, *v17.i8)));
          v37 = vmlaq_s32(vmulq_s32(v35, v17), v36, v18);
          v38 = vmulq_s32(v35, v19);
          v39 = vmulq_s32(v36, v20);
          v40 = vzip1q_s32(v38, v38);
          v41 = vzip2q_s32(v38, v38);
          v42 = vzip1q_s32(v39, v39);
          v43 = vmovl_u8(*&v7[v31]);
          v44 = vmovl_u8(*&v16[v31]);
          v45 = vzip1q_s32(v37, v37);
          v46 = vmlal_u16(v23, *v43.i8, *v22.i8);
          v47 = vmlal_high_u16(v23, v43, v22);
          v48 = vzip2q_s32(v39, v39);
          v49 = vmlal_u16(v23, *v44.i8, *v22.i8);
          v50 = vmlal_high_u16(v23, v44, v22);
          v51 = vzip2q_s32(v37, v37);
          v52 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v46), 0xFuLL), vaddq_s32(v48, v47), 0xFuLL));
          v53 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v45, v46), 0xFuLL), vaddq_s32(v51, v47), 0xFuLL));
          v146.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v49), 0xFuLL), vaddq_s32(v48, v50), 0xFuLL));
          v54 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v46), 0xFuLL), vaddq_s32(v41, v47), 0xFuLL));
          v146.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v45, v49), 0xFuLL), vaddq_s32(v51, v50), 0xFuLL));
          vst4_s8(v27, *(&v24 - 3));
          v27 += 32;
          v146.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v49), 0xFuLL), vaddq_s32(v41, v50), 0xFuLL));
          v146.val[3] = -1;
          vst4_s8(v33, v146);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v7[v31];
        v25 = &v16[v31];
        v29 = &v8[v31];
        v28 = &v8[v31 + 1];
        v26 = &v27[v15];
      }

      else
      {
        v25 = &v7[v139];
        v26 = &v10[v15];
        v27 = v10;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v6 > v145)
      {
        v55 = v137;
        do
        {
          v56 = *v29;
          v29 += 2;
          v57 = v56 - 128;
          v58 = *v28;
          v28 += 2;
          v59 = 38155 * *v30 - 610480;
          v60 = -6987 * v57 - 17461 * (v58 - 128);
          v61 = 69219 * v57;
          v62 = 58745 * (v58 - 128);
          v63 = (v59 + v62) >> 15;
          if (v63 >= 255)
          {
            v63 = 255;
          }

          v64 = v63 & ~(v63 >> 31);
          v65 = (v60 + v59) >> 15;
          if (v65 >= 255)
          {
            v65 = 255;
          }

          v66 = v65 & ~(v65 >> 31);
          v67 = (v59 + v61) >> 15;
          if (v67 >= 255)
          {
            v67 = 255;
          }

          v68 = v67 & ~(v67 >> 31);
          v69 = 38155 * v30[1] - 610480;
          v70 = (v69 + v62) >> 15;
          if (v70 >= 255)
          {
            v70 = 255;
          }

          v71 = v70 & ~(v70 >> 31);
          v72 = (v69 + v60) >> 15;
          if (v72 >= 255)
          {
            v72 = 255;
          }

          v73 = v72 & ~(v72 >> 31);
          v74 = (v69 + v61) >> 15;
          if (v74 >= 255)
          {
            v74 = 255;
          }

          v30 += 2;
          *v27 = v68;
          v27[1] = v66;
          v27[2] = v64;
          v27[3] = -1;
          v27[5] = v73;
          v27[4] = v74 & ~(v74 >> 31);
          v27[6] = v71;
          v27[7] = -1;
          v27 += 8;
          v75 = *v25;
          v76 = v25[1];
          v25 += 2;
          v77 = 38155 * v75 - 610480;
          v78 = (v77 + v62) >> 15;
          if (v78 >= 255)
          {
            v78 = 255;
          }

          v79 = v78 & ~(v78 >> 31);
          v80 = (v77 + v60) >> 15;
          if (v80 >= 255)
          {
            v80 = 255;
          }

          v81 = v80 & ~(v80 >> 31);
          v82 = (v77 + v61) >> 15;
          if (v82 >= 255)
          {
            v82 = 255;
          }

          v83 = 38155 * v76 - 610480;
          v84 = v82 & ~(v82 >> 31);
          v85 = (v83 + v62) >> 15;
          if (v85 >= 255)
          {
            v85 = 255;
          }

          v86 = (v83 + v60) >> 15;
          if (v86 >= 255)
          {
            v86 = 255;
          }

          v87 = v86 & ~(v86 >> 31);
          v88 = (v83 + v61) >> 15;
          *v26 = v84;
          v26[1] = v81;
          if (v88 >= 255)
          {
            v89 = 255;
          }

          else
          {
            v89 = v88;
          }

          v26[2] = v79;
          v26[3] = -1;
          v26[4] = v89 & ~(v89 >> 31);
          v26[5] = v87;
          v26[6] = v85 & ~(v85 >> 31);
          v26[7] = -1;
          v26 += 8;
          --v55;
        }

        while (v55);
        v6 = v142;
        a1 = v143;
        v11 = v140;
        v13 = v138;
      }

      if (a1)
      {
        v90 = *v29 - 128;
        v91 = *v28 - 128;
        v92 = 38155 * *v30 - 610480;
        v93 = -6987 * v90 - 17461 * v91;
        v94 = 69219 * v90;
        v95 = 58745 * v91;
        v96 = (v92 + v95) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        v97 = v96 & ~(v96 >> 31);
        v98 = (v93 + v92) >> 15;
        if (v98 >= 255)
        {
          v98 = 255;
        }

        v99 = v98 & ~(v98 >> 31);
        v100 = (v92 + v94) >> 15;
        if (v100 >= 255)
        {
          v100 = 255;
        }

        *v27 = v100 & ~(v100 >> 31);
        v27[1] = v99;
        v27[2] = v97;
        v27[3] = -1;
        v101 = 38155 * *v25 - 610480;
        v102 = (v101 + v95) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = (v101 + v93) >> 15;
        if (v103 >= 255)
        {
          v103 = 255;
        }

        v104 = v103 & ~(v103 >> 31);
        v105 = (v101 + v94) >> 15;
        if (v105 >= 255)
        {
          v105 = 255;
        }

        *v26 = v105 & ~(v105 >> 31);
        v26[1] = v104;
        v26[2] = v102 & ~(v102 >> 31);
        v26[3] = -1;
      }

      v7 += v144;
      v8 += v13;
      v9 += v13;
      v10 += 2 * v15;
      ++v12;
      v16 += v144;
    }

    while (v12 != v11);
  }

  if (v136)
  {
    if (a1 >= 2)
    {
      do
      {
        v106 = *v8;
        v8 += 2;
        v107 = v106 - 128;
        v108 = *v9;
        v9 += 2;
        v109 = *v7;
        v110 = v7[1];
        v7 += 2;
        v111 = v6;
        v112 = 38155 * v109 - 610480;
        v113 = -6987 * v107 - 17461 * (v108 - 128);
        v114 = 69219 * v107;
        v115 = 58745 * (v108 - 128);
        v116 = (v112 + v115) >> 15;
        if (v116 >= 255)
        {
          v116 = 255;
        }

        v117 = v116 & ~(v116 >> 31);
        v118 = (v113 + v112) >> 15;
        if (v118 >= 255)
        {
          v118 = 255;
        }

        v119 = v118 & ~(v118 >> 31);
        v120 = (v112 + v114) >> 15;
        if (v120 >= 255)
        {
          v120 = 255;
        }

        v121 = v120 & ~(v120 >> 31);
        v122 = 38155 * v110 - 610480;
        v123 = (v122 + v115) >> 15;
        if (v123 >= 255)
        {
          v123 = 255;
        }

        v124 = (v122 + v113) >> 15;
        if (v124 >= 255)
        {
          v124 = 255;
        }

        v125 = v124 & ~(v124 >> 31);
        v126 = (v122 + v114) >> 15;
        *v10 = v121;
        v10[1] = v119;
        if (v126 >= 255)
        {
          v126 = 255;
        }

        v10[2] = v117;
        v10[3] = -1;
        v10[4] = v126 & ~(v126 >> 31);
        v10[5] = v125;
        v10[6] = v123 & ~(v123 >> 31);
        v10[7] = -1;
        v10 += 8;
        v6 = v111 - 1;
      }

      while (v111 != 1);
    }

    if (a1)
    {
      v127 = *v8 - 128;
      v128 = *v9 - 128;
      v129 = 38155 * *v7 - 610480;
      v130 = -6987 * v127 - 17461 * v128;
      v131 = (v129 + 58745 * v128) >> 15;
      if (v131 >= 255)
      {
        v131 = 255;
      }

      v132 = (v130 + v129) >> 15;
      if (v132 >= 255)
      {
        v132 = 255;
      }

      v133 = v132 & ~(v132 >> 31);
      v134 = (v129 + 69219 * v127) >> 15;
      if (v134 >= 255)
      {
        v134 = 255;
      }

      *v10 = v134 & ~(v134 >> 31);
      v10[1] = v133;
      v10[2] = v131 & ~(v131 >> 31);
      v10[3] = -1;
    }
  }

  return 0;
}

uint64_t vt_Copy_420vITU709_24RGB_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = *a4;
  v7 = a4[1];
  v8 = v7 + 1;
  v9 = *a6;
  v124 = a1;
  v117 = a2;
  if (a2 >= 2)
  {
    v11 = 0;
    v12 = a2 >> 1;
    v13 = a3[1];
    v14 = *a5;
    v15 = 4 * (a1 >> 3);
    v125 = 2 * *a3;
    v121 = *a3;
    v122 = a2 >> 1;
    v16 = &v6[*a3];
    v123 = a1 >> 3;
    v118 = (a1 >> 1) - v15;
    v119 = v15;
    v17.i64[0] = 0xFF000000FFLL;
    v17.i64[1] = 0xFF000000FFLL;
    v18.i64[0] = 0x7F0000007FLL;
    v18.i64[1] = 0x7F0000007FLL;
    v19 = vdupq_n_s32(0xFFFFE4B5);
    v20 = vdupq_n_s32(0xFFFFBBCB);
    v21 = vdupq_n_s32(0x10E63u);
    v22 = vdupq_n_s32(0xE579u);
    v23 = vdupq_n_s16(0x950Bu);
    v24 = vdupq_n_s32(0xFFF6AF50);
    v10 = a1 >> 1;
    v120 = v13;
    do
    {
      if (a1 >= 8)
      {
        v31 = 0;
        v32 = v123;
        v27 = v9;
        do
        {
          v33 = *&v7[v31];
          v34 = &v27[v14];
          v35 = vaddw_u16(v18, *&vmovl_u8(vuzp1_s8(v33, 0xFF000000FFLL)));
          v36 = vaddw_u16(v18, *&vmovl_u8(vuzp2_s8(v33, 0xFF000000FFLL)));
          v37 = vmlaq_s32(vmulq_s32(v35, v19), v36, v20);
          v38 = vmulq_s32(v35, v21);
          v39 = vmulq_s32(v36, v22);
          v40 = vzip1q_s32(v38, v38);
          v41 = vzip2q_s32(v38, v38);
          v42 = vzip1q_s32(v39, v39);
          v43 = vzip1q_s32(v37, v37);
          v44 = vmovl_u8(*&v6[v31]);
          v45 = vmovl_u8(*&v16[v31]);
          v46 = vmlal_u16(v24, *v44.i8, *v23.i8);
          v47 = vzip2q_s32(v39, v39);
          v48 = vmlal_high_u16(v24, v44, v23);
          v49 = vmlal_u16(v24, *v45.i8, *v23.i8);
          v50 = vzip2q_s32(v37, v37);
          v51 = vmlal_high_u16(v24, v45, v23);
          v126.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v46), 0xFuLL), vaddq_s32(v47, v48), 0xFuLL));
          v126.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v46), 0xFuLL), vaddq_s32(v50, v48), 0xFuLL));
          v127.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v49), 0xFuLL), vaddq_s32(v47, v51), 0xFuLL));
          v126.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v46), 0xFuLL), vaddq_s32(v41, v48), 0xFuLL));
          v127.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v49), 0xFuLL), vaddq_s32(v50, v51), 0xFuLL));
          vst3_s8(v27, v126);
          v27 += 24;
          v127.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v49), 0xFuLL), vaddq_s32(v41, v51), 0xFuLL));
          vst3_s8(v34, v127);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v6[v31];
        v25 = &v16[v31];
        v29 = &v7[v31];
        v28 = &v7[v31 + 1];
        v26 = &v27[v14];
      }

      else
      {
        v25 = &v6[v121];
        v26 = &v9[v14];
        v27 = v9;
        v28 = v8;
        v29 = v7;
        v30 = v6;
      }

      if (v10 > v15)
      {
        v52 = v118;
        do
        {
          v54 = *v29;
          v29 += 2;
          v53 = v54;
          v55 = *v28;
          v28 += 2;
          v56 = v53 - 128;
          v57 = -6987 * (v53 - 128) - 17461 * (v55 - 128);
          v58 = 69219 * v56;
          v59 = 58745 * (v55 - 128);
          v60 = 38155 * v30[1] - 610480;
          v61 = (v60 + v57) >> 15;
          if (v61 >= 255)
          {
            v61 = 255;
          }

          v62 = (v60 + v58) >> 15;
          v63 = v61 & ~(v61 >> 31);
          if (v62 >= 255)
          {
            v62 = 255;
          }

          v64.i32[0] = 38155 * *v30 - 610480;
          v64.i32[1] = v57;
          v64.i64[1] = __PAIR64__(v60, v64.u32[0]);
          v65.i32[0] = v59;
          v66.i64[0] = __PAIR64__(v64.u32[0], v59);
          v66.i64[1] = __PAIR64__(v59, v58);
          v30 += 2;
          *v27 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v64, v66), 0xFuLL), v17), 0)), *v17.i8).u32[0];
          v27[4] = v63;
          v27[5] = v62 & ~(v62 >> 31);
          v27 += 6;
          v67 = *v25;
          v68 = v25[1];
          v25 += 2;
          v69 = 38155 * v67 - 610480;
          v70 = 38155 * v68 - 610480;
          v71 = (v70 + v57) >> 15;
          if (v71 >= 255)
          {
            v71 = 255;
          }

          v65.i32[1] = v69;
          v72 = vdupq_lane_s32(*v65.i8, 1);
          v65.i64[1] = __PAIR64__(v59, v58);
          v72.i32[1] = v57;
          v72.i32[3] = v70;
          if ((v70 + v58) >> 15 >= 255)
          {
            v73 = 255;
          }

          else
          {
            v73 = (v70 + v58) >> 15;
          }

          *v26 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v65, v72), 0xFuLL), v17), 0)), *v17.i8).u32[0];
          v26[4] = v71 & ~(v71 >> 31);
          v26[5] = v73 & ~(v73 >> 31);
          v26 += 6;
          --v52;
        }

        while (v52);
        a1 = v124;
        v12 = v122;
        v15 = v119;
        v13 = v120;
      }

      if (a1)
      {
        v74 = *v29 - 128;
        v75 = *v28 - 128;
        v76 = 38155 * *v30 - 610480;
        v77 = -6987 * v74 - 17461 * v75;
        v78 = 69219 * v74;
        v79 = 58745 * v75;
        v80 = (v76 + v79) >> 15;
        if (v80 >= 255)
        {
          v80 = 255;
        }

        v81 = v80 & ~(v80 >> 31);
        v82 = (v77 + v76) >> 15;
        if (v82 >= 255)
        {
          v82 = 255;
        }

        v83 = v82 & ~(v82 >> 31);
        v84 = (v76 + v78) >> 15;
        if (v84 >= 255)
        {
          v84 = 255;
        }

        *v27 = v81;
        v27[1] = v83;
        v27[2] = v84 & ~(v84 >> 31);
        v85 = 38155 * *v25 - 610480;
        v86 = (v85 + v79) >> 15;
        if (v86 >= 255)
        {
          v86 = 255;
        }

        v87 = v86 & ~(v86 >> 31);
        v88 = (v85 + v77) >> 15;
        if (v88 >= 255)
        {
          v88 = 255;
        }

        v89 = v88 & ~(v88 >> 31);
        v90 = (v85 + v78) >> 15;
        if (v90 >= 255)
        {
          v90 = 255;
        }

        *v26 = v87;
        v26[1] = v89;
        v26[2] = v90 & ~(v90 >> 31);
      }

      v6 += v125;
      v7 += v13;
      v8 += v13;
      v9 += 2 * v14;
      ++v11;
      v16 += v125;
    }

    while (v11 != v12);
  }

  else
  {
    v10 = a1 >> 1;
  }

  if (v117)
  {
    if (a1 >= 2)
    {
      v91.i64[0] = 0xFF000000FFLL;
      v91.i64[1] = 0xFF000000FFLL;
      do
      {
        v92 = *v7;
        v7 += 2;
        v93 = v92 - 128;
        v94 = *v8;
        v8 += 2;
        v95 = *v6;
        v96 = v6[1];
        v6 += 2;
        v97 = 38155 * v95 - 610480;
        v98 = -6987 * v93 - 17461 * (v94 - 128);
        v99 = 58745 * (v94 - 128);
        v100 = 69219 * v93;
        v101 = 38155 * v96 - 610480;
        v102 = (v101 + v98) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = v102 & ~(v102 >> 31);
        v104.i64[0] = __PAIR64__(v98, v97);
        v104.i64[1] = __PAIR64__(v101, v97);
        v105.i64[0] = __PAIR64__(v97, v99);
        v105.i64[1] = __PAIR64__(v99, v100);
        if ((v101 + v100) >> 15 >= 255)
        {
          v106 = 255;
        }

        else
        {
          v106 = (v101 + v100) >> 15;
        }

        *v9 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v104, v105), 0xFuLL), v91), 0)), *v91.i8).u32[0];
        v9[4] = v103;
        v9[5] = v106 & ~(v106 >> 31);
        v9 += 6;
        --v10;
      }

      while (v10);
      LOBYTE(a1) = v124;
    }

    if (a1)
    {
      v107 = *v7 - 128;
      v108 = *v8 - 128;
      v109 = 38155 * *v6 - 610480;
      v110 = -6987 * v107 - 17461 * v108;
      v111 = (v109 + 58745 * v108) >> 15;
      if (v111 >= 255)
      {
        v111 = 255;
      }

      v112 = v111 & ~(v111 >> 31);
      v113 = (v110 + v109) >> 15;
      if (v113 >= 255)
      {
        v113 = 255;
      }

      v114 = v113 & ~(v113 >> 31);
      v115 = (v109 + 69219 * v107) >> 15;
      if (v115 >= 255)
      {
        v115 = 255;
      }

      *v9 = v112;
      v9[1] = v114;
      v9[2] = v115 & ~(v115 >> 31);
    }
  }

  return 0;
}

uint64_t vt_Copy_420fITU709F_32BGRA_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = a1 >> 1;
  v7 = *a4;
  v8 = a4[1];
  v9 = v8 + 1;
  v10 = *a6;
  v134 = a2;
  if (a2 >= 2)
  {
    v12 = 0;
    v13 = a2 >> 1;
    v14 = *a3;
    v15 = a3[1];
    v16 = *a5;
    v17 = 4 * (a1 >> 3);
    v141 = 2 * v14;
    v142 = v15;
    v137 = v14;
    v138 = a2 >> 1;
    v18 = &v7[v14];
    v139 = a1 >> 3;
    v135 = v6 - v17;
    v136 = v17;
    v19 = vdupq_n_s32(0xFFFFE807);
    v20 = vdupq_n_s32(0xFFFFC416);
    v21.i64[0] = 0x7F0000007FLL;
    v21.i64[1] = 0x7F0000007FLL;
    v22 = vdupq_n_s32(0xED84u);
    v23 = vdupq_n_s32(0xC993u);
    v24 = -1;
    v11 = a1;
    do
    {
      if (v11 >= 8)
      {
        v31 = 0;
        v32 = v139;
        v27 = v10;
        do
        {
          v33 = &v27[v16];
          v34 = *&v8[v31];
          v35 = vaddw_u16(v21, *&vmovl_u8(vuzp1_s8(v34, *v19.i8)));
          v36 = vaddw_u16(v21, *&vmovl_u8(vuzp2_s8(v34, *v19.i8)));
          v37 = vmulq_s32(v35, v19);
          v38 = vmulq_s32(v35, v22);
          v39 = vmulq_s32(v36, v23);
          v40 = vmlaq_s32(v37, v36, v20);
          v41 = vzip1q_s32(v38, v38);
          v42 = vzip2q_s32(v38, v38);
          v43 = vzip1q_s32(v39, v39);
          v44 = vzip1q_s32(v40, v40);
          v45 = vmovl_u8(*&v7[v31]);
          v46 = vmovl_u8(*&v18[v31]);
          v47 = vshll_n_u16(*v45.i8, 0xFuLL);
          v48 = vzip2q_s32(v39, v39);
          v49 = vshll_high_n_u16(v45, 0xFuLL);
          v50 = vshll_n_u16(*v46.i8, 0xFuLL);
          v51 = vshll_high_n_u16(v46, 0xFuLL);
          v52 = vzip2q_s32(v40, v40);
          v53 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v47), 0xFuLL), vaddq_s32(v48, v49), 0xFuLL));
          v54 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v47), 0xFuLL), vaddq_s32(v52, v49), 0xFuLL));
          v143.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v50), 0xFuLL), vaddq_s32(v48, v51), 0xFuLL));
          v55 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v47), 0xFuLL), vaddq_s32(v42, v49), 0xFuLL));
          v143.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v50), 0xFuLL), vaddq_s32(v52, v51), 0xFuLL));
          vst4_s8(v27, *(&v24 - 3));
          v27 += 32;
          v143.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v50), 0xFuLL), vaddq_s32(v42, v51), 0xFuLL));
          v143.val[3] = -1;
          vst4_s8(v33, v143);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v7[v31];
        v25 = &v18[v31];
        v29 = &v8[v31];
        v28 = &v8[v31 + 1];
        v26 = &v27[v16];
      }

      else
      {
        v25 = &v7[v137];
        v26 = &v10[v16];
        v27 = v10;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v6 > v17)
      {
        v56 = v135;
        do
        {
          v58 = *v29;
          v29 += 2;
          v57 = v58;
          v59 = *v28;
          v28 += 2;
          v60 = v57 - 128;
          v61 = *v30;
          v62 = v30[1];
          v30 += 2;
          v63 = -6137 * (v57 - 128) - 15338 * (v59 - 128);
          v64 = 51603 * (v59 - 128);
          v65 = 60804 * v60;
          v66 = (v64 + (v61 << 15)) >> 15;
          if (v66 >= 255)
          {
            v66 = 255;
          }

          v67 = v66 & ~(v66 >> 31);
          v68 = (v63 + (v61 << 15)) >> 15;
          if (v68 >= 255)
          {
            v68 = 255;
          }

          v69 = v68 & ~(v68 >> 31);
          v70 = (v65 + (v61 << 15)) >> 15;
          if (v70 >= 255)
          {
            v70 = 255;
          }

          v71 = v70 & ~(v70 >> 31);
          v72 = (v64 + (v62 << 15)) >> 15;
          if (v72 >= 255)
          {
            v72 = 255;
          }

          v73 = (v63 + (v62 << 15)) >> 15;
          v74 = v72 & ~(v72 >> 31);
          if (v73 >= 255)
          {
            v73 = 255;
          }

          v75 = (v65 + (v62 << 15)) >> 15;
          v76 = v73 & ~(v73 >> 31);
          if (v75 >= 255)
          {
            v75 = 255;
          }

          v27[1] = v69;
          v27[2] = v67;
          v27[3] = -1;
          *v27 = v71;
          v27[4] = v75 & ~(v75 >> 31);
          v27[5] = v76;
          v27[6] = v74;
          v27[7] = -1;
          v77 = *v25;
          v27 += 8;
          v78 = v25[1];
          v25 += 2;
          v79 = (v64 + (v77 << 15)) >> 15;
          if (v79 >= 255)
          {
            v79 = 255;
          }

          v80 = v79 & ~(v79 >> 31);
          v81 = (v63 + (v77 << 15)) >> 15;
          if (v81 >= 255)
          {
            v81 = 255;
          }

          v82 = v81 & ~(v81 >> 31);
          v83 = (v65 + (v77 << 15)) >> 15;
          if (v83 >= 255)
          {
            v83 = 255;
          }

          v84 = v83 & ~(v83 >> 31);
          v85 = (v64 + (v78 << 15)) >> 15;
          if (v85 >= 255)
          {
            v85 = 255;
          }

          v86 = (v63 + (v78 << 15)) >> 15;
          if (v86 >= 255)
          {
            v86 = 255;
          }

          v87 = v86 & ~(v86 >> 31);
          v88 = (v65 + (v78 << 15)) >> 15;
          *v26 = v84;
          v26[1] = v82;
          if (v88 >= 255)
          {
            v89 = 255;
          }

          else
          {
            v89 = v88;
          }

          v26[2] = v80;
          v26[3] = -1;
          v26[4] = v89 & ~(v89 >> 31);
          v26[5] = v87;
          v26[6] = v85 & ~(v85 >> 31);
          v26[7] = -1;
          v26 += 8;
          --v56;
        }

        while (v56);
        v11 = a1;
        v13 = v138;
        v17 = v136;
      }

      if (v11)
      {
        v90 = *v29 - 128;
        v91 = *v28 - 128;
        v92 = *v30;
        v93 = -6137 * v90 - 15338 * v91;
        v94 = 60804 * v90;
        v95 = 51603 * v91;
        v96 = (v95 + (v92 << 15)) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        v97 = v96 & ~(v96 >> 31);
        v98 = (v93 + (v92 << 15)) >> 15;
        if (v98 >= 255)
        {
          v98 = 255;
        }

        v99 = v98 & ~(v98 >> 31);
        v100 = (v94 + (v92 << 15)) >> 15;
        if (v100 >= 255)
        {
          v100 = 255;
        }

        *v27 = v100 & ~(v100 >> 31);
        v27[1] = v99;
        v27[2] = v97;
        v27[3] = -1;
        v101 = *v25;
        v102 = (v95 + (v101 << 15)) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = (v93 + (v101 << 15)) >> 15;
        if (v103 >= 255)
        {
          v103 = 255;
        }

        v104 = v103 & ~(v103 >> 31);
        v105 = (v94 + (v101 << 15)) >> 15;
        if (v105 >= 255)
        {
          v105 = 255;
        }

        *v26 = v105 & ~(v105 >> 31);
        v26[1] = v104;
        v26[2] = v102 & ~(v102 >> 31);
        v26[3] = -1;
      }

      v7 += v141;
      v8 += v142;
      v9 += v142;
      v10 += 2 * v16;
      ++v12;
      v18 += v141;
    }

    while (v12 != v13);
  }

  else
  {
    v11 = a1;
  }

  if (v134)
  {
    if (v11 >= 2)
    {
      do
      {
        v106 = *v8;
        v8 += 2;
        v107 = v106 - 128;
        v108 = *v9;
        v9 += 2;
        v109 = *v7;
        v110 = v7[1];
        v7 += 2;
        v111 = -6137 * v107 - 15338 * (v108 - 128);
        v112 = 51603 * (v108 - 128);
        v113 = (v112 + (v109 << 15)) >> 15;
        if (v113 >= 255)
        {
          v113 = 255;
        }

        v114 = v113 & ~(v113 >> 31);
        v115 = (v111 + (v109 << 15)) >> 15;
        v116 = 60804 * v107;
        if (v115 >= 255)
        {
          v115 = 255;
        }

        v117 = v115 & ~(v115 >> 31);
        v118 = (v116 + (v109 << 15)) >> 15;
        if (v118 >= 255)
        {
          v118 = 255;
        }

        v119 = v118 & ~(v118 >> 31);
        v120 = (v112 + (v110 << 15)) >> 15;
        if (v120 >= 255)
        {
          v120 = 255;
        }

        v121 = (v111 + (v110 << 15)) >> 15;
        if (v121 >= 255)
        {
          v121 = 255;
        }

        v122 = v121 & ~(v121 >> 31);
        v123 = (v116 + (v110 << 15)) >> 15;
        *v10 = v119;
        v10[1] = v117;
        if (v123 >= 255)
        {
          v123 = 255;
        }

        v10[2] = v114;
        v10[3] = -1;
        v10[4] = v123 & ~(v123 >> 31);
        v10[5] = v122;
        v10[6] = v120 & ~(v120 >> 31);
        v10[7] = -1;
        v10 += 8;
        --v6;
      }

      while (v6);
      LOBYTE(v11) = a1;
    }

    if (v11)
    {
      v124 = *v8 - 128;
      v125 = *v9 - 128;
      v126 = *v7;
      v127 = -6137 * v124 - 15338 * v125;
      v128 = 60804 * v124;
      v129 = (51603 * v125 + (v126 << 15)) >> 15;
      if (v129 >= 255)
      {
        v129 = 255;
      }

      v130 = (v127 + (v126 << 15)) >> 15;
      if (v130 >= 255)
      {
        v130 = 255;
      }

      v131 = v130 & ~(v130 >> 31);
      v132 = (v128 + (v126 << 15)) >> 15;
      if (v132 >= 255)
      {
        v132 = 255;
      }

      *v10 = v132 & ~(v132 >> 31);
      v10[1] = v131;
      v10[2] = v129 & ~(v129 >> 31);
      v10[3] = -1;
    }
  }

  return 0;
}

uint64_t vt_Copy_420fITU709F_32ARGB_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = a1 >> 1;
  v7 = *a4;
  v8 = a4[1];
  v9 = v8 + 1;
  v10 = *a6;
  v137 = a2;
  if (a2 >= 2)
  {
    v12 = 0;
    v13 = a2 >> 1;
    v14 = *a3;
    v15 = a3[1];
    v16 = *a5;
    v17 = 4 * (a1 >> 3);
    v144 = 2 * v14;
    v145 = v15;
    v140 = v14;
    v141 = a2 >> 1;
    v18 = &v7[v14];
    v142 = a1 >> 3;
    v138 = v6 - v17;
    v139 = v17;
    v19 = vdupq_n_s32(0xFFFFE807);
    v20 = vdupq_n_s32(0xFFFFC416);
    v21.i64[0] = 0x7F0000007FLL;
    v21.i64[1] = 0x7F0000007FLL;
    v22 = vdupq_n_s32(0xED84u);
    v23 = vdupq_n_s32(0xC993u);
    v24 = -1;
    v11 = a1;
    do
    {
      if (v11 >= 8)
      {
        v31 = 0;
        v32 = v142;
        v27 = v10;
        do
        {
          v33 = &v27[v16];
          v34 = *&v8[v31];
          v35 = vaddw_u16(v21, *&vmovl_u8(vuzp1_s8(v34, *v19.i8)));
          v36 = vaddw_u16(v21, *&vmovl_u8(vuzp2_s8(v34, *v19.i8)));
          v37 = vmulq_s32(v35, v19);
          v38 = vmulq_s32(v35, v22);
          v39 = vmulq_s32(v36, v23);
          v40 = vmlaq_s32(v37, v36, v20);
          v41 = vzip1q_s32(v38, v38);
          v42 = vzip2q_s32(v38, v38);
          v43 = vzip1q_s32(v39, v39);
          v44 = vzip1q_s32(v40, v40);
          v45 = vmovl_u8(*&v7[v31]);
          v46 = vmovl_u8(*&v18[v31]);
          v47 = vshll_n_u16(*v45.i8, 0xFuLL);
          v48 = vzip2q_s32(v39, v39);
          v49 = vshll_high_n_u16(v45, 0xFuLL);
          v50 = vshll_n_u16(*v46.i8, 0xFuLL);
          v51 = vshll_high_n_u16(v46, 0xFuLL);
          v52 = vzip2q_s32(v40, v40);
          v53 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v47), 0xFuLL), vaddq_s32(v48, v49), 0xFuLL));
          v54 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v47), 0xFuLL), vaddq_s32(v52, v49), 0xFuLL));
          v146.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v50), 0xFuLL), vaddq_s32(v48, v51), 0xFuLL));
          v55 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v47), 0xFuLL), vaddq_s32(v42, v49), 0xFuLL));
          v146.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v50), 0xFuLL), vaddq_s32(v52, v51), 0xFuLL));
          vst4_s8(v27, *&v24);
          v27 += 32;
          v146.val[3] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v50), 0xFuLL), vaddq_s32(v42, v51), 0xFuLL));
          v146.val[0] = -1;
          vst4_s8(v33, v146);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v7[v31];
        v25 = &v18[v31];
        v29 = &v8[v31];
        v28 = &v8[v31 + 1];
        v26 = &v27[v16];
      }

      else
      {
        v25 = &v7[v140];
        v26 = &v10[v16];
        v27 = v10;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v6 > v17)
      {
        v56 = v138;
        do
        {
          v58 = *v29;
          v29 += 2;
          v57 = v58;
          v59 = *v28;
          v28 += 2;
          v60 = v57 - 128;
          v61 = *v30;
          v62 = v30[1];
          v30 += 2;
          v63 = -6137 * (v57 - 128) - 15338 * (v59 - 128);
          v64 = 51603 * (v59 - 128);
          v65 = 60804 * v60;
          v66 = (v64 + (v61 << 15)) >> 15;
          if (v66 >= 255)
          {
            v66 = 255;
          }

          v67 = v66 & ~(v66 >> 31);
          v68 = (v63 + (v61 << 15)) >> 15;
          if (v68 >= 255)
          {
            v68 = 255;
          }

          v69 = v68 & ~(v68 >> 31);
          v70 = (v65 + (v61 << 15)) >> 15;
          if (v70 >= 255)
          {
            v70 = 255;
          }

          v71 = v70 & ~(v70 >> 31);
          v72 = (v64 + (v62 << 15)) >> 15;
          if (v72 >= 255)
          {
            v72 = 255;
          }

          v73 = (v63 + (v62 << 15)) >> 15;
          v74 = v72 & ~(v72 >> 31);
          if (v73 >= 255)
          {
            v73 = 255;
          }

          v75 = (v65 + (v62 << 15)) >> 15;
          v76 = v73 & ~(v73 >> 31);
          if (v75 >= 255)
          {
            v75 = 255;
          }

          *v27 = -1;
          v27[1] = v67;
          v27[2] = v69;
          v27[3] = v71;
          v27[4] = -1;
          v27[5] = v74;
          v27[6] = v76;
          v27[7] = v75 & ~(v75 >> 31);
          v77 = *v25;
          v27 += 8;
          v78 = v25[1];
          v25 += 2;
          v79 = (v64 + (v77 << 15)) >> 15;
          if (v79 >= 255)
          {
            v79 = 255;
          }

          v80 = v79 & ~(v79 >> 31);
          v81 = (v63 + (v77 << 15)) >> 15;
          if (v81 >= 255)
          {
            v81 = 255;
          }

          v82 = v81 & ~(v81 >> 31);
          v83 = (v65 + (v77 << 15)) >> 15;
          if (v83 >= 255)
          {
            v83 = 255;
          }

          v84 = v83 & ~(v83 >> 31);
          v85 = (v64 + (v78 << 15)) >> 15;
          if (v85 >= 255)
          {
            v85 = 255;
          }

          v86 = (v63 + (v78 << 15)) >> 15;
          v87 = v85 & ~(v85 >> 31);
          if (v86 >= 255)
          {
            v86 = 255;
          }

          v88 = (v65 + (v78 << 15)) >> 15;
          v89 = v86 & ~(v86 >> 31);
          *v26 = -1;
          v26[1] = v80;
          if (v88 >= 255)
          {
            v88 = 255;
          }

          v26[2] = v82;
          v26[4] = -1;
          v26[3] = v84;
          v26[5] = v87;
          v26[6] = v89;
          v26[7] = v88 & ~(v88 >> 31);
          v26 += 8;
          --v56;
        }

        while (v56);
        v11 = a1;
        v13 = v141;
        v17 = v139;
      }

      if (v11)
      {
        v90 = *v29 - 128;
        v91 = *v28 - 128;
        v92 = *v30;
        v93 = -6137 * v90 - 15338 * v91;
        v94 = 60804 * v90;
        v95 = 51603 * v91;
        v96 = (v95 + (v92 << 15)) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        v97 = v96 & ~(v96 >> 31);
        v98 = (v93 + (v92 << 15)) >> 15;
        if (v98 >= 255)
        {
          v98 = 255;
        }

        v99 = v98 & ~(v98 >> 31);
        v100 = (v94 + (v92 << 15)) >> 15;
        if (v100 >= 255)
        {
          v100 = 255;
        }

        *v27 = -1;
        v27[1] = v97;
        v27[2] = v99;
        v27[3] = v100 & ~(v100 >> 31);
        v101 = *v25;
        v102 = (v95 + (v101 << 15)) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = v102 & ~(v102 >> 31);
        v104 = (v93 + (v101 << 15)) >> 15;
        if (v104 >= 255)
        {
          v104 = 255;
        }

        v105 = v104 & ~(v104 >> 31);
        v106 = (v94 + (v101 << 15)) >> 15;
        if (v106 >= 255)
        {
          v106 = 255;
        }

        *v26 = -1;
        v26[1] = v103;
        v26[2] = v105;
        v26[3] = v106 & ~(v106 >> 31);
      }

      v7 += v144;
      v8 += v145;
      v9 += v145;
      v10 += 2 * v16;
      ++v12;
      v18 += v144;
    }

    while (v12 != v13);
  }

  else
  {
    v11 = a1;
  }

  if (v137)
  {
    if (v11 >= 2)
    {
      do
      {
        v107 = *v8;
        v8 += 2;
        v108 = v107 - 128;
        v109 = *v9;
        v9 += 2;
        v110 = *v7;
        v111 = v7[1];
        v7 += 2;
        v112 = -6137 * v108 - 15338 * (v109 - 128);
        v113 = 51603 * (v109 - 128);
        v114 = (v113 + (v110 << 15)) >> 15;
        if (v114 >= 255)
        {
          v114 = 255;
        }

        v115 = v114 & ~(v114 >> 31);
        v116 = (v112 + (v110 << 15)) >> 15;
        v117 = 60804 * v108;
        if (v116 >= 255)
        {
          v116 = 255;
        }

        v118 = v116 & ~(v116 >> 31);
        v119 = (v117 + (v110 << 15)) >> 15;
        if (v119 >= 255)
        {
          v119 = 255;
        }

        v120 = v119 & ~(v119 >> 31);
        v121 = (v113 + (v111 << 15)) >> 15;
        if (v121 >= 255)
        {
          v121 = 255;
        }

        v122 = v121 & ~(v121 >> 31);
        v123 = (v112 + (v111 << 15)) >> 15;
        if (v123 >= 255)
        {
          v123 = 255;
        }

        v124 = v123 & ~(v123 >> 31);
        v125 = (v117 + (v111 << 15)) >> 15;
        *v10 = -1;
        v10[1] = v115;
        if (v125 >= 255)
        {
          v125 = 255;
        }

        v10[2] = v118;
        v10[3] = v120;
        v10[4] = -1;
        v10[5] = v122;
        v10[6] = v124;
        v10[7] = v125 & ~(v125 >> 31);
        v10 += 8;
        --v6;
      }

      while (v6);
      LOBYTE(v11) = a1;
    }

    if (v11)
    {
      v126 = *v8 - 128;
      v127 = *v9 - 128;
      v128 = *v7;
      v129 = -6137 * v126 - 15338 * v127;
      v130 = 60804 * v126;
      v131 = (51603 * v127 + (v128 << 15)) >> 15;
      if (v131 >= 255)
      {
        v131 = 255;
      }

      v132 = v131 & ~(v131 >> 31);
      v133 = (v129 + (v128 << 15)) >> 15;
      if (v133 >= 255)
      {
        v133 = 255;
      }

      v134 = v133 & ~(v133 >> 31);
      v135 = (v130 + (v128 << 15)) >> 15;
      if (v135 >= 255)
      {
        v135 = 255;
      }

      *v10 = -1;
      v10[1] = v132;
      v10[2] = v134;
      v10[3] = v135 & ~(v135 >> 31);
    }
  }

  return 0;
}

uint64_t vt_Copy_420fITU709F_24RGB_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = a1 >> 1;
  v7 = *a4;
  v8 = a4[1];
  v9 = v8 + 1;
  v10 = *a6;
  v130 = a1;
  v125 = a2;
  if (a2 >= 2)
  {
    v11 = 0;
    v12 = a2 >> 1;
    v13 = *a3;
    v14 = a3[1];
    v15 = *a5;
    v16 = 4 * (a1 >> 3);
    v17 = 2 * v13;
    v128 = v13;
    v129 = a1 >> 3;
    v18 = &v7[v13];
    v126 = v6 - v16;
    v19.i64[0] = 0xFF000000FFLL;
    v19.i64[1] = 0xFF000000FFLL;
    v20.i64[0] = 0x7F0000007FLL;
    v20.i64[1] = 0x7F0000007FLL;
    v21 = vdupq_n_s32(0xFFFFE807);
    v22 = vdupq_n_s32(0xFFFFC416);
    v23 = vdupq_n_s32(0xED84u);
    v24 = vdupq_n_s32(0xC993u);
    v127 = 2 * v13;
    do
    {
      if (a1 >= 8)
      {
        v31 = 0;
        v32 = v129;
        v27 = v10;
        do
        {
          v33 = *&v8[v31];
          v34 = &v27[v15];
          v35 = vaddw_u16(v20, *&vmovl_u8(vuzp1_s8(v33, 0x80000000C993)));
          v36 = vaddw_u16(v20, *&vmovl_u8(vuzp2_s8(v33, 0x80000000C993)));
          v37 = vmlaq_s32(vmulq_s32(v35, v21), v36, v22);
          v38 = vmulq_s32(v35, v23);
          v39 = vmulq_s32(v36, v24);
          v40 = vzip1q_s32(v38, v38);
          v41 = vzip2q_s32(v38, v38);
          v42 = vzip1q_s32(v39, v39);
          v43 = vzip2q_s32(v39, v39);
          v44 = vzip1q_s32(v37, v37);
          v45 = vmovl_u8(*&v7[v31]);
          v46 = vmovl_u8(*&v18[v31]);
          v47 = vshll_n_u16(*v45.i8, 0xFuLL);
          v48 = vshll_high_n_u16(v45, 0xFuLL);
          v49 = vshll_n_u16(*v46.i8, 0xFuLL);
          v50 = vzip2q_s32(v37, v37);
          v51 = vshll_high_n_u16(v46, 0xFuLL);
          v132.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v47), 0xFuLL), vaddq_s32(v43, v48), 0xFuLL));
          v132.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v47), 0xFuLL), vaddq_s32(v50, v48), 0xFuLL));
          v131.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v49), 0xFuLL), vaddq_s32(v43, v51), 0xFuLL));
          v132.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v47), 0xFuLL), vaddq_s32(v41, v48), 0xFuLL));
          v131.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v49), 0xFuLL), vaddq_s32(v50, v51), 0xFuLL));
          vst3_s8(v27, v132);
          v27 += 24;
          v131.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v49), 0xFuLL), vaddq_s32(v41, v51), 0xFuLL));
          vst3_s8(v34, v131);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v7[v31];
        v25 = &v18[v31];
        v29 = &v8[v31];
        v28 = &v8[v31 + 1];
        v26 = &v27[v15];
      }

      else
      {
        v25 = &v7[v128];
        v26 = &v10[v15];
        v27 = v10;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v6 > v16)
      {
        v52 = v14;
        v53 = v16;
        v54 = v12;
        v55 = v126;
        do
        {
          v56 = *v29;
          v29 += 2;
          v57 = v56 - 128;
          v58 = *v28;
          v28 += 2;
          v59 = *v30;
          v60 = v30[1];
          v30 += 2;
          v61 = -6137 * v57 - 15338 * (v58 - 128);
          v62.i32[0] = v58 - 128;
          v62.i32[1] = v59;
          v63 = 60804 * v57;
          v64 = vmul_s32(v62, 0x80000000C993);
          v65 = v60 << 15;
          v66 = (v61 + (v60 << 15)) >> 15;
          if (v66 >= 255)
          {
            v66 = 255;
          }

          v67 = v66 & ~(v66 >> 31);
          v68 = (v63 + (v60 << 15)) >> 15;
          if (v68 >= 255)
          {
            v68 = 255;
          }

          *v69.i8 = v64;
          v69.i64[1] = __PAIR64__(v64.u32[0], v63);
          v70 = vdupq_lane_s32(v64, 1);
          v70.i32[1] = v61;
          v70.i32[3] = v65;
          *v27 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v69, v70), 0xFuLL), v19), 0)), 0x80000000C993).u32[0];
          v27[4] = v67;
          v27[5] = v68 & ~(v68 >> 31);
          v27 += 6;
          v71 = *v25;
          v72 = v25[1];
          v25 += 2;
          v73 = v71 << 15;
          v74 = v72 << 15;
          v75 = (v61 + (v72 << 15)) >> 15;
          if (v75 >= 255)
          {
            v75 = 255;
          }

          v76 = (v63 + (v72 << 15)) >> 15;
          v77.i64[0] = __PAIR64__(v73, v64.u32[0]);
          v78 = vdupq_lane_s32(__PAIR64__(v73, v64.u32[0]), 1);
          v77.i64[1] = __PAIR64__(v64.u32[0], v63);
          v78.i32[1] = v61;
          v78.i32[3] = v74;
          if (v76 >= 255)
          {
            v79 = 255;
          }

          else
          {
            v79 = v76;
          }

          *v26 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v77, v78), 0xFuLL), v19), 0)), 0x80000000C993).u32[0];
          v26[4] = v75 & ~(v75 >> 31);
          v26[5] = v79 & ~(v79 >> 31);
          v26 += 6;
          --v55;
        }

        while (v55);
        v12 = v54;
        v16 = v53;
        a1 = v130;
        v14 = v52;
        v17 = v127;
      }

      if (a1)
      {
        v80 = *v29 - 128;
        v81 = *v28 - 128;
        v82 = *v30;
        v83 = -6137 * v80 - 15338 * v81;
        v84 = 60804 * v80;
        v85 = 51603 * v81;
        v86 = (v85 + (v82 << 15)) >> 15;
        if (v86 >= 255)
        {
          v86 = 255;
        }

        v87 = v86 & ~(v86 >> 31);
        v88 = (v83 + (v82 << 15)) >> 15;
        if (v88 >= 255)
        {
          v88 = 255;
        }

        v89 = v88 & ~(v88 >> 31);
        v90 = (v84 + (v82 << 15)) >> 15;
        if (v90 >= 255)
        {
          v90 = 255;
        }

        *v27 = v87;
        v27[1] = v89;
        v27[2] = v90 & ~(v90 >> 31);
        v91 = *v25;
        v92 = (v85 + (v91 << 15)) >> 15;
        if (v92 >= 255)
        {
          v92 = 255;
        }

        v93 = v92 & ~(v92 >> 31);
        v94 = (v83 + (v91 << 15)) >> 15;
        if (v94 >= 255)
        {
          v94 = 255;
        }

        v95 = v94 & ~(v94 >> 31);
        v96 = (v84 + (v91 << 15)) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        *v26 = v93;
        v26[1] = v95;
        v26[2] = v96 & ~(v96 >> 31);
      }

      v7 += v17;
      v8 += v14;
      v9 += v14;
      v10 += 2 * v15;
      ++v11;
      v18 += v17;
    }

    while (v11 != v12);
  }

  if (v125)
  {
    if (a1 >= 2)
    {
      v97.i64[0] = 0xFF000000FFLL;
      v97.i64[1] = 0xFF000000FFLL;
      do
      {
        v98 = *v8;
        v8 += 2;
        v99 = v98 - 128;
        v100 = *v9;
        v9 += 2;
        v101 = *v7;
        v102 = v7[1];
        v7 += 2;
        v103 = v101 << 15;
        v104 = -6137 * v99 - 15338 * (v100 - 128);
        v105 = 51603 * (v100 - 128);
        v106 = 60804 * v99;
        v107 = v102 << 15;
        v108 = (v104 + (v102 << 15)) >> 15;
        v109 = v106 + (v102 << 15);
        if (v108 >= 255)
        {
          v108 = 255;
        }

        v110.i64[0] = __PAIR64__(v103, v105);
        v110.i64[1] = __PAIR64__(v105, v106);
        v111 = v109 >> 15;
        v112.i64[0] = __PAIR64__(v104, v103);
        v112.i64[1] = __PAIR64__(v107, v103);
        if (v111 >= 255)
        {
          v113 = 255;
        }

        else
        {
          v113 = v111;
        }

        *v10 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v110, v112), 0xFuLL), v97), 0)), *v97.i8).u32[0];
        v10[4] = v108 & ~(v108 >> 31);
        v10[5] = v113 & ~(v113 >> 31);
        v10 += 6;
        --v6;
      }

      while (v6);
      LOBYTE(a1) = v130;
    }

    if (a1)
    {
      v114 = *v8 - 128;
      v115 = *v9 - 128;
      v116 = *v7;
      v117 = -6137 * v114 - 15338 * v115;
      v118 = 60804 * v114;
      v119 = (51603 * v115 + (v116 << 15)) >> 15;
      if (v119 >= 255)
      {
        v119 = 255;
      }

      v120 = v119 & ~(v119 >> 31);
      v121 = (v117 + (v116 << 15)) >> 15;
      if (v121 >= 255)
      {
        v121 = 255;
      }

      v122 = v121 & ~(v121 >> 31);
      v123 = (v118 + (v116 << 15)) >> 15;
      if (v123 >= 255)
      {
        v123 = 255;
      }

      *v10 = v120;
      v10[1] = v122;
      v10[2] = v123 & ~(v123 >> 31);
    }
  }

  return 0;
}

uint64_t vt_Copy_y420ITU2020_32ARGB_vec(unint64_t a1, unint64_t a2, uint64_t *a3, uint8x8_t **a4, uint64_t *a5, char **a6)
{
  v6 = a1;
  v7 = *a4;
  v8 = a4[1];
  v9 = a4[2];
  v10 = a1 >> 1;
  v11 = *a6;
  v137 = a2;
  if (a2 >= 2)
  {
    v12 = 0;
    v144 = a2 >> 1;
    v13 = *a3;
    v143 = a3[1];
    v142 = a3[2];
    v14 = *a5;
    v15 = 4 * (a1 >> 3);
    v141 = 2 * *a3;
    v16 = v10 - v15;
    v17.i64[0] = 0x7F0000007FLL;
    v17.i64[1] = 0x7F0000007FLL;
    v18 = vdupq_n_s32(0xFFFFE7F5);
    v19 = vdupq_n_s32(0xFFFFAC81);
    v20 = vdupq_n_s32(0x112F4u);
    v21 = vdupq_n_s32(0xD781u);
    v22 = vdupq_n_s16(0x957Bu);
    v23 = vdupq_n_s32(0xFFF6A850);
    v24 = -1;
    v138 = a1 >> 1;
    do
    {
      if (v6 >= 8)
      {
        v31 = 0;
        v30 = v7;
        v27 = v11;
        do
        {
          v32 = &v27[v14];
          v33 = vaddw_u16(v17, *&vmovl_u8(v8->u32[v31 / 4]));
          v34 = vaddw_u16(v17, *&vmovl_u8(v9->u32[v31 / 4]));
          v35 = vmlaq_s32(vmulq_s32(v33, v18), v34, v19);
          v36 = vmulq_s32(v33, v20);
          v37 = vmulq_s32(v34, v21);
          v38 = vzip1q_s32(v36, v36);
          v39 = vzip2q_s32(v36, v36);
          v40 = vzip1q_s32(v37, v37);
          v41 = vmovl_u8(*v30);
          v42 = vmovl_u8(*(v30 + v13));
          v43 = vzip2q_s32(v37, v37);
          v44 = vmlal_u16(v23, *v41.i8, *v22.i8);
          v45 = vmlal_high_u16(v23, v41, v22);
          v46 = vzip1q_s32(v35, v35);
          v47 = vmlal_u16(v23, *v42.i8, *v22.i8);
          v48 = vmlal_high_u16(v23, v42, v22);
          v49 = vzip2q_s32(v35, v35);
          v145.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v44), 0xFuLL), vaddq_s32(v43, v45), 0xFuLL));
          v145.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v46, v44), 0xFuLL), vaddq_s32(v49, v45), 0xFuLL));
          v50 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v47), 0xFuLL), vaddq_s32(v43, v48), 0xFuLL));
          v145.val[3] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v38, v44), 0xFuLL), vaddq_s32(v39, v45), 0xFuLL));
          v51 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v46, v47), 0xFuLL), vaddq_s32(v49, v48), 0xFuLL));
          v52 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v38, v47), 0xFuLL), vaddq_s32(v39, v48), 0xFuLL));
          v145.val[0] = -1;
          vst4_s8(v27, v145);
          v27 += 32;
          vst4_s8(v32, *&v24);
          ++v30;
          v31 += 4;
        }

        while (v15 != v31);
        v25 = v30 + v13;
        v29 = v8 + v31;
        v28 = v9 + v31;
        v26 = &v27[v14];
      }

      else
      {
        v25 = v7 + v13;
        v26 = &v11[v14];
        v27 = v11;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v10 > v15)
      {
        v140 = v12;
        v53 = 0;
        do
        {
          v54 = v29[v53] - 128;
          v55 = v30->u8[0];
          v56 = v30->u8[1];
          v30 = (v30 + 2);
          v57 = 38267 * v55 - 612272;
          v58 = v28[v53] - 128;
          v59 = -6155 * v54 - 21375 * v58;
          v60 = 70388 * v54;
          v61 = 55169 * v58;
          v62 = (v57 + 55169 * v58) >> 15;
          if (v62 >= 255)
          {
            v62 = 255;
          }

          v63 = v62 & ~(v62 >> 31);
          v64 = (v59 + v57) >> 15;
          if (v64 >= 255)
          {
            v64 = 255;
          }

          v65 = v64 & ~(v64 >> 31);
          v66 = (v57 + v60) >> 15;
          if (v66 >= 255)
          {
            v66 = 255;
          }

          v67 = v66 & ~(v66 >> 31);
          v68 = 38267 * v56 - 612272;
          v69 = (v68 + v61) >> 15;
          if (v69 >= 255)
          {
            v69 = 255;
          }

          v70 = v69 & ~(v69 >> 31);
          v71 = (v68 + v59) >> 15;
          if (v71 >= 255)
          {
            v71 = 255;
          }

          v72 = v71 & ~(v71 >> 31);
          v73 = (v68 + v60) >> 15;
          if (v73 >= 255)
          {
            v73 = 255;
          }

          *v27 = -1;
          v27[1] = v63;
          v27[2] = v65;
          v27[3] = v67;
          v27[4] = -1;
          v27[5] = v70;
          v27[6] = v72;
          v27[7] = v73 & ~(v73 >> 31);
          v27 += 8;
          v74 = v25[1];
          v75 = 38267 * *v25 - 612272;
          v25 += 2;
          v76 = (v75 + v61) >> 15;
          if (v76 >= 255)
          {
            v76 = 255;
          }

          v77 = v76 & ~(v76 >> 31);
          v78 = (v75 + v59) >> 15;
          if (v78 >= 255)
          {
            v78 = 255;
          }

          v79 = (v75 + v60) >> 15;
          v80 = v78 & ~(v78 >> 31);
          if (v79 >= 255)
          {
            v79 = 255;
          }

          v81 = 38267 * v74 - 612272;
          v82 = (v81 + v61) >> 15;
          v83 = v79 & ~(v79 >> 31);
          if (v82 >= 255)
          {
            v82 = 255;
          }

          v84 = (v81 + v59) >> 15;
          v85 = v82 & ~(v82 >> 31);
          if (v84 >= 255)
          {
            v84 = 255;
          }

          v86 = (v81 + v60) >> 15;
          *v26 = -1;
          v87 = v84 & ~(v84 >> 31);
          v26[1] = v77;
          if (v86 >= 255)
          {
            v86 = 255;
          }

          v26[2] = v80;
          v26[4] = -1;
          v26[3] = v83;
          v26[5] = v85;
          v26[6] = v87;
          v26[7] = v86 & ~(v86 >> 31);
          v26 += 8;
          ++v53;
        }

        while (v16 != v53);
        v29 += v53;
        v28 += v53;
        v10 = v138;
        v6 = a1;
        v12 = v140;
      }

      if (v6)
      {
        v88 = *v29 - 128;
        v89 = *v28 - 128;
        v90 = 38267 * v30->u8[0] - 612272;
        v91 = -6155 * v88 - 21375 * v89;
        v92 = 70388 * v88;
        v93 = 55169 * v89;
        v94 = (v90 + v93) >> 15;
        if (v94 >= 255)
        {
          v94 = 255;
        }

        v95 = v94 & ~(v94 >> 31);
        v96 = (v91 + v90) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        v97 = v96 & ~(v96 >> 31);
        v98 = (v90 + v92) >> 15;
        if (v98 >= 255)
        {
          v98 = 255;
        }

        *v27 = -1;
        v27[1] = v95;
        v27[2] = v97;
        v27[3] = v98 & ~(v98 >> 31);
        v99 = 38267 * *v25 - 612272;
        v100 = (v99 + v93) >> 15;
        if (v100 >= 255)
        {
          v100 = 255;
        }

        v101 = v100 & ~(v100 >> 31);
        v102 = (v99 + v91) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = v102 & ~(v102 >> 31);
        v104 = (v99 + v92) >> 15;
        if (v104 >= 255)
        {
          v104 = 255;
        }

        *v26 = -1;
        v26[1] = v101;
        v26[2] = v103;
        v26[3] = v104 & ~(v104 >> 31);
      }

      v7 = (v7 + v141);
      v8 = (v8 + v143);
      v9 = (v9 + v142);
      v11 += 2 * v14;
      ++v12;
    }

    while (v12 != v144);
  }

  if (v137)
  {
    if (v6 >= 2)
    {
      do
      {
        v105 = v8->u8[0];
        v8 = (v8 + 1);
        v106 = v105 - 128;
        v107 = v9->u8[0];
        v9 = (v9 + 1);
        v108 = v7->u8[0];
        v109 = v10;
        v110 = v7->u8[1];
        v7 = (v7 + 2);
        v111 = 38267 * v108 - 612272;
        v112 = -6155 * v106 - 21375 * (v107 - 128);
        v113 = 70388 * v106;
        v114 = 55169 * (v107 - 128);
        v115 = (v111 + v114) >> 15;
        if (v115 >= 255)
        {
          v115 = 255;
        }

        v116 = v115 & ~(v115 >> 31);
        v117 = (v112 + v111) >> 15;
        if (v117 >= 255)
        {
          v117 = 255;
        }

        v118 = v117 & ~(v117 >> 31);
        v119 = (v111 + v113) >> 15;
        if (v119 >= 255)
        {
          v119 = 255;
        }

        v120 = v119 & ~(v119 >> 31);
        v121 = 38267 * v110 - 612272;
        v122 = (v121 + v114) >> 15;
        if (v122 >= 255)
        {
          v122 = 255;
        }

        v123 = v122 & ~(v122 >> 31);
        v124 = (v121 + v112) >> 15;
        if (v124 >= 255)
        {
          v124 = 255;
        }

        v125 = v124 & ~(v124 >> 31);
        v126 = (v121 + v113) >> 15;
        *v11 = -1;
        v11[1] = v116;
        if (v126 >= 255)
        {
          v126 = 255;
        }

        v11[2] = v118;
        v11[3] = v120;
        v11[4] = -1;
        v11[5] = v123;
        v11[6] = v125;
        v11[7] = v126 & ~(v126 >> 31);
        v11 += 8;
        v10 = v109 - 1;
      }

      while (v109 != 1);
    }

    if (v6)
    {
      v127 = v8->u8[0] - 128;
      v128 = v9->u8[0] - 128;
      v129 = 38267 * v7->u8[0] - 612272;
      v130 = -6155 * v127 - 21375 * v128;
      v131 = (v129 + 55169 * v128) >> 15;
      if (v131 >= 255)
      {
        v131 = 255;
      }

      v132 = v131 & ~(v131 >> 31);
      v133 = (v130 + v129) >> 15;
      if (v133 >= 255)
      {
        v133 = 255;
      }

      v134 = v133 & ~(v133 >> 31);
      v135 = (v129 + 70388 * v127) >> 15;
      if (v135 >= 255)
      {
        v135 = 255;
      }

      *v11 = -1;
      v11[1] = v132;
      v11[2] = v134;
      v11[3] = v135 & ~(v135 >> 31);
    }
  }

  return 0;
}

uint64_t vt_Copy_420vITU2020_32ARGB_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = a1 >> 1;
  v7 = *a4;
  v8 = a4[1];
  v9 = v8 + 1;
  v10 = *a6;
  v138 = a2;
  if (a2 >= 2)
  {
    v11 = a2 >> 1;
    v12 = 0;
    v14 = *a3;
    v13 = a3[1];
    v15 = *a5;
    v146 = 2 * v14;
    v147 = 4 * (a1 >> 3);
    v145 = a1;
    v141 = v14;
    v142 = v11;
    v16 = &v7[v14];
    v143 = a1 >> 3;
    v144 = a1 >> 1;
    v139 = v6 - v147;
    v140 = v13;
    v17 = vdupq_n_s32(0xFFFFE7F5);
    v18 = vdupq_n_s32(0xFFFFAC81);
    v19 = vdupq_n_s32(0x112F4u);
    v20 = vdupq_n_s32(0xD781u);
    v21.i64[0] = 0x7F0000007FLL;
    v21.i64[1] = 0x7F0000007FLL;
    v22 = vdupq_n_s16(0x957Bu);
    v23 = vdupq_n_s32(0xFFF6A850);
    v24 = -1;
    do
    {
      if (a1 >= 8)
      {
        v31 = 0;
        v32 = v143;
        v27 = v10;
        do
        {
          v33 = &v27[v15];
          v34 = *&v8[v31];
          v35 = vaddw_u16(v21, *&vmovl_u8(vuzp1_s8(v34, *v17.i8)));
          v36 = vaddw_u16(v21, *&vmovl_u8(vuzp2_s8(v34, *v17.i8)));
          v37 = vmlaq_s32(vmulq_s32(v35, v17), v36, v18);
          v38 = vmulq_s32(v35, v19);
          v39 = vmulq_s32(v36, v20);
          v40 = vzip1q_s32(v38, v38);
          v41 = vzip2q_s32(v38, v38);
          v42 = vzip1q_s32(v39, v39);
          v43 = vmovl_u8(*&v7[v31]);
          v44 = vmovl_u8(*&v16[v31]);
          v45 = vzip1q_s32(v37, v37);
          v46 = vmlal_u16(v23, *v43.i8, *v22.i8);
          v47 = vmlal_high_u16(v23, v43, v22);
          v48 = vzip2q_s32(v39, v39);
          v49 = vmlal_u16(v23, *v44.i8, *v22.i8);
          v50 = vmlal_high_u16(v23, v44, v22);
          v51 = vzip2q_s32(v37, v37);
          v52 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v46), 0xFuLL), vaddq_s32(v48, v47), 0xFuLL));
          v53 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v45, v46), 0xFuLL), vaddq_s32(v51, v47), 0xFuLL));
          v148.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v49), 0xFuLL), vaddq_s32(v48, v50), 0xFuLL));
          v54 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v46), 0xFuLL), vaddq_s32(v41, v47), 0xFuLL));
          v148.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v45, v49), 0xFuLL), vaddq_s32(v51, v50), 0xFuLL));
          vst4_s8(v27, *&v24);
          v27 += 32;
          v148.val[3] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v49), 0xFuLL), vaddq_s32(v41, v50), 0xFuLL));
          v148.val[0] = -1;
          vst4_s8(v33, v148);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v7[v31];
        v25 = &v16[v31];
        v29 = &v8[v31];
        v28 = &v8[v31 + 1];
        v26 = &v27[v15];
      }

      else
      {
        v25 = &v7[v141];
        v26 = &v10[v15];
        v27 = v10;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v6 > v147)
      {
        v55 = v139;
        do
        {
          v56 = *v29;
          v29 += 2;
          v57 = v56 - 128;
          v58 = *v28;
          v28 += 2;
          v59 = 38267 * *v30 - 612272;
          v60 = -6155 * v57 - 21375 * (v58 - 128);
          v61 = 70388 * v57;
          v62 = 55169 * (v58 - 128);
          v63 = (v59 + v62) >> 15;
          if (v63 >= 255)
          {
            v63 = 255;
          }

          v64 = v63 & ~(v63 >> 31);
          v65 = (v60 + v59) >> 15;
          if (v65 >= 255)
          {
            v65 = 255;
          }

          v66 = v65 & ~(v65 >> 31);
          v67 = (v59 + v61) >> 15;
          if (v67 >= 255)
          {
            v67 = 255;
          }

          v68 = v67 & ~(v67 >> 31);
          v69 = 38267 * v30[1] - 612272;
          v70 = (v69 + v62) >> 15;
          if (v70 >= 255)
          {
            v70 = 255;
          }

          v71 = v70 & ~(v70 >> 31);
          v72 = (v69 + v60) >> 15;
          if (v72 >= 255)
          {
            v72 = 255;
          }

          v73 = v72 & ~(v72 >> 31);
          v74 = (v69 + v61) >> 15;
          if (v74 >= 255)
          {
            v74 = 255;
          }

          v30 += 2;
          *v27 = -1;
          v27[1] = v64;
          v27[2] = v66;
          v27[3] = v68;
          v27[4] = -1;
          v27[5] = v71;
          v27[6] = v73;
          v27[7] = v74 & ~(v74 >> 31);
          v27 += 8;
          v75 = *v25;
          v76 = v25[1];
          v25 += 2;
          v77 = 38267 * v75 - 612272;
          v78 = (v77 + v62) >> 15;
          if (v78 >= 255)
          {
            v78 = 255;
          }

          v79 = v78 & ~(v78 >> 31);
          v80 = (v77 + v60) >> 15;
          if (v80 >= 255)
          {
            v80 = 255;
          }

          v81 = v80 & ~(v80 >> 31);
          v82 = (v77 + v61) >> 15;
          if (v82 >= 255)
          {
            v82 = 255;
          }

          v83 = 38267 * v76 - 612272;
          v84 = v82 & ~(v82 >> 31);
          v85 = (v83 + v62) >> 15;
          if (v85 >= 255)
          {
            v85 = 255;
          }

          v86 = (v83 + v60) >> 15;
          v87 = v85 & ~(v85 >> 31);
          if (v86 >= 255)
          {
            v86 = 255;
          }

          v88 = (v83 + v61) >> 15;
          *v26 = -1;
          v26[1] = v79;
          if (v88 >= 255)
          {
            v88 = 255;
          }

          v26[2] = v81;
          v26[4] = -1;
          v26[3] = v84;
          v26[5] = v87;
          v26[6] = v86 & ~(v86 >> 31);
          v26[7] = v88 & ~(v88 >> 31);
          v26 += 8;
          --v55;
        }

        while (v55);
        v6 = v144;
        a1 = v145;
        v11 = v142;
        v13 = v140;
      }

      if (a1)
      {
        v89 = *v29 - 128;
        v90 = *v28 - 128;
        v91 = 38267 * *v30 - 612272;
        v92 = -6155 * v89 - 21375 * v90;
        v93 = 70388 * v89;
        v94 = 55169 * v90;
        v95 = (v91 + v94) >> 15;
        if (v95 >= 255)
        {
          v95 = 255;
        }

        v96 = v95 & ~(v95 >> 31);
        v97 = (v92 + v91) >> 15;
        if (v97 >= 255)
        {
          v97 = 255;
        }

        v98 = v97 & ~(v97 >> 31);
        v99 = (v91 + v93) >> 15;
        if (v99 >= 255)
        {
          v99 = 255;
        }

        *v27 = -1;
        v27[1] = v96;
        v27[2] = v98;
        v27[3] = v99 & ~(v99 >> 31);
        v100 = 38267 * *v25 - 612272;
        v101 = (v100 + v94) >> 15;
        if (v101 >= 255)
        {
          v101 = 255;
        }

        v102 = v101 & ~(v101 >> 31);
        v103 = (v100 + v92) >> 15;
        if (v103 >= 255)
        {
          v103 = 255;
        }

        v104 = v103 & ~(v103 >> 31);
        v105 = (v100 + v93) >> 15;
        if (v105 >= 255)
        {
          v105 = 255;
        }

        *v26 = -1;
        v26[1] = v102;
        v26[2] = v104;
        v26[3] = v105 & ~(v105 >> 31);
      }

      v7 += v146;
      v8 += v13;
      v9 += v13;
      v10 += 2 * v15;
      ++v12;
      v16 += v146;
    }

    while (v12 != v11);
  }

  if (v138)
  {
    if (a1 >= 2)
    {
      do
      {
        v106 = *v8;
        v8 += 2;
        v107 = v106 - 128;
        v108 = *v9;
        v9 += 2;
        v109 = *v7;
        v110 = v7[1];
        v7 += 2;
        v111 = v6;
        v112 = 38267 * v109 - 612272;
        v113 = -6155 * v107 - 21375 * (v108 - 128);
        v114 = 70388 * v107;
        v115 = 55169 * (v108 - 128);
        v116 = (v112 + v115) >> 15;
        if (v116 >= 255)
        {
          v116 = 255;
        }

        v117 = v116 & ~(v116 >> 31);
        v118 = (v113 + v112) >> 15;
        if (v118 >= 255)
        {
          v118 = 255;
        }

        v119 = v118 & ~(v118 >> 31);
        v120 = (v112 + v114) >> 15;
        if (v120 >= 255)
        {
          v120 = 255;
        }

        v121 = v120 & ~(v120 >> 31);
        v122 = 38267 * v110 - 612272;
        v123 = (v122 + v115) >> 15;
        if (v123 >= 255)
        {
          v123 = 255;
        }

        v124 = v123 & ~(v123 >> 31);
        v125 = (v122 + v113) >> 15;
        if (v125 >= 255)
        {
          v125 = 255;
        }

        v126 = v125 & ~(v125 >> 31);
        v127 = (v122 + v114) >> 15;
        *v10 = -1;
        v10[1] = v117;
        if (v127 >= 255)
        {
          v127 = 255;
        }

        v10[2] = v119;
        v10[3] = v121;
        v10[4] = -1;
        v10[5] = v124;
        v10[6] = v126;
        v10[7] = v127 & ~(v127 >> 31);
        v10 += 8;
        v6 = v111 - 1;
      }

      while (v111 != 1);
    }

    if (a1)
    {
      v128 = *v8 - 128;
      v129 = *v9 - 128;
      v130 = 38267 * *v7 - 612272;
      v131 = -6155 * v128 - 21375 * v129;
      v132 = (v130 + 55169 * v129) >> 15;
      if (v132 >= 255)
      {
        v132 = 255;
      }

      v133 = v132 & ~(v132 >> 31);
      v134 = (v131 + v130) >> 15;
      if (v134 >= 255)
      {
        v134 = 255;
      }

      v135 = v134 & ~(v134 >> 31);
      v136 = (v130 + 70388 * v128) >> 15;
      if (v136 >= 255)
      {
        v136 = 255;
      }

      *v10 = -1;
      v10[1] = v133;
      v10[2] = v135;
      v10[3] = v136 & ~(v136 >> 31);
    }
  }

  return 0;
}

uint64_t vt_Copy_y420ITU2020_32BGRA_vec(unint64_t a1, unint64_t a2, uint64_t *a3, uint8x8_t **a4, uint64_t *a5, char **a6)
{
  v6 = a1;
  v7 = *a4;
  v8 = a4[1];
  v9 = a4[2];
  v10 = a1 >> 1;
  v11 = *a6;
  v136 = a2;
  if (a2 >= 2)
  {
    v12 = 0;
    v142 = a2 >> 1;
    v13 = *a3;
    v141 = a3[1];
    v14 = a3[2];
    v15 = *a5;
    v16 = 4 * (a1 >> 3);
    v17 = v10 - v16;
    v18.i64[0] = 0x7F0000007FLL;
    v18.i64[1] = 0x7F0000007FLL;
    v19 = vdupq_n_s32(0xFFFFE7F5);
    v20 = vdupq_n_s32(0xFFFFAC81);
    v21 = vdupq_n_s32(0x112F4u);
    v22 = vdupq_n_s32(0xD781u);
    v23 = vdupq_n_s16(0x957Bu);
    v24 = vdupq_n_s32(0xFFF6A850);
    v25 = -1;
    v138 = a1 >> 1;
    v137 = v14;
    do
    {
      if (v6 >= 8)
      {
        v32 = 0;
        v31 = v7;
        v28 = v11;
        do
        {
          v33 = &v28[v15];
          v34 = vaddw_u16(v18, *&vmovl_u8(v8->u32[v32 / 4]));
          v35 = vaddw_u16(v18, *&vmovl_u8(v9->u32[v32 / 4]));
          v36 = vmlaq_s32(vmulq_s32(v34, v19), v35, v20);
          v37 = vmulq_s32(v34, v21);
          v38 = vmulq_s32(v35, v22);
          v39 = vzip1q_s32(v37, v37);
          v40 = vzip2q_s32(v37, v37);
          v41 = vzip1q_s32(v38, v38);
          v42 = vmovl_u8(*v31);
          v43 = vmovl_u8(*(v31 + v13));
          v44 = vzip1q_s32(v36, v36);
          v45 = vmlal_u16(v24, *v42.i8, *v23.i8);
          v46 = vmlal_high_u16(v24, v42, v23);
          v47 = vzip2q_s32(v38, v38);
          v48 = vmlal_u16(v24, *v43.i8, *v23.i8);
          v49 = vmlal_high_u16(v24, v43, v23);
          v50 = vzip2q_s32(v36, v36);
          v51 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v45), 0xFuLL), vaddq_s32(v47, v46), 0xFuLL));
          v52 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v45), 0xFuLL), vaddq_s32(v50, v46), 0xFuLL));
          v143.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v48), 0xFuLL), vaddq_s32(v47, v49), 0xFuLL));
          v53 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v39, v45), 0xFuLL), vaddq_s32(v40, v46), 0xFuLL));
          v143.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v48), 0xFuLL), vaddq_s32(v50, v49), 0xFuLL));
          vst4_s8(v28, *(&v25 - 3));
          v28 += 32;
          v143.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v39, v48), 0xFuLL), vaddq_s32(v40, v49), 0xFuLL));
          v143.val[3] = -1;
          vst4_s8(v33, v143);
          ++v31;
          v32 += 4;
        }

        while (v16 != v32);
        v26 = v31 + v13;
        v30 = v8 + v32;
        v29 = v9 + v32;
        v27 = &v28[v15];
      }

      else
      {
        v26 = v7 + v13;
        v27 = &v11[v15];
        v28 = v11;
        v29 = v9;
        v30 = v8;
        v31 = v7;
      }

      if (v10 > v16)
      {
        v140 = v12;
        v54 = 0;
        do
        {
          v55 = v30[v54] - 128;
          v56 = v31->u8[0];
          v57 = v31->u8[1];
          v31 = (v31 + 2);
          v58 = 38267 * v56 - 612272;
          v59 = v29[v54] - 128;
          v60 = -6155 * v55 - 21375 * v59;
          v61 = 70388 * v55;
          v62 = 55169 * v59;
          v63 = (v58 + 55169 * v59) >> 15;
          if (v63 >= 255)
          {
            v63 = 255;
          }

          v64 = v63 & ~(v63 >> 31);
          v65 = (v60 + v58) >> 15;
          if (v65 >= 255)
          {
            v65 = 255;
          }

          v66 = v65 & ~(v65 >> 31);
          v67 = (v58 + v61) >> 15;
          if (v67 >= 255)
          {
            v67 = 255;
          }

          v68 = v67 & ~(v67 >> 31);
          v69 = 38267 * v57 - 612272;
          v70 = (v69 + v62) >> 15;
          if (v70 >= 255)
          {
            v70 = 255;
          }

          v71 = v70 & ~(v70 >> 31);
          v72 = (v69 + v60) >> 15;
          if (v72 >= 255)
          {
            v72 = 255;
          }

          v73 = v72 & ~(v72 >> 31);
          v74 = (v69 + v61) >> 15;
          if (v74 >= 255)
          {
            v74 = 255;
          }

          *v28 = v68;
          v28[1] = v66;
          v28[2] = v64;
          v28[3] = -1;
          v28[5] = v73;
          v28[6] = v71;
          v28[4] = v74 & ~(v74 >> 31);
          v28[7] = -1;
          v28 += 8;
          v75 = v26[1];
          v76 = 38267 * *v26 - 612272;
          v26 += 2;
          v77 = (v76 + v62) >> 15;
          if (v77 >= 255)
          {
            v77 = 255;
          }

          v78 = v77 & ~(v77 >> 31);
          v79 = (v76 + v60) >> 15;
          if (v79 >= 255)
          {
            v79 = 255;
          }

          v80 = (v76 + v61) >> 15;
          v81 = v79 & ~(v79 >> 31);
          if (v80 >= 255)
          {
            v80 = 255;
          }

          v82 = 38267 * v75 - 612272;
          v83 = (v82 + v62) >> 15;
          v84 = v80 & ~(v80 >> 31);
          if (v83 >= 255)
          {
            v83 = 255;
          }

          v85 = (v82 + v60) >> 15;
          v86 = v83 & ~(v83 >> 31);
          if (v85 >= 255)
          {
            v85 = 255;
          }

          v87 = v85 & ~(v85 >> 31);
          v88 = (v82 + v61) >> 15;
          *v27 = v84;
          v27[1] = v81;
          if (v88 >= 255)
          {
            v89 = 255;
          }

          else
          {
            v89 = v88;
          }

          v27[2] = v78;
          v27[3] = -1;
          v27[4] = v89 & ~(v89 >> 31);
          v27[5] = v87;
          v27[6] = v86;
          v27[7] = -1;
          v27 += 8;
          ++v54;
        }

        while (v17 != v54);
        v30 += v54;
        v29 += v54;
        v10 = v138;
        v6 = a1;
        v12 = v140;
        v14 = v137;
      }

      if (v6)
      {
        v90 = *v30 - 128;
        v91 = *v29 - 128;
        v92 = 38267 * v31->u8[0] - 612272;
        v93 = -6155 * v90 - 21375 * v91;
        v94 = 70388 * v90;
        v95 = 55169 * v91;
        v96 = (v92 + v95) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        v97 = v96 & ~(v96 >> 31);
        v98 = (v93 + v92) >> 15;
        if (v98 >= 255)
        {
          v98 = 255;
        }

        v99 = v98 & ~(v98 >> 31);
        v100 = (v92 + v94) >> 15;
        if (v100 >= 255)
        {
          v100 = 255;
        }

        *v28 = v100 & ~(v100 >> 31);
        v28[1] = v99;
        v28[2] = v97;
        v28[3] = -1;
        v101 = 38267 * *v26 - 612272;
        v102 = (v101 + v95) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = (v101 + v93) >> 15;
        if (v103 >= 255)
        {
          v103 = 255;
        }

        v104 = v103 & ~(v103 >> 31);
        v105 = (v101 + v94) >> 15;
        if (v105 >= 255)
        {
          v105 = 255;
        }

        *v27 = v105 & ~(v105 >> 31);
        v27[1] = v104;
        v27[2] = v102 & ~(v102 >> 31);
        v27[3] = -1;
      }

      v7 = (v7 + 2 * v13);
      v8 = (v8 + v141);
      v9 = (v9 + v14);
      v11 += 2 * v15;
      ++v12;
    }

    while (v12 != v142);
  }

  if (v136)
  {
    if (v6 >= 2)
    {
      do
      {
        v106 = v8->u8[0];
        v8 = (v8 + 1);
        v107 = v106 - 128;
        v108 = v9->u8[0];
        v9 = (v9 + 1);
        v109 = v7->u8[0];
        v110 = v10;
        v111 = v7->u8[1];
        v7 = (v7 + 2);
        v112 = 38267 * v109 - 612272;
        v113 = -6155 * v107 - 21375 * (v108 - 128);
        v114 = 70388 * v107;
        v115 = 55169 * (v108 - 128);
        v116 = (v112 + v115) >> 15;
        if (v116 >= 255)
        {
          v116 = 255;
        }

        v117 = v116 & ~(v116 >> 31);
        v118 = (v113 + v112) >> 15;
        if (v118 >= 255)
        {
          v118 = 255;
        }

        v119 = v118 & ~(v118 >> 31);
        v120 = (v112 + v114) >> 15;
        if (v120 >= 255)
        {
          v120 = 255;
        }

        v121 = v120 & ~(v120 >> 31);
        v122 = 38267 * v111 - 612272;
        v123 = (v122 + v115) >> 15;
        if (v123 >= 255)
        {
          v123 = 255;
        }

        v124 = (v122 + v113) >> 15;
        if (v124 >= 255)
        {
          v124 = 255;
        }

        v125 = v124 & ~(v124 >> 31);
        v126 = (v122 + v114) >> 15;
        *v11 = v121;
        v11[1] = v119;
        if (v126 >= 255)
        {
          v126 = 255;
        }

        v11[2] = v117;
        v11[3] = -1;
        v11[4] = v126 & ~(v126 >> 31);
        v11[5] = v125;
        v11[6] = v123 & ~(v123 >> 31);
        v11[7] = -1;
        v11 += 8;
        v10 = v110 - 1;
      }

      while (v110 != 1);
    }

    if (v6)
    {
      v127 = v8->u8[0] - 128;
      v128 = v9->u8[0] - 128;
      v129 = 38267 * v7->u8[0] - 612272;
      v130 = -6155 * v127 - 21375 * v128;
      v131 = (v129 + 55169 * v128) >> 15;
      if (v131 >= 255)
      {
        v131 = 255;
      }

      v132 = (v130 + v129) >> 15;
      if (v132 >= 255)
      {
        v132 = 255;
      }

      v133 = v132 & ~(v132 >> 31);
      v134 = (v129 + 70388 * v127) >> 15;
      if (v134 >= 255)
      {
        v134 = 255;
      }

      *v11 = v134 & ~(v134 >> 31);
      v11[1] = v133;
      v11[2] = v131 & ~(v131 >> 31);
      v11[3] = -1;
    }
  }

  return 0;
}

uint64_t vt_Copy_420vITU2020_32BGRA_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = a1 >> 1;
  v7 = *a4;
  v8 = a4[1];
  v9 = v8 + 1;
  v10 = *a6;
  v136 = a2;
  if (a2 >= 2)
  {
    v11 = a2 >> 1;
    v12 = 0;
    v14 = *a3;
    v13 = a3[1];
    v15 = *a5;
    v144 = 2 * v14;
    v145 = 4 * (a1 >> 3);
    v143 = a1;
    v139 = v14;
    v140 = v11;
    v16 = &v7[v14];
    v141 = a1 >> 3;
    v142 = a1 >> 1;
    v137 = v6 - v145;
    v138 = v13;
    v17 = vdupq_n_s32(0xFFFFE7F5);
    v18 = vdupq_n_s32(0xFFFFAC81);
    v19 = vdupq_n_s32(0x112F4u);
    v20 = vdupq_n_s32(0xD781u);
    v21.i64[0] = 0x7F0000007FLL;
    v21.i64[1] = 0x7F0000007FLL;
    v22 = vdupq_n_s16(0x957Bu);
    v23 = vdupq_n_s32(0xFFF6A850);
    v24 = -1;
    do
    {
      if (a1 >= 8)
      {
        v31 = 0;
        v32 = v141;
        v27 = v10;
        do
        {
          v33 = &v27[v15];
          v34 = *&v8[v31];
          v35 = vaddw_u16(v21, *&vmovl_u8(vuzp1_s8(v34, *v17.i8)));
          v36 = vaddw_u16(v21, *&vmovl_u8(vuzp2_s8(v34, *v17.i8)));
          v37 = vmlaq_s32(vmulq_s32(v35, v17), v36, v18);
          v38 = vmulq_s32(v35, v19);
          v39 = vmulq_s32(v36, v20);
          v40 = vzip1q_s32(v38, v38);
          v41 = vzip2q_s32(v38, v38);
          v42 = vzip1q_s32(v39, v39);
          v43 = vmovl_u8(*&v7[v31]);
          v44 = vmovl_u8(*&v16[v31]);
          v45 = vzip1q_s32(v37, v37);
          v46 = vmlal_u16(v23, *v43.i8, *v22.i8);
          v47 = vmlal_high_u16(v23, v43, v22);
          v48 = vzip2q_s32(v39, v39);
          v49 = vmlal_u16(v23, *v44.i8, *v22.i8);
          v50 = vmlal_high_u16(v23, v44, v22);
          v51 = vzip2q_s32(v37, v37);
          v52 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v46), 0xFuLL), vaddq_s32(v48, v47), 0xFuLL));
          v53 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v45, v46), 0xFuLL), vaddq_s32(v51, v47), 0xFuLL));
          v146.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v49), 0xFuLL), vaddq_s32(v48, v50), 0xFuLL));
          v54 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v46), 0xFuLL), vaddq_s32(v41, v47), 0xFuLL));
          v146.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v45, v49), 0xFuLL), vaddq_s32(v51, v50), 0xFuLL));
          vst4_s8(v27, *(&v24 - 3));
          v27 += 32;
          v146.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v49), 0xFuLL), vaddq_s32(v41, v50), 0xFuLL));
          v146.val[3] = -1;
          vst4_s8(v33, v146);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v7[v31];
        v25 = &v16[v31];
        v29 = &v8[v31];
        v28 = &v8[v31 + 1];
        v26 = &v27[v15];
      }

      else
      {
        v25 = &v7[v139];
        v26 = &v10[v15];
        v27 = v10;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v6 > v145)
      {
        v55 = v137;
        do
        {
          v56 = *v29;
          v29 += 2;
          v57 = v56 - 128;
          v58 = *v28;
          v28 += 2;
          v59 = 38267 * *v30 - 612272;
          v60 = -6155 * v57 - 21375 * (v58 - 128);
          v61 = 70388 * v57;
          v62 = 55169 * (v58 - 128);
          v63 = (v59 + v62) >> 15;
          if (v63 >= 255)
          {
            v63 = 255;
          }

          v64 = v63 & ~(v63 >> 31);
          v65 = (v60 + v59) >> 15;
          if (v65 >= 255)
          {
            v65 = 255;
          }

          v66 = v65 & ~(v65 >> 31);
          v67 = (v59 + v61) >> 15;
          if (v67 >= 255)
          {
            v67 = 255;
          }

          v68 = v67 & ~(v67 >> 31);
          v69 = 38267 * v30[1] - 612272;
          v70 = (v69 + v62) >> 15;
          if (v70 >= 255)
          {
            v70 = 255;
          }

          v71 = v70 & ~(v70 >> 31);
          v72 = (v69 + v60) >> 15;
          if (v72 >= 255)
          {
            v72 = 255;
          }

          v73 = v72 & ~(v72 >> 31);
          v74 = (v69 + v61) >> 15;
          if (v74 >= 255)
          {
            v74 = 255;
          }

          v30 += 2;
          *v27 = v68;
          v27[1] = v66;
          v27[2] = v64;
          v27[3] = -1;
          v27[5] = v73;
          v27[4] = v74 & ~(v74 >> 31);
          v27[6] = v71;
          v27[7] = -1;
          v27 += 8;
          v75 = *v25;
          v76 = v25[1];
          v25 += 2;
          v77 = 38267 * v75 - 612272;
          v78 = (v77 + v62) >> 15;
          if (v78 >= 255)
          {
            v78 = 255;
          }

          v79 = v78 & ~(v78 >> 31);
          v80 = (v77 + v60) >> 15;
          if (v80 >= 255)
          {
            v80 = 255;
          }

          v81 = v80 & ~(v80 >> 31);
          v82 = (v77 + v61) >> 15;
          if (v82 >= 255)
          {
            v82 = 255;
          }

          v83 = 38267 * v76 - 612272;
          v84 = v82 & ~(v82 >> 31);
          v85 = (v83 + v62) >> 15;
          if (v85 >= 255)
          {
            v85 = 255;
          }

          v86 = (v83 + v60) >> 15;
          if (v86 >= 255)
          {
            v86 = 255;
          }

          v87 = v86 & ~(v86 >> 31);
          v88 = (v83 + v61) >> 15;
          *v26 = v84;
          v26[1] = v81;
          if (v88 >= 255)
          {
            v89 = 255;
          }

          else
          {
            v89 = v88;
          }

          v26[2] = v79;
          v26[3] = -1;
          v26[4] = v89 & ~(v89 >> 31);
          v26[5] = v87;
          v26[6] = v85 & ~(v85 >> 31);
          v26[7] = -1;
          v26 += 8;
          --v55;
        }

        while (v55);
        v6 = v142;
        a1 = v143;
        v11 = v140;
        v13 = v138;
      }

      if (a1)
      {
        v90 = *v29 - 128;
        v91 = *v28 - 128;
        v92 = 38267 * *v30 - 612272;
        v93 = -6155 * v90 - 21375 * v91;
        v94 = 70388 * v90;
        v95 = 55169 * v91;
        v96 = (v92 + v95) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        v97 = v96 & ~(v96 >> 31);
        v98 = (v93 + v92) >> 15;
        if (v98 >= 255)
        {
          v98 = 255;
        }

        v99 = v98 & ~(v98 >> 31);
        v100 = (v92 + v94) >> 15;
        if (v100 >= 255)
        {
          v100 = 255;
        }

        *v27 = v100 & ~(v100 >> 31);
        v27[1] = v99;
        v27[2] = v97;
        v27[3] = -1;
        v101 = 38267 * *v25 - 612272;
        v102 = (v101 + v95) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = (v101 + v93) >> 15;
        if (v103 >= 255)
        {
          v103 = 255;
        }

        v104 = v103 & ~(v103 >> 31);
        v105 = (v101 + v94) >> 15;
        if (v105 >= 255)
        {
          v105 = 255;
        }

        *v26 = v105 & ~(v105 >> 31);
        v26[1] = v104;
        v26[2] = v102 & ~(v102 >> 31);
        v26[3] = -1;
      }

      v7 += v144;
      v8 += v13;
      v9 += v13;
      v10 += 2 * v15;
      ++v12;
      v16 += v144;
    }

    while (v12 != v11);
  }

  if (v136)
  {
    if (a1 >= 2)
    {
      do
      {
        v106 = *v8;
        v8 += 2;
        v107 = v106 - 128;
        v108 = *v9;
        v9 += 2;
        v109 = *v7;
        v110 = v7[1];
        v7 += 2;
        v111 = v6;
        v112 = 38267 * v109 - 612272;
        v113 = -6155 * v107 - 21375 * (v108 - 128);
        v114 = 70388 * v107;
        v115 = 55169 * (v108 - 128);
        v116 = (v112 + v115) >> 15;
        if (v116 >= 255)
        {
          v116 = 255;
        }

        v117 = v116 & ~(v116 >> 31);
        v118 = (v113 + v112) >> 15;
        if (v118 >= 255)
        {
          v118 = 255;
        }

        v119 = v118 & ~(v118 >> 31);
        v120 = (v112 + v114) >> 15;
        if (v120 >= 255)
        {
          v120 = 255;
        }

        v121 = v120 & ~(v120 >> 31);
        v122 = 38267 * v110 - 612272;
        v123 = (v122 + v115) >> 15;
        if (v123 >= 255)
        {
          v123 = 255;
        }

        v124 = (v122 + v113) >> 15;
        if (v124 >= 255)
        {
          v124 = 255;
        }

        v125 = v124 & ~(v124 >> 31);
        v126 = (v122 + v114) >> 15;
        *v10 = v121;
        v10[1] = v119;
        if (v126 >= 255)
        {
          v126 = 255;
        }

        v10[2] = v117;
        v10[3] = -1;
        v10[4] = v126 & ~(v126 >> 31);
        v10[5] = v125;
        v10[6] = v123 & ~(v123 >> 31);
        v10[7] = -1;
        v10 += 8;
        v6 = v111 - 1;
      }

      while (v111 != 1);
    }

    if (a1)
    {
      v127 = *v8 - 128;
      v128 = *v9 - 128;
      v129 = 38267 * *v7 - 612272;
      v130 = -6155 * v127 - 21375 * v128;
      v131 = (v129 + 55169 * v128) >> 15;
      if (v131 >= 255)
      {
        v131 = 255;
      }

      v132 = (v130 + v129) >> 15;
      if (v132 >= 255)
      {
        v132 = 255;
      }

      v133 = v132 & ~(v132 >> 31);
      v134 = (v129 + 70388 * v127) >> 15;
      if (v134 >= 255)
      {
        v134 = 255;
      }

      *v10 = v134 & ~(v134 >> 31);
      v10[1] = v133;
      v10[2] = v131 & ~(v131 >> 31);
      v10[3] = -1;
    }
  }

  return 0;
}

uint64_t vt_Copy_420vITU2020_24RGB_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = *a4;
  v7 = a4[1];
  v8 = v7 + 1;
  v9 = *a6;
  v124 = a1;
  v117 = a2;
  if (a2 >= 2)
  {
    v11 = 0;
    v12 = a2 >> 1;
    v13 = a3[1];
    v14 = *a5;
    v15 = 4 * (a1 >> 3);
    v125 = 2 * *a3;
    v121 = *a3;
    v122 = a2 >> 1;
    v16 = &v6[*a3];
    v123 = a1 >> 3;
    v118 = (a1 >> 1) - v15;
    v119 = v15;
    v17.i64[0] = 0xFF000000FFLL;
    v17.i64[1] = 0xFF000000FFLL;
    v18.i64[0] = 0x7F0000007FLL;
    v18.i64[1] = 0x7F0000007FLL;
    v19 = vdupq_n_s32(0xFFFFE7F5);
    v20 = vdupq_n_s32(0xFFFFAC81);
    v21 = vdupq_n_s32(0x112F4u);
    v22 = vdupq_n_s32(0xD781u);
    v23 = vdupq_n_s16(0x957Bu);
    v24 = vdupq_n_s32(0xFFF6A850);
    v10 = a1 >> 1;
    v120 = v13;
    do
    {
      if (a1 >= 8)
      {
        v31 = 0;
        v32 = v123;
        v27 = v9;
        do
        {
          v33 = *&v7[v31];
          v34 = &v27[v14];
          v35 = vaddw_u16(v18, *&vmovl_u8(vuzp1_s8(v33, 0xFF000000FFLL)));
          v36 = vaddw_u16(v18, *&vmovl_u8(vuzp2_s8(v33, 0xFF000000FFLL)));
          v37 = vmlaq_s32(vmulq_s32(v35, v19), v36, v20);
          v38 = vmulq_s32(v35, v21);
          v39 = vmulq_s32(v36, v22);
          v40 = vzip1q_s32(v38, v38);
          v41 = vzip2q_s32(v38, v38);
          v42 = vzip1q_s32(v39, v39);
          v43 = vzip1q_s32(v37, v37);
          v44 = vmovl_u8(*&v6[v31]);
          v45 = vmovl_u8(*&v16[v31]);
          v46 = vmlal_u16(v24, *v44.i8, *v23.i8);
          v47 = vzip2q_s32(v39, v39);
          v48 = vmlal_high_u16(v24, v44, v23);
          v49 = vmlal_u16(v24, *v45.i8, *v23.i8);
          v50 = vzip2q_s32(v37, v37);
          v51 = vmlal_high_u16(v24, v45, v23);
          v126.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v46), 0xFuLL), vaddq_s32(v47, v48), 0xFuLL));
          v126.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v46), 0xFuLL), vaddq_s32(v50, v48), 0xFuLL));
          v127.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v49), 0xFuLL), vaddq_s32(v47, v51), 0xFuLL));
          v126.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v46), 0xFuLL), vaddq_s32(v41, v48), 0xFuLL));
          v127.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v49), 0xFuLL), vaddq_s32(v50, v51), 0xFuLL));
          vst3_s8(v27, v126);
          v27 += 24;
          v127.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v49), 0xFuLL), vaddq_s32(v41, v51), 0xFuLL));
          vst3_s8(v34, v127);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v6[v31];
        v25 = &v16[v31];
        v29 = &v7[v31];
        v28 = &v7[v31 + 1];
        v26 = &v27[v14];
      }

      else
      {
        v25 = &v6[v121];
        v26 = &v9[v14];
        v27 = v9;
        v28 = v8;
        v29 = v7;
        v30 = v6;
      }

      if (v10 > v15)
      {
        v52 = v118;
        do
        {
          v54 = *v29;
          v29 += 2;
          v53 = v54;
          v55 = *v28;
          v28 += 2;
          v56 = v53 - 128;
          v57 = -6155 * (v53 - 128) - 21375 * (v55 - 128);
          v58 = 70388 * v56;
          v59 = 55169 * (v55 - 128);
          v60 = 38267 * v30[1] - 612272;
          v61 = (v60 + v57) >> 15;
          if (v61 >= 255)
          {
            v61 = 255;
          }

          v62 = (v60 + v58) >> 15;
          v63 = v61 & ~(v61 >> 31);
          if (v62 >= 255)
          {
            v62 = 255;
          }

          v64.i32[0] = 38267 * *v30 - 612272;
          v64.i32[1] = v57;
          v64.i64[1] = __PAIR64__(v60, v64.u32[0]);
          v65.i32[0] = v59;
          v66.i64[0] = __PAIR64__(v64.u32[0], v59);
          v66.i64[1] = __PAIR64__(v59, v58);
          v30 += 2;
          *v27 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v64, v66), 0xFuLL), v17), 0)), *v17.i8).u32[0];
          v27[4] = v63;
          v27[5] = v62 & ~(v62 >> 31);
          v27 += 6;
          v67 = *v25;
          v68 = v25[1];
          v25 += 2;
          v69 = 38267 * v67 - 612272;
          v70 = 38267 * v68 - 612272;
          v71 = (v70 + v57) >> 15;
          if (v71 >= 255)
          {
            v71 = 255;
          }

          v65.i32[1] = v69;
          v72 = vdupq_lane_s32(*v65.i8, 1);
          v65.i64[1] = __PAIR64__(v59, v58);
          v72.i32[1] = v57;
          v72.i32[3] = v70;
          if ((v70 + v58) >> 15 >= 255)
          {
            v73 = 255;
          }

          else
          {
            v73 = (v70 + v58) >> 15;
          }

          *v26 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v65, v72), 0xFuLL), v17), 0)), *v17.i8).u32[0];
          v26[4] = v71 & ~(v71 >> 31);
          v26[5] = v73 & ~(v73 >> 31);
          v26 += 6;
          --v52;
        }

        while (v52);
        a1 = v124;
        v12 = v122;
        v15 = v119;
        v13 = v120;
      }

      if (a1)
      {
        v74 = *v29 - 128;
        v75 = *v28 - 128;
        v76 = 38267 * *v30 - 612272;
        v77 = -6155 * v74 - 21375 * v75;
        v78 = 70388 * v74;
        v79 = 55169 * v75;
        v80 = (v76 + v79) >> 15;
        if (v80 >= 255)
        {
          v80 = 255;
        }

        v81 = v80 & ~(v80 >> 31);
        v82 = (v77 + v76) >> 15;
        if (v82 >= 255)
        {
          v82 = 255;
        }

        v83 = v82 & ~(v82 >> 31);
        v84 = (v76 + v78) >> 15;
        if (v84 >= 255)
        {
          v84 = 255;
        }

        *v27 = v81;
        v27[1] = v83;
        v27[2] = v84 & ~(v84 >> 31);
        v85 = 38267 * *v25 - 612272;
        v86 = (v85 + v79) >> 15;
        if (v86 >= 255)
        {
          v86 = 255;
        }

        v87 = v86 & ~(v86 >> 31);
        v88 = (v85 + v77) >> 15;
        if (v88 >= 255)
        {
          v88 = 255;
        }

        v89 = v88 & ~(v88 >> 31);
        v90 = (v85 + v78) >> 15;
        if (v90 >= 255)
        {
          v90 = 255;
        }

        *v26 = v87;
        v26[1] = v89;
        v26[2] = v90 & ~(v90 >> 31);
      }

      v6 += v125;
      v7 += v13;
      v8 += v13;
      v9 += 2 * v14;
      ++v11;
      v16 += v125;
    }

    while (v11 != v12);
  }

  else
  {
    v10 = a1 >> 1;
  }

  if (v117)
  {
    if (a1 >= 2)
    {
      v91.i64[0] = 0xFF000000FFLL;
      v91.i64[1] = 0xFF000000FFLL;
      do
      {
        v92 = *v7;
        v7 += 2;
        v93 = v92 - 128;
        v94 = *v8;
        v8 += 2;
        v95 = *v6;
        v96 = v6[1];
        v6 += 2;
        v97 = 38267 * v95 - 612272;
        v98 = -6155 * v93 - 21375 * (v94 - 128);
        v99 = 55169 * (v94 - 128);
        v100 = 70388 * v93;
        v101 = 38267 * v96 - 612272;
        v102 = (v101 + v98) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = v102 & ~(v102 >> 31);
        v104.i64[0] = __PAIR64__(v98, v97);
        v104.i64[1] = __PAIR64__(v101, v97);
        v105.i64[0] = __PAIR64__(v97, v99);
        v105.i64[1] = __PAIR64__(v99, v100);
        if ((v101 + v100) >> 15 >= 255)
        {
          v106 = 255;
        }

        else
        {
          v106 = (v101 + v100) >> 15;
        }

        *v9 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v104, v105), 0xFuLL), v91), 0)), *v91.i8).u32[0];
        v9[4] = v103;
        v9[5] = v106 & ~(v106 >> 31);
        v9 += 6;
        --v10;
      }

      while (v10);
      LOBYTE(a1) = v124;
    }

    if (a1)
    {
      v107 = *v7 - 128;
      v108 = *v8 - 128;
      v109 = 38267 * *v6 - 612272;
      v110 = -6155 * v107 - 21375 * v108;
      v111 = (v109 + 55169 * v108) >> 15;
      if (v111 >= 255)
      {
        v111 = 255;
      }

      v112 = v111 & ~(v111 >> 31);
      v113 = (v110 + v109) >> 15;
      if (v113 >= 255)
      {
        v113 = 255;
      }

      v114 = v113 & ~(v113 >> 31);
      v115 = (v109 + 70388 * v107) >> 15;
      if (v115 >= 255)
      {
        v115 = 255;
      }

      *v9 = v112;
      v9[1] = v114;
      v9[2] = v115 & ~(v115 >> 31);
    }
  }

  return 0;
}

uint64_t vt_Copy_420fITU2020F_32BGRA_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = a1 >> 1;
  v7 = *a4;
  v8 = a4[1];
  v9 = v8 + 1;
  v10 = *a6;
  v134 = a2;
  if (a2 >= 2)
  {
    v12 = 0;
    v13 = a2 >> 1;
    v14 = *a3;
    v15 = a3[1];
    v16 = *a5;
    v17 = 4 * (a1 >> 3);
    v141 = 2 * v14;
    v142 = v15;
    v137 = v14;
    v138 = a2 >> 1;
    v18 = &v7[v14];
    v139 = a1 >> 3;
    v135 = v6 - v17;
    v136 = v17;
    v19 = vdupq_n_s32(0xFFFFEAF1);
    v20 = vdupq_n_s32(0xFFFFB6DF);
    v21.i64[0] = 0x7F0000007FLL;
    v21.i64[1] = 0x7F0000007FLL;
    v22 = vdupq_n_s32(0xF0D2u);
    v23 = vdupq_n_s32(0xBCC0u);
    v24 = -1;
    v11 = a1;
    do
    {
      if (v11 >= 8)
      {
        v31 = 0;
        v32 = v139;
        v27 = v10;
        do
        {
          v33 = &v27[v16];
          v34 = *&v8[v31];
          v35 = vaddw_u16(v21, *&vmovl_u8(vuzp1_s8(v34, *v19.i8)));
          v36 = vaddw_u16(v21, *&vmovl_u8(vuzp2_s8(v34, *v19.i8)));
          v37 = vmulq_s32(v35, v19);
          v38 = vmulq_s32(v35, v22);
          v39 = vmulq_s32(v36, v23);
          v40 = vmlaq_s32(v37, v36, v20);
          v41 = vzip1q_s32(v38, v38);
          v42 = vzip2q_s32(v38, v38);
          v43 = vzip1q_s32(v39, v39);
          v44 = vzip1q_s32(v40, v40);
          v45 = vmovl_u8(*&v7[v31]);
          v46 = vmovl_u8(*&v18[v31]);
          v47 = vshll_n_u16(*v45.i8, 0xFuLL);
          v48 = vzip2q_s32(v39, v39);
          v49 = vshll_high_n_u16(v45, 0xFuLL);
          v50 = vshll_n_u16(*v46.i8, 0xFuLL);
          v51 = vshll_high_n_u16(v46, 0xFuLL);
          v52 = vzip2q_s32(v40, v40);
          v53 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v47), 0xFuLL), vaddq_s32(v48, v49), 0xFuLL));
          v54 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v47), 0xFuLL), vaddq_s32(v52, v49), 0xFuLL));
          v143.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v50), 0xFuLL), vaddq_s32(v48, v51), 0xFuLL));
          v55 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v47), 0xFuLL), vaddq_s32(v42, v49), 0xFuLL));
          v143.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v50), 0xFuLL), vaddq_s32(v52, v51), 0xFuLL));
          vst4_s8(v27, *(&v24 - 3));
          v27 += 32;
          v143.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v50), 0xFuLL), vaddq_s32(v42, v51), 0xFuLL));
          v143.val[3] = -1;
          vst4_s8(v33, v143);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v7[v31];
        v25 = &v18[v31];
        v29 = &v8[v31];
        v28 = &v8[v31 + 1];
        v26 = &v27[v16];
      }

      else
      {
        v25 = &v7[v137];
        v26 = &v10[v16];
        v27 = v10;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v6 > v17)
      {
        v56 = v135;
        do
        {
          v58 = *v29;
          v29 += 2;
          v57 = v58;
          v59 = *v28;
          v28 += 2;
          v60 = v57 - 128;
          v61 = *v30;
          v62 = v30[1];
          v30 += 2;
          v63 = -5391 * (v57 - 128) - 18721 * (v59 - 128);
          v64 = 48320 * (v59 - 128);
          v65 = 61650 * v60;
          v66 = (v64 + (v61 << 15)) >> 15;
          if (v66 >= 255)
          {
            v66 = 255;
          }

          v67 = v66 & ~(v66 >> 31);
          v68 = (v63 + (v61 << 15)) >> 15;
          if (v68 >= 255)
          {
            v68 = 255;
          }

          v69 = v68 & ~(v68 >> 31);
          v70 = (v65 + (v61 << 15)) >> 15;
          if (v70 >= 255)
          {
            v70 = 255;
          }

          v71 = v70 & ~(v70 >> 31);
          v72 = (v64 + (v62 << 15)) >> 15;
          if (v72 >= 255)
          {
            v72 = 255;
          }

          v73 = (v63 + (v62 << 15)) >> 15;
          v74 = v72 & ~(v72 >> 31);
          if (v73 >= 255)
          {
            v73 = 255;
          }

          v75 = (v65 + (v62 << 15)) >> 15;
          v76 = v73 & ~(v73 >> 31);
          if (v75 >= 255)
          {
            v75 = 255;
          }

          v27[1] = v69;
          v27[2] = v67;
          v27[3] = -1;
          *v27 = v71;
          v27[4] = v75 & ~(v75 >> 31);
          v27[5] = v76;
          v27[6] = v74;
          v27[7] = -1;
          v77 = *v25;
          v27 += 8;
          v78 = v25[1];
          v25 += 2;
          v79 = (v64 + (v77 << 15)) >> 15;
          if (v79 >= 255)
          {
            v79 = 255;
          }

          v80 = v79 & ~(v79 >> 31);
          v81 = (v63 + (v77 << 15)) >> 15;
          if (v81 >= 255)
          {
            v81 = 255;
          }

          v82 = v81 & ~(v81 >> 31);
          v83 = (v65 + (v77 << 15)) >> 15;
          if (v83 >= 255)
          {
            v83 = 255;
          }

          v84 = v83 & ~(v83 >> 31);
          v85 = (v64 + (v78 << 15)) >> 15;
          if (v85 >= 255)
          {
            v85 = 255;
          }

          v86 = (v63 + (v78 << 15)) >> 15;
          if (v86 >= 255)
          {
            v86 = 255;
          }

          v87 = v86 & ~(v86 >> 31);
          v88 = (v65 + (v78 << 15)) >> 15;
          *v26 = v84;
          v26[1] = v82;
          if (v88 >= 255)
          {
            v89 = 255;
          }

          else
          {
            v89 = v88;
          }

          v26[2] = v80;
          v26[3] = -1;
          v26[4] = v89 & ~(v89 >> 31);
          v26[5] = v87;
          v26[6] = v85 & ~(v85 >> 31);
          v26[7] = -1;
          v26 += 8;
          --v56;
        }

        while (v56);
        v11 = a1;
        v13 = v138;
        v17 = v136;
      }

      if (v11)
      {
        v90 = *v29 - 128;
        v91 = *v28 - 128;
        v92 = *v30;
        v93 = -5391 * v90 - 18721 * v91;
        v94 = 61650 * v90;
        v95 = 48320 * v91;
        v96 = (v95 + (v92 << 15)) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        v97 = v96 & ~(v96 >> 31);
        v98 = (v93 + (v92 << 15)) >> 15;
        if (v98 >= 255)
        {
          v98 = 255;
        }

        v99 = v98 & ~(v98 >> 31);
        v100 = (v94 + (v92 << 15)) >> 15;
        if (v100 >= 255)
        {
          v100 = 255;
        }

        *v27 = v100 & ~(v100 >> 31);
        v27[1] = v99;
        v27[2] = v97;
        v27[3] = -1;
        v101 = *v25;
        v102 = (v95 + (v101 << 15)) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = (v93 + (v101 << 15)) >> 15;
        if (v103 >= 255)
        {
          v103 = 255;
        }

        v104 = v103 & ~(v103 >> 31);
        v105 = (v94 + (v101 << 15)) >> 15;
        if (v105 >= 255)
        {
          v105 = 255;
        }

        *v26 = v105 & ~(v105 >> 31);
        v26[1] = v104;
        v26[2] = v102 & ~(v102 >> 31);
        v26[3] = -1;
      }

      v7 += v141;
      v8 += v142;
      v9 += v142;
      v10 += 2 * v16;
      ++v12;
      v18 += v141;
    }

    while (v12 != v13);
  }

  else
  {
    v11 = a1;
  }

  if (v134)
  {
    if (v11 >= 2)
    {
      do
      {
        v106 = *v8;
        v8 += 2;
        v107 = v106 - 128;
        v108 = *v9;
        v9 += 2;
        v109 = *v7;
        v110 = v7[1];
        v7 += 2;
        v111 = -5391 * v107 - 18721 * (v108 - 128);
        v112 = 48320 * (v108 - 128);
        v113 = (v112 + (v109 << 15)) >> 15;
        if (v113 >= 255)
        {
          v113 = 255;
        }

        v114 = v113 & ~(v113 >> 31);
        v115 = (v111 + (v109 << 15)) >> 15;
        v116 = 61650 * v107;
        if (v115 >= 255)
        {
          v115 = 255;
        }

        v117 = v115 & ~(v115 >> 31);
        v118 = (v116 + (v109 << 15)) >> 15;
        if (v118 >= 255)
        {
          v118 = 255;
        }

        v119 = v118 & ~(v118 >> 31);
        v120 = (v112 + (v110 << 15)) >> 15;
        if (v120 >= 255)
        {
          v120 = 255;
        }

        v121 = (v111 + (v110 << 15)) >> 15;
        if (v121 >= 255)
        {
          v121 = 255;
        }

        v122 = v121 & ~(v121 >> 31);
        v123 = (v116 + (v110 << 15)) >> 15;
        *v10 = v119;
        v10[1] = v117;
        if (v123 >= 255)
        {
          v123 = 255;
        }

        v10[2] = v114;
        v10[3] = -1;
        v10[4] = v123 & ~(v123 >> 31);
        v10[5] = v122;
        v10[6] = v120 & ~(v120 >> 31);
        v10[7] = -1;
        v10 += 8;
        --v6;
      }

      while (v6);
      LOBYTE(v11) = a1;
    }

    if (v11)
    {
      v124 = *v8 - 128;
      v125 = *v9 - 128;
      v126 = *v7;
      v127 = -5391 * v124 - 18721 * v125;
      v128 = 61650 * v124;
      v129 = (48320 * v125 + (v126 << 15)) >> 15;
      if (v129 >= 255)
      {
        v129 = 255;
      }

      v130 = (v127 + (v126 << 15)) >> 15;
      if (v130 >= 255)
      {
        v130 = 255;
      }

      v131 = v130 & ~(v130 >> 31);
      v132 = (v128 + (v126 << 15)) >> 15;
      if (v132 >= 255)
      {
        v132 = 255;
      }

      *v10 = v132 & ~(v132 >> 31);
      v10[1] = v131;
      v10[2] = v129 & ~(v129 >> 31);
      v10[3] = -1;
    }
  }

  return 0;
}

uint64_t vt_Copy_420fITU2020F_32ARGB_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = a1 >> 1;
  v7 = *a4;
  v8 = a4[1];
  v9 = v8 + 1;
  v10 = *a6;
  v137 = a2;
  if (a2 >= 2)
  {
    v12 = 0;
    v13 = a2 >> 1;
    v14 = *a3;
    v15 = a3[1];
    v16 = *a5;
    v17 = 4 * (a1 >> 3);
    v144 = 2 * v14;
    v145 = v15;
    v140 = v14;
    v141 = a2 >> 1;
    v18 = &v7[v14];
    v142 = a1 >> 3;
    v138 = v6 - v17;
    v139 = v17;
    v19 = vdupq_n_s32(0xFFFFEAF1);
    v20 = vdupq_n_s32(0xFFFFB6DF);
    v21.i64[0] = 0x7F0000007FLL;
    v21.i64[1] = 0x7F0000007FLL;
    v22 = vdupq_n_s32(0xF0D2u);
    v23 = vdupq_n_s32(0xBCC0u);
    v24 = -1;
    v11 = a1;
    do
    {
      if (v11 >= 8)
      {
        v31 = 0;
        v32 = v142;
        v27 = v10;
        do
        {
          v33 = &v27[v16];
          v34 = *&v8[v31];
          v35 = vaddw_u16(v21, *&vmovl_u8(vuzp1_s8(v34, *v19.i8)));
          v36 = vaddw_u16(v21, *&vmovl_u8(vuzp2_s8(v34, *v19.i8)));
          v37 = vmulq_s32(v35, v19);
          v38 = vmulq_s32(v35, v22);
          v39 = vmulq_s32(v36, v23);
          v40 = vmlaq_s32(v37, v36, v20);
          v41 = vzip1q_s32(v38, v38);
          v42 = vzip2q_s32(v38, v38);
          v43 = vzip1q_s32(v39, v39);
          v44 = vzip1q_s32(v40, v40);
          v45 = vmovl_u8(*&v7[v31]);
          v46 = vmovl_u8(*&v18[v31]);
          v47 = vshll_n_u16(*v45.i8, 0xFuLL);
          v48 = vzip2q_s32(v39, v39);
          v49 = vshll_high_n_u16(v45, 0xFuLL);
          v50 = vshll_n_u16(*v46.i8, 0xFuLL);
          v51 = vshll_high_n_u16(v46, 0xFuLL);
          v52 = vzip2q_s32(v40, v40);
          v53 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v47), 0xFuLL), vaddq_s32(v48, v49), 0xFuLL));
          v54 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v47), 0xFuLL), vaddq_s32(v52, v49), 0xFuLL));
          v146.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v43, v50), 0xFuLL), vaddq_s32(v48, v51), 0xFuLL));
          v55 = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v47), 0xFuLL), vaddq_s32(v42, v49), 0xFuLL));
          v146.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v50), 0xFuLL), vaddq_s32(v52, v51), 0xFuLL));
          vst4_s8(v27, *&v24);
          v27 += 32;
          v146.val[3] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v41, v50), 0xFuLL), vaddq_s32(v42, v51), 0xFuLL));
          v146.val[0] = -1;
          vst4_s8(v33, v146);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v7[v31];
        v25 = &v18[v31];
        v29 = &v8[v31];
        v28 = &v8[v31 + 1];
        v26 = &v27[v16];
      }

      else
      {
        v25 = &v7[v140];
        v26 = &v10[v16];
        v27 = v10;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v6 > v17)
      {
        v56 = v138;
        do
        {
          v58 = *v29;
          v29 += 2;
          v57 = v58;
          v59 = *v28;
          v28 += 2;
          v60 = v57 - 128;
          v61 = *v30;
          v62 = v30[1];
          v30 += 2;
          v63 = -5391 * (v57 - 128) - 18721 * (v59 - 128);
          v64 = 48320 * (v59 - 128);
          v65 = 61650 * v60;
          v66 = (v64 + (v61 << 15)) >> 15;
          if (v66 >= 255)
          {
            v66 = 255;
          }

          v67 = v66 & ~(v66 >> 31);
          v68 = (v63 + (v61 << 15)) >> 15;
          if (v68 >= 255)
          {
            v68 = 255;
          }

          v69 = v68 & ~(v68 >> 31);
          v70 = (v65 + (v61 << 15)) >> 15;
          if (v70 >= 255)
          {
            v70 = 255;
          }

          v71 = v70 & ~(v70 >> 31);
          v72 = (v64 + (v62 << 15)) >> 15;
          if (v72 >= 255)
          {
            v72 = 255;
          }

          v73 = (v63 + (v62 << 15)) >> 15;
          v74 = v72 & ~(v72 >> 31);
          if (v73 >= 255)
          {
            v73 = 255;
          }

          v75 = (v65 + (v62 << 15)) >> 15;
          v76 = v73 & ~(v73 >> 31);
          if (v75 >= 255)
          {
            v75 = 255;
          }

          *v27 = -1;
          v27[1] = v67;
          v27[2] = v69;
          v27[3] = v71;
          v27[4] = -1;
          v27[5] = v74;
          v27[6] = v76;
          v27[7] = v75 & ~(v75 >> 31);
          v77 = *v25;
          v27 += 8;
          v78 = v25[1];
          v25 += 2;
          v79 = (v64 + (v77 << 15)) >> 15;
          if (v79 >= 255)
          {
            v79 = 255;
          }

          v80 = v79 & ~(v79 >> 31);
          v81 = (v63 + (v77 << 15)) >> 15;
          if (v81 >= 255)
          {
            v81 = 255;
          }

          v82 = v81 & ~(v81 >> 31);
          v83 = (v65 + (v77 << 15)) >> 15;
          if (v83 >= 255)
          {
            v83 = 255;
          }

          v84 = v83 & ~(v83 >> 31);
          v85 = (v64 + (v78 << 15)) >> 15;
          if (v85 >= 255)
          {
            v85 = 255;
          }

          v86 = (v63 + (v78 << 15)) >> 15;
          v87 = v85 & ~(v85 >> 31);
          if (v86 >= 255)
          {
            v86 = 255;
          }

          v88 = (v65 + (v78 << 15)) >> 15;
          v89 = v86 & ~(v86 >> 31);
          *v26 = -1;
          v26[1] = v80;
          if (v88 >= 255)
          {
            v88 = 255;
          }

          v26[2] = v82;
          v26[4] = -1;
          v26[3] = v84;
          v26[5] = v87;
          v26[6] = v89;
          v26[7] = v88 & ~(v88 >> 31);
          v26 += 8;
          --v56;
        }

        while (v56);
        v11 = a1;
        v13 = v141;
        v17 = v139;
      }

      if (v11)
      {
        v90 = *v29 - 128;
        v91 = *v28 - 128;
        v92 = *v30;
        v93 = -5391 * v90 - 18721 * v91;
        v94 = 61650 * v90;
        v95 = 48320 * v91;
        v96 = (v95 + (v92 << 15)) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        v97 = v96 & ~(v96 >> 31);
        v98 = (v93 + (v92 << 15)) >> 15;
        if (v98 >= 255)
        {
          v98 = 255;
        }

        v99 = v98 & ~(v98 >> 31);
        v100 = (v94 + (v92 << 15)) >> 15;
        if (v100 >= 255)
        {
          v100 = 255;
        }

        *v27 = -1;
        v27[1] = v97;
        v27[2] = v99;
        v27[3] = v100 & ~(v100 >> 31);
        v101 = *v25;
        v102 = (v95 + (v101 << 15)) >> 15;
        if (v102 >= 255)
        {
          v102 = 255;
        }

        v103 = v102 & ~(v102 >> 31);
        v104 = (v93 + (v101 << 15)) >> 15;
        if (v104 >= 255)
        {
          v104 = 255;
        }

        v105 = v104 & ~(v104 >> 31);
        v106 = (v94 + (v101 << 15)) >> 15;
        if (v106 >= 255)
        {
          v106 = 255;
        }

        *v26 = -1;
        v26[1] = v103;
        v26[2] = v105;
        v26[3] = v106 & ~(v106 >> 31);
      }

      v7 += v144;
      v8 += v145;
      v9 += v145;
      v10 += 2 * v16;
      ++v12;
      v18 += v144;
    }

    while (v12 != v13);
  }

  else
  {
    v11 = a1;
  }

  if (v137)
  {
    if (v11 >= 2)
    {
      do
      {
        v107 = *v8;
        v8 += 2;
        v108 = v107 - 128;
        v109 = *v9;
        v9 += 2;
        v110 = *v7;
        v111 = v7[1];
        v7 += 2;
        v112 = -5391 * v108 - 18721 * (v109 - 128);
        v113 = 48320 * (v109 - 128);
        v114 = (v113 + (v110 << 15)) >> 15;
        if (v114 >= 255)
        {
          v114 = 255;
        }

        v115 = v114 & ~(v114 >> 31);
        v116 = (v112 + (v110 << 15)) >> 15;
        v117 = 61650 * v108;
        if (v116 >= 255)
        {
          v116 = 255;
        }

        v118 = v116 & ~(v116 >> 31);
        v119 = (v117 + (v110 << 15)) >> 15;
        if (v119 >= 255)
        {
          v119 = 255;
        }

        v120 = v119 & ~(v119 >> 31);
        v121 = (v113 + (v111 << 15)) >> 15;
        if (v121 >= 255)
        {
          v121 = 255;
        }

        v122 = v121 & ~(v121 >> 31);
        v123 = (v112 + (v111 << 15)) >> 15;
        if (v123 >= 255)
        {
          v123 = 255;
        }

        v124 = v123 & ~(v123 >> 31);
        v125 = (v117 + (v111 << 15)) >> 15;
        *v10 = -1;
        v10[1] = v115;
        if (v125 >= 255)
        {
          v125 = 255;
        }

        v10[2] = v118;
        v10[3] = v120;
        v10[4] = -1;
        v10[5] = v122;
        v10[6] = v124;
        v10[7] = v125 & ~(v125 >> 31);
        v10 += 8;
        --v6;
      }

      while (v6);
      LOBYTE(v11) = a1;
    }

    if (v11)
    {
      v126 = *v8 - 128;
      v127 = *v9 - 128;
      v128 = *v7;
      v129 = -5391 * v126 - 18721 * v127;
      v130 = 61650 * v126;
      v131 = (48320 * v127 + (v128 << 15)) >> 15;
      if (v131 >= 255)
      {
        v131 = 255;
      }

      v132 = v131 & ~(v131 >> 31);
      v133 = (v129 + (v128 << 15)) >> 15;
      if (v133 >= 255)
      {
        v133 = 255;
      }

      v134 = v133 & ~(v133 >> 31);
      v135 = (v130 + (v128 << 15)) >> 15;
      if (v135 >= 255)
      {
        v135 = 255;
      }

      *v10 = -1;
      v10[1] = v132;
      v10[2] = v134;
      v10[3] = v135 & ~(v135 >> 31);
    }
  }

  return 0;
}

uint64_t vt_Copy_420fITU2020F_24RGB_vec(unint64_t a1, unint64_t a2, uint64_t *a3, unsigned __int8 **a4, uint64_t *a5, char **a6)
{
  v6 = a1 >> 1;
  v7 = *a4;
  v8 = a4[1];
  v9 = v8 + 1;
  v10 = *a6;
  v130 = a1;
  v125 = a2;
  if (a2 >= 2)
  {
    v11 = 0;
    v12 = a2 >> 1;
    v13 = *a3;
    v14 = a3[1];
    v15 = *a5;
    v16 = 4 * (a1 >> 3);
    v17 = 2 * v13;
    v128 = v13;
    v129 = a1 >> 3;
    v18 = &v7[v13];
    v126 = v6 - v16;
    v19.i64[0] = 0xFF000000FFLL;
    v19.i64[1] = 0xFF000000FFLL;
    v20.i64[0] = 0x7F0000007FLL;
    v20.i64[1] = 0x7F0000007FLL;
    v21 = vdupq_n_s32(0xFFFFEAF1);
    v22 = vdupq_n_s32(0xFFFFB6DF);
    v23 = vdupq_n_s32(0xF0D2u);
    v24 = vdupq_n_s32(0xBCC0u);
    v127 = 2 * v13;
    do
    {
      if (a1 >= 8)
      {
        v31 = 0;
        v32 = v129;
        v27 = v10;
        do
        {
          v33 = *&v8[v31];
          v34 = &v27[v15];
          v35 = vaddw_u16(v20, *&vmovl_u8(vuzp1_s8(v33, 0x80000000BCC0)));
          v36 = vaddw_u16(v20, *&vmovl_u8(vuzp2_s8(v33, 0x80000000BCC0)));
          v37 = vmlaq_s32(vmulq_s32(v35, v21), v36, v22);
          v38 = vmulq_s32(v35, v23);
          v39 = vmulq_s32(v36, v24);
          v40 = vzip1q_s32(v38, v38);
          v41 = vzip2q_s32(v38, v38);
          v42 = vzip1q_s32(v39, v39);
          v43 = vzip2q_s32(v39, v39);
          v44 = vzip1q_s32(v37, v37);
          v45 = vmovl_u8(*&v7[v31]);
          v46 = vmovl_u8(*&v18[v31]);
          v47 = vshll_n_u16(*v45.i8, 0xFuLL);
          v48 = vshll_high_n_u16(v45, 0xFuLL);
          v49 = vshll_n_u16(*v46.i8, 0xFuLL);
          v50 = vzip2q_s32(v37, v37);
          v51 = vshll_high_n_u16(v46, 0xFuLL);
          v132.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v47), 0xFuLL), vaddq_s32(v43, v48), 0xFuLL));
          v132.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v47), 0xFuLL), vaddq_s32(v50, v48), 0xFuLL));
          v131.val[0] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v42, v49), 0xFuLL), vaddq_s32(v43, v51), 0xFuLL));
          v132.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v47), 0xFuLL), vaddq_s32(v41, v48), 0xFuLL));
          v131.val[1] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v44, v49), 0xFuLL), vaddq_s32(v50, v51), 0xFuLL));
          vst3_s8(v27, v132);
          v27 += 24;
          v131.val[2] = vqmovun_s16(vshrn_high_n_s32(vshrn_n_s32(vaddq_s32(v40, v49), 0xFuLL), vaddq_s32(v41, v51), 0xFuLL));
          vst3_s8(v34, v131);
          v31 += 8;
          --v32;
        }

        while (v32);
        v30 = &v7[v31];
        v25 = &v18[v31];
        v29 = &v8[v31];
        v28 = &v8[v31 + 1];
        v26 = &v27[v15];
      }

      else
      {
        v25 = &v7[v128];
        v26 = &v10[v15];
        v27 = v10;
        v28 = v9;
        v29 = v8;
        v30 = v7;
      }

      if (v6 > v16)
      {
        v52 = v14;
        v53 = v16;
        v54 = v12;
        v55 = v126;
        do
        {
          v56 = *v29;
          v29 += 2;
          v57 = v56 - 128;
          v58 = *v28;
          v28 += 2;
          v59 = *v30;
          v60 = v30[1];
          v30 += 2;
          v61 = -5391 * v57 - 18721 * (v58 - 128);
          v62.i32[0] = v58 - 128;
          v62.i32[1] = v59;
          v63 = 61650 * v57;
          v64 = vmul_s32(v62, 0x80000000BCC0);
          v65 = v60 << 15;
          v66 = (v61 + (v60 << 15)) >> 15;
          if (v66 >= 255)
          {
            v66 = 255;
          }

          v67 = v66 & ~(v66 >> 31);
          v68 = (v63 + (v60 << 15)) >> 15;
          if (v68 >= 255)
          {
            v68 = 255;
          }

          *v69.i8 = v64;
          v69.i64[1] = __PAIR64__(v64.u32[0], v63);
          v70 = vdupq_lane_s32(v64, 1);
          v70.i32[1] = v61;
          v70.i32[3] = v65;
          *v27 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v69, v70), 0xFuLL), v19), 0)), 0x80000000BCC0).u32[0];
          v27[4] = v67;
          v27[5] = v68 & ~(v68 >> 31);
          v27 += 6;
          v71 = *v25;
          v72 = v25[1];
          v25 += 2;
          v73 = v71 << 15;
          v74 = v72 << 15;
          v75 = (v61 + (v72 << 15)) >> 15;
          if (v75 >= 255)
          {
            v75 = 255;
          }

          v76 = (v63 + (v72 << 15)) >> 15;
          v77.i64[0] = __PAIR64__(v73, v64.u32[0]);
          v78 = vdupq_lane_s32(__PAIR64__(v73, v64.u32[0]), 1);
          v77.i64[1] = __PAIR64__(v64.u32[0], v63);
          v78.i32[1] = v61;
          v78.i32[3] = v74;
          if (v76 >= 255)
          {
            v79 = 255;
          }

          else
          {
            v79 = v76;
          }

          *v26 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v77, v78), 0xFuLL), v19), 0)), 0x80000000BCC0).u32[0];
          v26[4] = v75 & ~(v75 >> 31);
          v26[5] = v79 & ~(v79 >> 31);
          v26 += 6;
          --v55;
        }

        while (v55);
        v12 = v54;
        v16 = v53;
        a1 = v130;
        v14 = v52;
        v17 = v127;
      }

      if (a1)
      {
        v80 = *v29 - 128;
        v81 = *v28 - 128;
        v82 = *v30;
        v83 = -5391 * v80 - 18721 * v81;
        v84 = 61650 * v80;
        v85 = 48320 * v81;
        v86 = (v85 + (v82 << 15)) >> 15;
        if (v86 >= 255)
        {
          v86 = 255;
        }

        v87 = v86 & ~(v86 >> 31);
        v88 = (v83 + (v82 << 15)) >> 15;
        if (v88 >= 255)
        {
          v88 = 255;
        }

        v89 = v88 & ~(v88 >> 31);
        v90 = (v84 + (v82 << 15)) >> 15;
        if (v90 >= 255)
        {
          v90 = 255;
        }

        *v27 = v87;
        v27[1] = v89;
        v27[2] = v90 & ~(v90 >> 31);
        v91 = *v25;
        v92 = (v85 + (v91 << 15)) >> 15;
        if (v92 >= 255)
        {
          v92 = 255;
        }

        v93 = v92 & ~(v92 >> 31);
        v94 = (v83 + (v91 << 15)) >> 15;
        if (v94 >= 255)
        {
          v94 = 255;
        }

        v95 = v94 & ~(v94 >> 31);
        v96 = (v84 + (v91 << 15)) >> 15;
        if (v96 >= 255)
        {
          v96 = 255;
        }

        *v26 = v93;
        v26[1] = v95;
        v26[2] = v96 & ~(v96 >> 31);
      }

      v7 += v17;
      v8 += v14;
      v9 += v14;
      v10 += 2 * v15;
      ++v11;
      v18 += v17;
    }

    while (v11 != v12);
  }

  if (v125)
  {
    if (a1 >= 2)
    {
      v97.i64[0] = 0xFF000000FFLL;
      v97.i64[1] = 0xFF000000FFLL;
      do
      {
        v98 = *v8;
        v8 += 2;
        v99 = v98 - 128;
        v100 = *v9;
        v9 += 2;
        v101 = *v7;
        v102 = v7[1];
        v7 += 2;
        v103 = v101 << 15;
        v104 = -5391 * v99 - 18721 * (v100 - 128);
        v105 = 48320 * (v100 - 128);
        v106 = 61650 * v99;
        v107 = v102 << 15;
        v108 = (v104 + (v102 << 15)) >> 15;
        v109 = v106 + (v102 << 15);
        if (v108 >= 255)
        {
          v108 = 255;
        }

        v110.i64[0] = __PAIR64__(v103, v105);
        v110.i64[1] = __PAIR64__(v105, v106);
        v111 = v109 >> 15;
        v112.i64[0] = __PAIR64__(v104, v103);
        v112.i64[1] = __PAIR64__(v107, v103);
        if (v111 >= 255)
        {
          v113 = 255;
        }

        else
        {
          v113 = v111;
        }

        *v10 = vuzp1_s8(vmovn_s32(vmaxq_s32(vminq_s32(vshrq_n_s32(vaddq_s32(v110, v112), 0xFuLL), v97), 0)), *v97.i8).u32[0];
        v10[4] = v108 & ~(v108 >> 31);
        v10[5] = v113 & ~(v113 >> 31);
        v10 += 6;
        --v6;
      }

      while (v6);
      LOBYTE(a1) = v130;
    }

    if (a1)
    {
      v114 = *v8 - 128;
      v115 = *v9 - 128;
      v116 = *v7;
      v117 = -5391 * v114 - 18721 * v115;
      v118 = 61650 * v114;
      v119 = (48320 * v115 + (v116 << 15)) >> 15;
      if (v119 >= 255)
      {
        v119 = 255;
      }

      v120 = v119 & ~(v119 >> 31);
      v121 = (v117 + (v116 << 15)) >> 15;
      if (v121 >= 255)
      {
        v121 = 255;
      }

      v122 = v121 & ~(v121 >> 31);
      v123 = (v118 + (v116 << 15)) >> 15;
      if (v123 >= 255)
      {
        v123 = 255;
      }

      *v10 = v120;
      v10[1] = v122;
      v10[2] = v123 & ~(v123 >> 31);
    }
  }

  return 0;
}

BOOL VTRequiresMatrixChange(uint64_t a1, int a2, uint64_t a3, int a4)
{
  result = 0;
  if (a2)
  {
    if (a4)
    {
      return FigCFEqual() == 0;
    }
  }

  return result;
}

uint64_t VTCreateYCbCrCFStringsAndProvideDefaultsFromColorSpaceHint(unint64_t cf, int a2, unint64_t a3, int a4, CGColorSpace *a5, CGColorSpace *a6, void *a7, void *a8)
{
  if (cf)
  {
    v15 = CFRetain(cf);
  }

  else
  {
    v15 = 0;
  }

  v21 = v15;
  if (a3)
  {
    v16 = CFRetain(a3);
  }

  else
  {
    v16 = 0;
  }

  cfa = v16;
  if (!a7 || !a8)
  {
    fig_log_get_emitter();
    v17 = FigSignalErrorAtGM();
    if (!v15)
    {
      goto LABEL_15;
    }

    goto LABEL_14;
  }

  if (!(cf | a3))
  {
    if (!a2 || a4)
    {
      if (!a2 && a4)
      {
        _createBestGuessYCbCrCFStringFromColorSpace(a6, &cfa);
        v16 = cfa;
      }
    }

    else
    {
      _createBestGuessYCbCrCFStringFromColorSpace(a5, &v21);
      v15 = v21;
    }
  }

  v17 = VTCreateYCbCrCFStringsAndProvideDefaults(v15, a2, v16, a4, a7, a8);
  v15 = v21;
  if (v21)
  {
LABEL_14:
    CFRelease(v15);
  }

LABEL_15:
  if (cfa)
  {
    CFRelease(cfa);
  }

  return v17;
}

void _createBestGuessYCbCrCFStringFromColorSpace(CGColorSpace *a1, const void **a2)
{
  cf = 0;
  if (a2)
  {
    if (a1)
    {
      Name = CGColorSpaceGetName(a1);
      VTGetDefaultColorAttributesWithHints(0, Name, 0, 0, 0, 0, &cf);
      v4 = *a2;
      v5 = cf;
      *a2 = cf;
      if (v5)
      {
        CFRetain(v5);
      }

      if (v4)
      {
        CFRelease(v4);
      }
    }

    else
    {
      *a2 = 0;
    }
  }

  else
  {
    fig_log_get_emitter();
    FigSignalErrorAtGM();
  }

  if (cf)
  {
    CFRelease(cf);
  }
}

uint64_t VTCreateYCbCrCFStringsAndProvideDefaults(CFTypeRef cf, int a2, const void *a3, int a4, void *a5, void *a6)
{
  if (cf)
  {
    v12 = CFRetain(cf);
    if (a3)
    {
      goto LABEL_3;
    }

LABEL_6:
    v13 = 0;
    if (!a5)
    {
      goto LABEL_13;
    }

    goto LABEL_7;
  }

  v12 = 0;
  if (!a3)
  {
    goto LABEL_6;
  }

LABEL_3:
  v13 = CFRetain(a3);
  if (!a5)
  {
    goto LABEL_13;
  }

LABEL_7:
  if (a6)
  {
    if (a2)
    {
      if (!cf)
      {
        if (a3)
        {
          v12 = CFRetain(a3);
          if (!a4)
          {
LABEL_26:
            if (v13)
            {
              CFRelease(v13);
              v13 = 0;
            }

            goto LABEL_28;
          }
        }

        else if (!a4)
        {
          v12 = VTGetDefaultYCbCrMatrixWithNoHints();
          goto LABEL_26;
        }

        goto LABEL_28;
      }
    }

    else if (v12)
    {
      CFRelease(v12);
      v12 = 0;
    }

    if (!a4)
    {
      goto LABEL_26;
    }

    if (!a3)
    {
      if (cf)
      {
        v15 = CFRetain(cf);
      }

      else
      {
        if (a2)
        {
          goto LABEL_28;
        }

        v15 = VTGetDefaultYCbCrMatrixWithNoHints();
      }

      v13 = v15;
    }

LABEL_28:
    v14 = 0;
    *a5 = v12;
    *a6 = v13;
    return v14;
  }

LABEL_13:
  fig_log_get_emitter();
  v14 = FigSignalErrorAtGM();
  if (v12)
  {
    CFRelease(v12);
  }

  if (v13)
  {
    CFRelease(v13);
  }

  return v14;
}

uint64_t VTConvertToSessionPropertiesFromCVProperties(const __CFDictionary *a1, __CFDictionary *a2)
{
  Value = CFDictionaryGetValue(a1, *MEMORY[0x1E6965D88]);
  v5 = CFDictionaryGetValue(a1, *MEMORY[0x1E6965F30]);
  v6 = CFDictionaryGetValue(a1, *MEMORY[0x1E6965EC8]);
  v7 = CFDictionaryGetValue(a1, *MEMORY[0x1E6965F98]);
  if (Value)
  {
    CFDictionarySetValue(a2, @"DestinationColorPrimaries", Value);
  }

  else
  {
    CFDictionaryRemoveValue(a2, @"DestinationColorPrimaries");
  }

  if (v5)
  {
    CFDictionarySetValue(a2, @"DestinationTransferFunction", v5);
  }

  else
  {
    CFDictionaryRemoveValue(a2, @"DestinationTransferFunction");
  }

  if (v6)
  {
    CFDictionarySetValue(a2, @"DestinationICCProfile", v6);
  }

  else
  {
    CFDictionaryRemoveValue(a2, @"DestinationICCProfile");
  }

  if (v7)
  {
    CFDictionarySetValue(a2, @"DestinationYCbCrMatrix", v7);
  }

  else
  {
    CFDictionaryRemoveValue(a2, @"DestinationYCbCrMatrix");
  }

  return 0;
}

uint64_t VTGetBitsPerComponentFromPixelFormatType(int a1)
{
  if (CVPixelFormatDescriptionGetDescriptionWithPixelFormatType())
  {
    if (a1 == 1380410945)
    {
      return 32;
    }

    else
    {
      FigCFDictionaryGetInt32IfPresent();
      return 0;
    }
  }

  else
  {
    VTGetBitsPerComponentFromPixelFormatType_cold_1();
    return 0;
  }
}

uint64_t VTCreateColorAttachments(unint64_t a1, unint64_t a2, const void *a3, const void *a4, const void *a5, const void *a6, int a7, unint64_t a8, unint64_t a9, const void *a10, const void *a11, uint64_t a12, const void *a13, int a14, char a15, __CFDictionary **a16, __CFDictionary **a17)
{
  if (a3)
  {
    v17 = a4 == 0;
  }

  else
  {
    v17 = 1;
  }

  v18 = !v17;
  if (a1 | a2)
  {
    v19 = 1;
  }

  else
  {
    v19 = v18;
  }

  if (a10)
  {
    v20 = a11 == 0;
  }

  else
  {
    v20 = 1;
  }

  v21 = !v20;
  if (a8 | a9)
  {
    v22 = 1;
  }

  else
  {
    v22 = v21;
  }

  v69 = v22;
  if (a16)
  {
    v23 = a17 == 0;
  }

  else
  {
    v23 = 1;
  }

  if (v23)
  {
    VTCreateColorAttachments_cold_4(v72);
    return v72[0];
  }

  v26 = a4;
  v63 = (a1 | a2) != 0;
  v28 = MEMORY[0x1E695E9D8];
  v29 = MEMORY[0x1E695E9E8];
  Mutable = CFDictionaryCreateMutable(0, 0, MEMORY[0x1E695E9D8], MEMORY[0x1E695E9E8]);
  v31 = CFDictionaryCreateMutable(0, 0, v28, v29);
  v32 = MEMORY[0x1E6965F98];
  if (a6)
  {
    CFDictionarySetValue(Mutable, *MEMORY[0x1E6965F98], a6);
  }

  if (a13)
  {
    CFDictionarySetValue(v31, *v32, a13);
  }

  if (!v26)
  {
    if (a11)
    {
      goto LABEL_37;
    }

    goto LABEL_31;
  }

  if (a5)
  {
    fig_log_get_emitter();
    FigSignalErrorAtGM();
    v26 = 0;
  }

  if (!a11)
  {
LABEL_31:
    if (!v26 && a3 && a5 && (!a10 || FigCFEqual()))
    {
      v33 = *MEMORY[0x1E6965D88];
      CFDictionarySetValue(Mutable, *MEMORY[0x1E6965D88], a3);
      v34 = *MEMORY[0x1E6965ED0];
      CFDictionarySetValue(Mutable, *MEMORY[0x1E6965ED0], a5);
      CFDictionarySetValue(v31, v33, a3);
      CFDictionarySetValue(v31, v34, a5);
    }
  }

LABEL_37:
  if ((v19 | v69) == 1)
  {
    if (!v19)
    {
      v41 = a14;
      v37 = 0;
      goto LABEL_45;
    }

    if (FigCFEqual())
    {
      v35 = 1;
      v36 = a1;
    }

    else
    {
      v42 = FigCFEqual();
      v35 = v42 != 0;
      v36 = a1;
      if (!v42 && a1)
      {
        v43 = CFGetTypeID(a1);
        v35 = v43 == CGColorSpaceGetTypeID() && CGColorSpaceUsesITUR_2100TF(a1);
        v36 = a1;
      }
    }

    cfa = v35;
    if (FigCFEqual())
    {
      v44 = 1;
    }

    else
    {
      v46 = FigCFEqual();
      v44 = v46 != 0;
      if (!v46 && a8)
      {
        v47 = CFGetTypeID(a8);
        v44 = v47 == CGColorSpaceGetTypeID() && CGColorSpaceUsesITUR_2100TF(a8);
      }
    }

    if (v36)
    {
      if (FigCFEqual() && FigCFEqual() != 0 && v44)
      {
        v37 = CGColorSpaceCreateWithName(*MEMORY[0x1E695F180]);
      }

      else
      {
        v37 = 0;
      }

      if (v37)
      {
        v45 = v37;
      }

      else
      {
        v45 = v36;
      }

      CFDictionarySetValue(Mutable, *MEMORY[0x1E6965CE8], v45);
      goto LABEL_73;
    }

    v48 = a2;
    if (a2)
    {
      v49 = *MEMORY[0x1E6965EC8];
      v50 = Mutable;
    }

    else
    {
      v37 = 0;
      if (!a3 || !v26)
      {
        goto LABEL_73;
      }

      CFDictionarySetValue(Mutable, *MEMORY[0x1E6965D88], a3);
      v49 = *MEMORY[0x1E6965F30];
      v50 = Mutable;
      v48 = v26;
    }

    CFDictionarySetValue(v50, v49, v48);
    v37 = 0;
LABEL_73:
    if (v69)
    {
      if (a8)
      {
        v40 = a16;
        v39 = a17;
        v41 = a14;
        if (FigCFEqual() && FigCFEqual() != 0 && cfa)
        {
          v38 = CGColorSpaceCreateWithName(*MEMORY[0x1E695F180]);
        }

        else
        {
          v38 = 0;
        }

        if (v38)
        {
          v59 = v38;
        }

        else
        {
          v59 = a8;
        }

        CFDictionarySetValue(v31, *MEMORY[0x1E6965CE8], v59);
LABEL_109:
        v60 = a7 == 1651521076 || a7 == 1647392369;
        if (v60 && v41 == 1380411457)
        {
          CFDictionarySetValue(v31, *MEMORY[0x1E6965F20], *MEMORY[0x1E695E4D0]);
        }

        goto LABEL_116;
      }

      v41 = a14;
      v40 = a16;
      v39 = a17;
      v58 = a9;
      if (a9)
      {
        v56 = *MEMORY[0x1E6965EC8];
        v57 = v31;
      }

      else
      {
        v38 = 0;
        if (!a10 || !a11)
        {
          goto LABEL_109;
        }

        CFDictionarySetValue(v31, *MEMORY[0x1E6965D88], a10);
        v56 = *MEMORY[0x1E6965F30];
        v57 = v31;
        v58 = a11;
      }

LABEL_108:
      CFDictionarySetValue(v57, v56, v58);
      v38 = 0;
      goto LABEL_109;
    }

    if (!a15)
    {
      goto LABEL_87;
    }

    if (!a7)
    {
      VTCreateColorAttachments_cold_3(&v71);
      v38 = 0;
      v61 = v71;
      goto LABEL_117;
    }

    if (!a14)
    {
      VTCreateColorAttachments_cold_2(&v70);
      v38 = 0;
      v61 = v70;
      goto LABEL_117;
    }

    v51 = VTGetBitsPerComponentFromPixelFormatType(a7);
    v52 = VTGetBitsPerComponentFromPixelFormatType(a14);
    v53 = cfa;
    if (v51 <= 9)
    {
      v53 = 0;
    }

    if (!v53 || v52 > 9)
    {
LABEL_87:
      v41 = a14;
      if (v63)
      {
        if (v36)
        {
          v54 = v36;
        }

        else
        {
          v54 = a2;
        }

        v55 = MEMORY[0x1E6965CE8];
        if (!v36)
        {
          v55 = MEMORY[0x1E6965EC8];
        }

        CFDictionarySetValue(v31, *v55, v54);
      }

      v38 = 0;
      v40 = a16;
      v39 = a17;
      if (!a3 || !v26)
      {
        goto LABEL_109;
      }

      CFDictionarySetValue(v31, *MEMORY[0x1E6965D88], a3);
      v56 = *MEMORY[0x1E6965F30];
      v57 = v31;
      v58 = v26;
      goto LABEL_108;
    }

    CFDictionarySetValue(v31, *MEMORY[0x1E6965D88], *MEMORY[0x1E6965DB8]);
    CFDictionarySetValue(v31, *MEMORY[0x1E6965F30], *MEMORY[0x1E6965F50]);
    v41 = a14;
    if (CVPixelFormatDescriptionGetDescriptionWithPixelFormatType())
    {
      FigCFDictionaryGetBooleanIfPresent();
    }

    else
    {
      VTCreateColorAttachments_cold_1();
    }

LABEL_45:
    v38 = 0;
    v40 = a16;
    v39 = a17;
    goto LABEL_109;
  }

  v37 = 0;
  v38 = 0;
  v40 = a16;
  v39 = a17;
LABEL_116:
  v61 = 0;
  *v40 = Mutable;
  *v39 = v31;
  v31 = 0;
  Mutable = 0;
LABEL_117:
  if (v37)
  {
    CFRelease(v37);
  }

  if (v38)
  {
    CFRelease(v38);
  }

  if (Mutable)
  {
    CFRelease(Mutable);
  }

  if (v31)
  {
    CFRelease(v31);
  }

  return v61;
}

uint64_t VTDoColorDictionariesMatch(const __CFDictionary *a1, const __CFDictionary *a2)
{
  v4 = 0;
  cf = 0;
  v2 = 1;
  if (a1 && a2)
  {
    VTCreateColorSpacesFromDictionaries(a1, a2, &cf, &v4);
    v2 = FigCFEqual();
    if (cf)
    {
      CFRelease(cf);
    }

    if (v4)
    {
      CFRelease(v4);
    }
  }

  return v2;
}

uint64_t VTCreateVImageConverter(int a1, CGColorSpace *a2, int a3, CGColorSpace *a4, vImageConverterRef *a5)
{
  if (!a5)
  {
    VTCreateVImageConverter_cold_1(&v21);
    return v21;
  }

  v8 = 0;
  *&sFormat.renderingIntent = 0;
  *&dFormat.renderingIntent = 0;
  error = 0;
  v9 = 0;
  if (a1 <= 1380410944)
  {
    if (a1 == 32)
    {
      v9 = 0x2000000008;
      v8 = 4;
    }

    else if (a1 == 1111970369)
    {
      v9 = 0x2000000008;
      v8 = 8196;
    }
  }

  else
  {
    switch(a1)
    {
      case 1380410945:
        v9 = 0x8000000020;
        v8 = 8451;
        break;
      case 1380411457:
        v9 = 0x4000000010;
        v8 = 4355;
        break;
      case 1815491698:
        v9 = 0x4000000010;
        v8 = 4099;
        break;
    }
  }

  v10 = 0;
  sFormat.bitmapInfo = v8;
  *&sFormat.bitsPerComponent = v9;
  sFormat.colorSpace = a2;
  v11 = 0;
  *&sFormat.version = 0uLL;
  if (a3 <= 1380410944)
  {
    if (a3 == 32)
    {
      v11 = 0x2000000008;
      v10 = 4;
    }

    else if (a3 == 1111970369)
    {
      v11 = 0x2000000008;
      v10 = 8196;
    }
  }

  else
  {
    switch(a3)
    {
      case 1380410945:
        v11 = 0x8000000020;
        v10 = 8451;
        break;
      case 1380411457:
        v11 = 0x4000000010;
        v10 = 4355;
        break;
      case 1815491698:
        v11 = 0x4000000010;
        v10 = 4099;
        break;
    }
  }

  dFormat.bitmapInfo = v10;
  *&dFormat.bitsPerComponent = v11;
  dFormat.colorSpace = a4;
  *&dFormat.version = 0uLL;
  Mutable = CFDictionaryCreateMutable(0, 0, MEMORY[0x1E695E9D8], MEMORY[0x1E695E9E8]);
  CFDictionarySetValue(Mutable, *MEMORY[0x1E695F478], *MEMORY[0x1E695E4D0]);
  v13 = CGColorConversionInfoCreateFromList(Mutable, a2, kCGColorConversionTransformFromSpace, kCGRenderingIntentDefault, a4, 1, 0, 0, error, *&dFormat.bitsPerComponent, dFormat.colorSpace, *&dFormat.bitmapInfo, 0, *&dFormat.renderingIntent, *&sFormat.bitsPerComponent, sFormat.colorSpace, *&sFormat.bitmapInfo, sFormat.decode, *&sFormat.renderingIntent);
  v14 = v13;
  if (v13)
  {
    v15 = vImageConverter_CreateWithCGColorConversionInfo(v13, &sFormat, &dFormat, 0, 0, &error);
    if (v15)
    {
      goto LABEL_26;
    }
  }

  else
  {
    v15 = vImageConverter_CreateWithCGImageFormat(&sFormat, &dFormat, 0, 0, &error);
    if (v15)
    {
LABEL_26:
      v16 = 0;
      *a5 = v15;
      if (!Mutable)
      {
        goto LABEL_28;
      }

      goto LABEL_27;
    }
  }

  v16 = 4294955084;
  if (Mutable)
  {
LABEL_27:
    CFRelease(Mutable);
  }

LABEL_28:
  if (v14)
  {
    CFRelease(v14);
  }

  return v16;
}

uint64_t VTIsPixelBufferCompatibleWithColorProperties(void *a1, const void *a2, const void *a3, const void *a4, const void *a5, CGColorSpaceRef *a6)
{
  if (checkTransferServiceTrace_onceToken == -1)
  {
    if (a2)
    {
      goto LABEL_6;
    }
  }

  else
  {
    VTIsPixelBufferCompatibleWithColorProperties_cold_1();
    if (a2)
    {
      goto LABEL_6;
    }
  }

  if (!a3 && !a4 && !a5)
  {
    return 1;
  }

LABEL_6:
  if (!VTIsBufferTaggedWithColorProperties(a1))
  {
    return 1;
  }

  Value = 1;
  v13 = CVBufferCopyAttachments(a1, kCVAttachmentMode_ShouldPropagate);
  v14 = v13;
  if (a2)
  {
    if (v13)
    {
      CFDictionaryGetValue(v13, *MEMORY[0x1E6965D88]);
    }

    Value = FigCFEqual() != 0;
  }

  if (a3 && Value)
  {
    if (v14)
    {
      CFDictionaryGetValue(v14, *MEMORY[0x1E6965F30]);
    }

    if (FigCFEqual())
    {
      Value = Value;
    }

    else
    {
      Value = 0;
    }
  }

  if (a4 && Value)
  {
    if (v14)
    {
      CFDictionaryGetValue(v14, *MEMORY[0x1E6965F98]);
    }

    if (FigCFEqual())
    {
      Value = Value;
    }

    else
    {
      Value = 0;
    }
  }

  if (a5 && Value)
  {
    if (v14)
    {
      CFDictionaryGetValue(v14, *MEMORY[0x1E6965EC8]);
    }

    if (FigCFEqual())
    {
      Value = Value;
    }

    else
    {
      Value = 0;
    }
  }

  if (!a6 || (Value & 1) != 0)
  {
    if (!v14)
    {
      return Value;
    }

    goto LABEL_54;
  }

  if (v14)
  {
    Value = CFDictionaryGetValue(v14, *MEMORY[0x1E6965CE8]);
    if (!Value)
    {
LABEL_54:
      CFRelease(v14);
      return Value;
    }

    if (*a6)
    {
LABEL_53:
      Value = FigCFEqual();
      goto LABEL_54;
    }

    Mutable = CFDictionaryCreateMutable(0, 0, MEMORY[0x1E695E9D8], MEMORY[0x1E695E9E8]);
    v16 = Mutable;
    if (a5)
    {
      v17 = MEMORY[0x1E6965EC8];
    }

    else
    {
      if (a2)
      {
        CFDictionaryAddValue(Mutable, *MEMORY[0x1E6965D88], a2);
      }

      if (a3)
      {
        CFDictionaryAddValue(v16, *MEMORY[0x1E6965F30], a3);
      }

      if (!a4)
      {
        goto LABEL_50;
      }

      v17 = MEMORY[0x1E6965F98];
      a5 = a4;
    }

    CFDictionaryAddValue(v16, *v17, a5);
LABEL_50:
    ColorSpaceFromAttachments = CVImageBufferCreateColorSpaceFromAttachments(v16);
    if (v16)
    {
      CFRelease(v16);
    }

    *a6 = ColorSpaceFromAttachments;
    goto LABEL_53;
  }

  return 0;
}

uint64_t RegisterVTFrameSilo()
{
  result = _CFRuntimeRegisterClass();
  sVTFrameSiloID = result;
  return result;
}

OSStatus VTFrameSiloCreate(CFAllocatorRef allocator, CFURLRef fileURL, CMTimeRange *timeRange, CFDictionaryRef options, VTFrameSiloRef *frameSiloOut)
{
  if (!frameSiloOut)
  {
    return -12902;
  }

  MEMORY[0x193AE3010](&VTFrameSiloGetTypeID_sRegisterVTFrameSiloOnce, RegisterVTFrameSilo, timeRange, options);
  Instance = _CFRuntimeCreateInstance();
  if (!Instance)
  {
    return -12904;
  }

  v10 = Instance;
  memset(&callBacks, 0, sizeof(callBacks));
  v11 = MEMORY[0x1E6960C70];
  *(Instance + 32) = *MEMORY[0x1E6960C70];
  v12 = *(v11 + 16);
  *(Instance + 72) = 1;
  *(Instance + 48) = v12;
  *(Instance + 56) = 1;
  v13 = *&timeRange->start.epoch;
  *&range1.start.value = *&timeRange->start.value;
  *&range1.start.epoch = v13;
  *&range1.duration.timescale = *&timeRange->duration.timescale;
  v14 = *(MEMORY[0x1E6960C98] + 16);
  v24 = *MEMORY[0x1E6960C98];
  *&range2.start.value = *MEMORY[0x1E6960C98];
  v22 = *(MEMORY[0x1E6960C98] + 32);
  v23 = v14;
  *&range2.start.epoch = v14;
  *&range2.duration.timescale = v22;
  if (!CMTimeRangeEqual(&range1, &range2) && ((timeRange->start.flags & 1) == 0 || (timeRange->duration.flags & 1) == 0 || timeRange->duration.epoch || timeRange->duration.value < 0))
  {
    VTFrameSiloCreate_cold_1(&range1);
    value = range1.start.value;
LABEL_14:
    CFRelease(v10);
    return value;
  }

  v15 = malloc_type_malloc(0x30uLL, 0x1000040EED21634uLL);
  *(v10 + 64) = v15;
  v17 = *&timeRange->start.epoch;
  v16 = *&timeRange->duration.timescale;
  *v15 = *&timeRange->start.value;
  v15[1] = v17;
  v15[2] = v16;
  callBacks.version = 0;
  callBacks.retain = vtFrameSiloFormatDescriptionRetain;
  callBacks.release = vtFrameSiloFormatDescriptionRelease;
  callBacks.copyDescription = vtFrameSiloFormatDescriptionCopyDescription;
  callBacks.equal = vtFrameSiloFormatDescriptionEqual;
  *(v10 + 80) = CFArrayCreateMutable(allocator, 0, &callBacks);
  *&range1.start.value = v24;
  *&range1.start.epoch = v23;
  *&range1.duration.timescale = v22;
  v18 = VTMultiPassStorageCreate(allocator, fileURL, &range1, 0, (v10 + 24));
  if (v18)
  {
    value = v18;
    goto LABEL_14;
  }

  v19 = CFStringCreateWithFormat(*MEMORY[0x1E695E480], 0, @"VTFrameSilo-%d", 1);
  value = VTMultiPassStorageSetIdentifier(*(v10 + 24), v19);
  if (!value)
  {
    *frameSiloOut = v10;
    v10 = 0;
  }

  if (v19)
  {
    CFRelease(v19);
  }

  if (v10)
  {
    goto LABEL_14;
  }

  return value;
}

void vtFrameSiloFormatDescriptionRelease(int a1, void *a2)
{
  v3 = a2[6];
  if (v3)
  {
    CFRelease(v3);
  }

  free(a2);
}

__CFString *vtFrameSiloFormatDescriptionCopyDescription(uint64_t a1)
{
  Mutable = CFStringCreateMutable(0, 0);
  CFStringAppendFormat(Mutable, 0, @"<VTFrameSiloFormatDescription>{formatDescription:%p, timeRange:[%lld/%d,%lld/%d]}", *(a1 + 48), *a1, *(a1 + 8), *(a1 + 24), *(a1 + 32));
  return Mutable;
}

uint64_t VTFrameSiloInvalidate(uint64_t a1)
{
  if (a1 && !*(a1 + 16))
  {
    *(a1 + 16) = 1;
    v2 = *(a1 + 64);
    if (v2)
    {
      free(v2);
      *(a1 + 64) = 0;
    }

    v3 = *(a1 + 80);
    if (v3)
    {
      CFRelease(v3);
      *(a1 + 80) = 0;
    }

    VTMultiPassStorageClose(*(a1 + 24));
    v4 = *(a1 + 24);
    if (v4)
    {
      CFRelease(v4);
      *(a1 + 24) = 0;
    }
  }

  return 0;
}

OSStatus VTFrameSiloGetProgressOfCurrentPass(VTFrameSiloRef silo, Float32 *progressOut)
{
  v27 = *MEMORY[0x1E69E9840];
  *&v24.value = *MEMORY[0x1E6960CC0];
  v2 = *(MEMORY[0x1E6960CC0] + 16);
  v24.epoch = v2;
  v19 = *&v24.value;
  *&v23.value = *&v24.value;
  v23.epoch = v2;
  if (!silo)
  {
    VTFrameSiloGetProgressOfCurrentPass_cold_3(&lhs);
    return lhs.start.value;
  }

  if (!progressOut)
  {
    VTFrameSiloGetProgressOfCurrentPass_cold_2(&lhs);
    return lhs.start.value;
  }

  if (*(silo + 16))
  {
    fig_log_get_emitter();

    return FigSignalErrorAtGM();
  }

  if (*(silo + 7) >= 1)
  {
    v5 = 0;
    v6 = 0;
    v17 = 893;
    while (1)
    {
      v7 = *(silo + 8) + v5;
      v8 = *(v7 + 8);
      v25 = *v7;
      v26 = v8;
      v9 = *(v7 + 12);
      if ((v9 & 1) == 0)
      {
        break;
      }

      v10 = *(v7 + 36);
      if ((v10 & 1) == 0)
      {
        break;
      }

      if (*(v7 + 40))
      {
        break;
      }

      v11 = *(v7 + 24);
      if (v11 < 0)
      {
        break;
      }

      if ((*(v7 + 12) & 0x1D) != 1)
      {
        v16 = 894;
LABEL_27:
        v17 = v16;
        break;
      }

      if ((*(v7 + 36) & 0x1D) != 1)
      {
        v16 = 895;
        goto LABEL_27;
      }

      v12 = *(v7 + 16);
      v13 = *(v7 + 32);
      lhs.start = v23;
      rhs.value = v11;
      rhs.timescale = v13;
      rhs.flags = v10;
      rhs.epoch = 0;
      CMTimeAdd(&v23, &lhs.start, &rhs);
      if ((*(silo + 44) & 1) != 0 && (lhs.start.value = v25, lhs.start.timescale = v26, lhs.start.flags = v9, lhs.start.epoch = v12, lhs.duration.value = v11, lhs.duration.timescale = v13, lhs.duration.flags = v10, lhs.duration.epoch = 0, CMTimeRangeGetEnd(&rhs, &lhs), *&lhs.start.value = *(silo + 2), lhs.start.epoch = *(silo + 6), CMTimeCompare(&lhs.start, &rhs) >= 1))
      {
        v24 = v23;
      }

      else
      {
        lhs.start.value = v25;
        lhs.start.timescale = v26;
        lhs.start.flags = v9;
        lhs.start.epoch = v12;
        lhs.duration.value = v11;
        lhs.duration.timescale = v13;
        lhs.duration.flags = v10;
        lhs.duration.epoch = 0;
        rhs = *(silo + 32);
        if (CMTimeRangeContainsTime(&lhs, &rhs))
        {
          memset(&lhs, 0, 24);
          rhs = *(silo + 32);
          start.value = v25;
          start.timescale = v26;
          start.flags = v9;
          start.epoch = v12;
          CMTimeSubtract(&lhs.start, &rhs, &start);
          rhs = v24;
          start = lhs.start;
          CMTimeAdd(&v24, &rhs, &start);
        }
      }

      ++v6;
      v5 += 48;
      if (v6 >= *(silo + 7))
      {
        goto LABEL_21;
      }
    }

    VTFrameSiloGetProgressOfCurrentPass_cold_1(v17, &v25, &lhs);
    return lhs.start.value;
  }

LABEL_21:
  lhs.start = v23;
  *&rhs.value = v19;
  rhs.epoch = v2;
  if (CMTimeCompare(&lhs.start, &rhs) < 1)
  {
    v15 = 0.0;
  }

  else
  {
    lhs.start = v24;
    Seconds = CMTimeGetSeconds(&lhs.start);
    lhs.start = v23;
    v15 = Seconds / CMTimeGetSeconds(&lhs.start);
  }

  result = 0;
  *progressOut = v15;
  return result;
}

OSStatus VTFrameSiloCallFunctionForEachSampleBuffer(VTFrameSiloRef silo, CMTimeRange *timeRange, void *refcon, OSStatus (__cdecl *callback)(void *, CMSampleBufferRef))
{
  v71 = *MEMORY[0x1E69E9840];
  epoch = 0;
  theData = 0;
  v57 = 0uLL;
  if (!silo)
  {
    VTFrameSiloCallFunctionForEachSampleBuffer_cold_7(&range);
LABEL_81:
    v32 = 0;
    value = range.duration.value;
    goto LABEL_69;
  }

  if (!callback)
  {
    VTFrameSiloCallFunctionForEachSampleBuffer_cold_6(&range);
    goto LABEL_81;
  }

  if (*(silo + 16))
  {
    fig_log_get_emitter();

    return FigSignalErrorAtGM();
  }

  v7 = timeRange;
  v8 = MEMORY[0x1E6960C70];
  if ((timeRange->start.flags & 1) == 0 || (timeRange->duration.flags & 1) == 0 || timeRange->duration.epoch || timeRange->duration.value < 0)
  {
    *&time.version = *MEMORY[0x1E6960C70];
    *(&time.FreeBlock + 4) = *(MEMORY[0x1E6960C70] + 16);
    v9 = *(silo + 3);
    *&range.duration.value = *&time.version;
    range.duration.epoch = *(&time.FreeBlock + 4);
    TimeStamp = VTMultiPassStorageGetTimeStamp(v9, &range.duration.value, @"GetFirstTimeStamp", &time);
    if (TimeStamp)
    {
LABEL_77:
      value = TimeStamp;
      v32 = 0;
      goto LABEL_69;
    }

    *&start.value = *&time.version;
    start.epoch = *(&time.FreeBlock + 4);
    end = **&MEMORY[0x1E6960C88];
    CMTimeRangeFromTimeToTime(&range, &start, &end);
    v11 = *&range.duration.epoch;
    *&v7->start.value = *&range.duration.value;
    *&v7->start.epoch = v11;
    *&v7->duration.timescale = *&range.presentationTimeStamp.timescale;
  }

  v12 = *&v7->start.epoch;
  v57 = *&v7->start.value;
  epoch = v7->start.epoch;
  *&range.duration.value = *&v7->start.value;
  *&range.duration.epoch = v12;
  *&range.presentationTimeStamp.timescale = *&v7->duration.timescale;
  *&time.version = *&v7->start.value;
  *(&time.FreeBlock + 4) = v7->start.epoch;
  if (CMTimeRangeContainsTime(&range, &time))
  {
    v13 = 0;
    v14 = 0;
    v15 = *MEMORY[0x1E695E480];
    v53 = *v8;
    v52 = *(v8 + 2);
    blockAllocator = *MEMORY[0x1E695E480];
    v49 = callback;
    while (1)
    {
      v55 = v53;
      v56 = v52;
      v16 = *(silo + 3);
      *&range.duration.value = v57;
      range.duration.epoch = epoch;
      TimeStamp = VTMultiPassStorageCopyDataAtTimeStamp(v16, &range.duration.value, 0, &theData);
      if (TimeStamp)
      {
        goto LABEL_77;
      }

      v17 = theData;
      if ((v13 & (theData == 0)) == 1)
      {
        VTFrameSiloCallFunctionForEachSampleBuffer_cold_5(&range);
        goto LABEL_81;
      }

      if (!theData)
      {
        v32 = 0;
        goto LABEL_52;
      }

      sampleBufferOut = 0;
      blockBufferOut = 0;
      sampleSizeArray = 0;
      memset(&range, 0, sizeof(range));
      memset(&time, 0, sizeof(time));
      error = 0;
      format = kCFPropertyListBinaryFormat_v1_0;
      Length = CFDataGetLength(theData);
      BytePtr = CFDataGetBytePtr(v17);
      CFRetain(v17);
      v21 = *(BytePtr + 1);
      v20 = *(BytePtr + 2);
      v22 = *(BytePtr + 3);
      range.decodeTimeStamp.epoch = *(BytePtr + 8);
      *&range.decodeTimeStamp.value = v22;
      *&range.duration.value = *BytePtr;
      *&range.duration.epoch = v21;
      *&range.presentationTimeStamp.timescale = v20;
      v69 = *(BytePtr + 6);
      v70 = *(BytePtr + 14);
      flags = HIDWORD(v22);
      v24 = range.decodeTimeStamp.epoch;
      if (BYTE12(v22) & 1) == 0 && (range.presentationTimeStamp.flags)
      {
        v69 = *(BytePtr + 3);
        v70 = *(BytePtr + 8);
        v24 = range.presentationTimeStamp.epoch;
        flags = range.presentationTimeStamp.flags;
      }

      v25 = *(BytePtr + 18);
      if (v25 <= 0)
      {
        break;
      }

      v26 = CFDataCreate(v15, BytePtr + 76, *(BytePtr + 18));
      if (!v26)
      {
        VTFrameSiloCallFunctionForEachSampleBuffer_cold_3(&start);
        goto LABEL_62;
      }

      v27 = v15;
      v28 = v7;
      cf = v26;
      v29 = CFPropertyListCreateWithData(v27, v26, 0, &format, &error);
      if (error)
      {
        v30 = CFErrorCopyFailureReason(error);
        value = CFErrorGetCode(error);
        v32 = 0;
        v33 = v49;
        v34 = v29;
LABEL_24:
        v7 = v28;
LABEL_25:
        v35 = cf;
        goto LABEL_38;
      }

      v48 = v29;
      ValueAtIndex = CFArrayGetValueAtIndex(v29, 0);
      if (!ValueAtIndex)
      {
        VTFrameSiloCallFunctionForEachSampleBuffer_cold_2(&start);
        v32 = 0;
        v30 = 0;
        value = start.value;
        v34 = v29;
        v33 = v49;
        goto LABEL_24;
      }

      theDict = ValueAtIndex;
      v37 = (v25 + 76);
      sampleSizeArray = Length - v37;
      time.version = 0;
      time.AllocateBlock = 0;
      time.FreeBlock = vtFrameSiloFreeBlockCFData;
      time.refCon = v17;
      v38 = CMBlockBufferCreateWithMemoryBlock(blockAllocator, BytePtr, Length, blockAllocator, &time, v37, Length - v37, 0, &blockBufferOut);
      v7 = v28;
      if (v38)
      {
        value = v38;
        v32 = 0;
        v30 = 0;
        v34 = v48;
        v33 = v49;
        goto LABEL_25;
      }

      v34 = v48;
      v33 = v49;
      v35 = cf;
      while (1)
      {
        v39 = CFArrayGetValueAtIndex(*(silo + 10), v14);
        start = v39[1];
        end.value = v69;
        end.timescale = v70;
        end.flags = flags;
        end.epoch = v24;
        if ((CMTimeCompare(&start, &end) & 0x80000000) == 0)
        {
          break;
        }

        if (++v14 >= CFArrayGetCount(*(silo + 10)))
        {
          goto LABEL_37;
        }
      }

      v40 = v39[2].value;
      if (!v40)
      {
LABEL_37:
        v32 = 0;
        v30 = 0;
        value = -12902;
        goto LABEL_38;
      }

      v41 = CMSampleBufferCreate(blockAllocator, blockBufferOut, 1u, 0, 0, v40, 1, 1, &range, 1, &sampleSizeArray, &sampleBufferOut);
      if (v41)
      {
        value = v41;
        v32 = 0;
        v30 = 0;
      }

      else
      {
        SampleAttachmentsArray = CMSampleBufferGetSampleAttachmentsArray(sampleBufferOut, 1u);
        v43 = CFArrayGetValueAtIndex(SampleAttachmentsArray, 0);
        if (v43)
        {
          CFDictionaryApplyFunction(theDict, vtFrameSiloMergeDictionary, v43);
          v30 = 0;
          value = 0;
          v32 = sampleBufferOut;
          sampleBufferOut = 0;
        }

        else
        {
          VTFrameSiloCallFunctionForEachSampleBuffer_cold_1(&start);
          v32 = 0;
          v30 = 0;
          value = start.value;
        }
      }

LABEL_38:
      if (blockBufferOut)
      {
        CFRelease(blockBufferOut);
      }

      if (sampleBufferOut)
      {
        CFRelease(sampleBufferOut);
      }

      if (v34)
      {
        CFRelease(v34);
      }

      if (v35)
      {
        CFRelease(v35);
      }

      if (error)
      {
        CFRelease(error);
      }

      v15 = blockAllocator;
      if (v30)
      {
        CFRelease(v30);
      }

      if (value)
      {
        goto LABEL_69;
      }

      v44 = (v33)(refcon, v32);
      if (v44)
      {
LABEL_76:
        value = v44;
        goto LABEL_69;
      }

LABEL_52:
      v45 = *(silo + 3);
      *&range.duration.value = v57;
      range.duration.epoch = epoch;
      v44 = VTMultiPassStorageGetTimeStamp(v45, &range.duration.value, @"GetNextTimeStamp", &v55);
      if (v44)
      {
        goto LABEL_76;
      }

      if ((BYTE12(v55) & 1) == 0)
      {
        goto LABEL_68;
      }

      v57 = v55;
      epoch = v56;
      if (theData)
      {
        CFRelease(theData);
        theData = 0;
      }

      if (v32)
      {
        CFRelease(v32);
      }

      v46 = *&v7->start.epoch;
      *&range.duration.value = *&v7->start.value;
      *&range.duration.epoch = v46;
      *&range.presentationTimeStamp.timescale = *&v7->duration.timescale;
      *&time.version = v57;
      *(&time.FreeBlock + 4) = epoch;
      v13 = 1;
      if (!CMTimeRangeContainsTime(&range, &time))
      {
        goto LABEL_67;
      }
    }

    VTFrameSiloCallFunctionForEachSampleBuffer_cold_4(&start);
LABEL_62:
    v32 = 0;
    v34 = 0;
    v35 = 0;
    v30 = 0;
    value = start.value;
    v33 = v49;
    goto LABEL_38;
  }

LABEL_67:
  v32 = 0;
LABEL_68:
  value = 0;
LABEL_69:
  if (theData)
  {
    CFRelease(theData);
  }

  if (v32)
  {
    CFRelease(v32);
  }

  return value;
}

OSStatus VTFrameSiloCallBlockForEachSampleBuffer(VTFrameSiloRef silo, CMTimeRange *timeRange, void *handler)
{
  v3 = *&timeRange->start.epoch;
  *&v5.start.value = *&timeRange->start.value;
  *&v5.start.epoch = v3;
  *&v5.duration.timescale = *&timeRange->duration.timescale;
  return VTFrameSiloCallFunctionForEachSampleBuffer(silo, &v5, handler, vtFrameSiloBlockFunctionCallback);
}

double vtFrameSiloInit(_OWORD *a1)
{
  result = 0.0;
  a1[4] = 0u;
  a1[5] = 0u;
  a1[2] = 0u;
  a1[3] = 0u;
  a1[1] = 0u;
  return result;
}

__CFString *vtFrameSiloCopyDebugDesc(const void *a1)
{
  v2 = CFGetAllocator(a1);
  Mutable = CFStringCreateMutable(v2, 0);
  v4 = CFGetAllocator(a1);
  CFStringAppendFormat(Mutable, 0, @"<VTFrameSilo %p [%p]>{}", a1, v4);
  return Mutable;
}

void vtFrameSiloFreeBlockCFData(CFTypeRef cf)
{
  if (cf)
  {
    CFRelease(cf);
  }
}

uint64_t OUTLINED_FUNCTION_12_8(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, CMTime *time2, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, __int128 time2a, uint64_t time2_16, uint64_t a15, CMTime *time1, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20, uint64_t a21, uint64_t a22, uint64_t a23, uint64_t a24, uint64_t a25, uint64_t time1a)
{
  time2a = *(v26 + 24);
  time2_16 = *(v26 + 40);

  return CMTimeCompare(&time1a, &time2a);
}

uint64_t OUTLINED_FUNCTION_13_10(__int128 *a1, uint64_t a2, uint64_t a3, uint64_t a4, CMTime *time2, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, uint64_t a11, uint64_t a12, __int128 time2a, uint64_t time2_16, uint64_t a15, CMTime *time1, uint64_t a17, uint64_t a18, uint64_t a19, uint64_t a20, uint64_t a21, uint64_t a22, uint64_t a23, uint64_t a24, uint64_t a25, uint64_t time1a)
{
  v27 = *a1;
  time2_16 = *(a1 + 2);
  time2a = v27;

  return CMTimeCompare(&time1a, &time2a);
}

uint64_t OUTLINED_FUNCTION_14_9(uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5, uint64_t a6, uint64_t a7, uint64_t a8, uint64_t a9, uint64_t a10, CMTime *time2, uint64_t a12, CMTime *time1, uint64_t a14, __int128 a15, uint64_t a16, uint64_t a17, __int128 time2a, uint64_t time2_16, uint64_t a20, uint64_t time1a, uint64_t time1_8, uint64_t time1_16, uint64_t a24, __int128 a25, uint64_t a26)
{
  time2a = a25;
  time2_16 = a26;

  return CMTimeCompare(&time1a, &time2a);
}

void OUTLINED_FUNCTION_16_9()
{
  *(v0 + 32) = *(v3 - 144);
  *(v0 + 40) = *(v3 - 136);
  *(v0 + 44) = v2;
  *(v0 + 48) = v1;
}

uint64_t vt_Copy_l10r_TRC_Tone_Mat_TRC_420vf(uint64_t a1, uint64_t *a2, uint64_t a3, void *a4, unint64_t *a5, uint64_t *a6, uint64_t a7, void *a8, void *a9)
{
  v64 = a3;
  v65 = a8;
  v63 = a7;
  v70 = a4;
  v71 = a5;
  v72 = *MEMORY[0x1E69E9840];
  v62 = a1;
  v9 = *(a1 + 162);
  v10 = a2[1];
  v12 = a2[2];
  v11 = a2[3];
  v14 = a2[4];
  v13 = a2[5];
  v15 = *a6;
  v66 = *a2;
  v67 = v15;
  v16 = a6[1];
  v17 = a6[2];
  v18 = a6[3];
  v19 = a6[4];
  v20 = a6[5];
  v68 = v16;
  v69 = v10;
  v22 = v13 + v11 != v10 || v20 + v18 != v16;
  v60 = v22;
  if (v9 == 255)
  {
    v23 = malloc_type_calloc(1uLL, 0x49CuLL, 0x10B0040FF6A342BuLL);
    if (!v23)
    {
      v24 = 0;
LABEL_65:
      free(v23);
      return v24;
    }
  }

  else
  {
    MEMORY[0x1EEE9AC00](a1, 4 * v9 + 160, a3, a4);
    v23 = &v59[-v25];
    bzero(&v59[-v25], v26);
  }

  v27 = v17 - 1;
  v28 = a9;
  v29 = v12 - 1;
  if (v19)
  {
    v30 = v14 + 1;
  }

  else
  {
    v29 = v12;
    v30 = v14;
  }

  if (v19)
  {
    v31 = v19 + 1;
  }

  else
  {
    v27 = v17;
    v31 = v19;
  }

  v32 = v29 - (v27 & 1);
  v33 = v27 & 0xFFFFFFFFFFFFFFFELL;
  v34 = v18 - 1;
  v35 = v11 - 1;
  if (v20)
  {
    v36 = v13 + 1;
  }

  else
  {
    v35 = v11;
    v36 = v13;
  }

  if (v20)
  {
    v37 = v20 + 1;
  }

  else
  {
    v34 = v18;
    v37 = v20;
  }

  if (v34)
  {
    if (v60 || (v38 = v35 + 1 + v36, *v70 * v38 > *v71) || v70[1] * v38 > v71[1] || (v39 = v34 + 1 + v37, (*v65 * v39) > *a9) || (v65[1] * (v39 / 2)) > a9[1] || (v65[2] * v39) > a9[2])
    {
      --v34;
      --v35;
    }

    else
    {
      ++v68;
      ++v69;
      ++v35;
      ++v34;
    }
  }

  if (v32 + v30 > v66)
  {
    v32 = v66 - v30;
  }

  if (v33 + v31 > v67)
  {
    v33 = v67 - v31;
  }

  if (v35 + v36 > v69)
  {
    v35 = v69 - v36;
  }

  if (v34 + v37 > v68)
  {
    v34 = v68 - v37;
  }

  if (v32 >= v33)
  {
    v40 = v33;
  }

  else
  {
    v40 = v32;
  }

  if (v35 >= v34)
  {
    v41 = v34;
  }

  else
  {
    v41 = v35;
  }

  v42 = v36 + v41 - 1;
  v43 = v42 * *v70 + 4 * (v40 + v30);
  v44 = *v71;
  v61 = v36;
  if (v43 > v44)
  {
    v45 = v30;
    v46 = v31;
    v47 = a9;
    goto LABEL_58;
  }

  if (*(v64 + 8) && v40 + v30 + v70[1] * v42 > v71[1])
  {
    v45 = v30;
    v46 = v31;
    v47 = a9;
    goto LABEL_58;
  }

  v48 = v41 + v37 - 1;
  v49 = v40 + v31;
  if ((v40 + v31 + *v65 * v48) > *a9)
  {
    v45 = v30;
    v46 = v31;
    v47 = a9;
    goto LABEL_58;
  }

  v50 = v63;
  if (*(v63 + 8) && ((v49 + 1 + ((v49 + 1) >> 63)) & 0xFFFFFFFFFFFFFFFELL) + v65[1] * ((v41 + v37 + 1) / 2 - 1) > a9[1])
  {
    v45 = v30;
    v46 = v31;
    v47 = a9;
    goto LABEL_58;
  }

  if (*(v63 + 16) && (v49 + v65[2] * v48) > a9[2])
  {
    v45 = v30;
    v46 = v31;
    v47 = a9;
LABEL_58:
    fig_log_get_emitter();
    v24 = FigSignalErrorAtGM();
    v50 = v63;
    v28 = v47;
    v31 = v46;
    v30 = v45;
    v36 = v61;
    if (v24)
    {
      goto LABEL_64;
    }
  }

  *v23 = v9;
  *(v23 + 4) = v66;
  v51 = v68;
  *(v23 + 12) = v69;
  *(v23 + 20) = v40;
  *(v23 + 28) = v41;
  *(v23 + 36) = v30;
  *(v23 + 44) = v36;
  v23[11] = v51;
  v23[12] = v40;
  v23[13] = v41;
  v23[14] = v31;
  v52 = v70;
  v23[7] = v64;
  v23[8] = v52;
  v53 = v67;
  v23[9] = v71;
  v23[10] = v53;
  v23[15] = v37;
  v23[16] = v50;
  v23[17] = v65;
  v23[18] = v28;
  v23[19] = v62;
  global_queue = dispatch_get_global_queue(0, 0);
  dispatch_apply_f(v9, global_queue, v23, vt_Copy_l10r_TRC_Tone_Mat_TRC_420vf_GCD);
  if (!v9)
  {
    return 0;
  }

  v55 = (v23 + 20);
  v56 = v9;
  while (1)
  {
    v57 = *v55++;
    v24 = v57;
    if (v57)
    {
      break;
    }

    if (!--v56)
    {
      v24 = 0;
      break;
    }
  }

LABEL_64:
  if (v9 == 255)
  {
    goto LABEL_65;
  }

  return v24;
}

unsigned __int8 *vt_Copy_l10r_TRC_Tone_Mat_TRC_420vf_GCD(unsigned __int8 *result, uint64_t a2, double a3, double a4, double a5, double a6)
{
  v6 = 2 * *result;
  v7 = *(result + 13);
  v8 = v7 * a2 / v6;
  v9 = 2 * ((v7 + v7 * a2) / v6 - v8);
  if (v9 >= 1)
  {
    v10 = 0;
    v11 = *(result + 19);
    v12 = *(result + 24) & 0xFFFFFFFE;
    v13 = **(result + 8);
    v14 = *(result + 16);
    v15 = *(result + 17);
    v16 = *v15;
    v17 = v15[1];
    v18 = v15[2];
    *&v19 = *(v11 + 128);
    v20 = 8191.0 / *&v19;
    LOWORD(v19) = *(v11 + 140);
    *&a6 = v19;
    LOWORD(v19) = *(v11 + 144);
    v21 = v19;
    LOWORD(v19) = *(v11 + 146);
    v22 = v19;
    LOWORD(v19) = *(v11 + 148);
    v23 = v19;
    LOWORD(v19) = *(v11 + 150);
    v24 = v19;
    v188 = v24;
    LOWORD(v24) = *(v11 + 152);
    v184 = *(v11 + 40);
    v185 = *(v11 + 36);
    v183 = *(v11 + 44);
    v181 = *(v11 + 52) * 0.25;
    v182 = *(v11 + 48) * 0.25;
    v179 = *(v11 + 60) * 0.25;
    v180 = *(v11 + 56) * 0.25;
    v177 = *(v11 + 72);
    v178 = *(v11 + 64) * 0.25;
    v175 = *(v11 + 76);
    v176 = *(v11 + 68) * 0.25;
    v173 = *(v11 + 84);
    v174 = *(v11 + 80);
    v171 = *(v11 + 92);
    v172 = *(v11 + 88);
    v169 = *(v11 + 100);
    v170 = *(v11 + 96);
    v167 = *(v11 + 104);
    v25 = v11 + 164;
    v26 = v11 + 16548;
    v27 = v11 + 32932;
    v28 = *(v11 + 108);
    v29 = *(v11 + 112);
    v30 = *(v11 + 116);
    v31 = *(v11 + 120);
    v32 = *(result + 14);
    v33 = *(result + 15) + 2 * v8;
    v34 = *(result + 44) + 2 * (*(result + 28) * a2 / v6);
    v35 = v14[2];
    _ZF = v35 == 0;
    v37 = (v35 + v18 * v33 + v32);
    if (_ZF)
    {
      v37 = 0;
    }

    v38 = (*v14 + v16 * v33 + v32);
    v39 = (**(result + 7) + v34 * v13 + 4 * *(result + 36));
    v40 = v14[1] + v17 * (v33 / 2) + v32;
    v41 = vdup_lane_s32(*&a6, 0);
    v186 = LODWORD(v24);
    v187 = v22;
    v168 = v20;
    v165 = v29;
    v166 = v28;
    v163 = v31;
    v164 = v30;
    v162 = v41;
    do
    {
      v42 = v39 + v13;
      v43 = &v38[v16];
      v44 = &v37[v18];
      if (v12 >= 1)
      {
        v45 = 0;
        v46 = &v37[v18];
        v47 = &v38[v16];
        v48 = (v39 + v13);
        do
        {
          v49 = *v39++;
          v50 = v49;
          v51 = v49.u32[1];
          v52 = vdup_n_s32(0x45FFF800u);
          _D0 = vcvt_s32_f32(vrnda_f32(vminnm_f32(vmaxnm_f32(vmul_n_f32(vsub_f32(vcvt_f32_u32(vand_s8(vshl_u32(vdup_lane_s32(v49, 0), 0xFFFFFFF6FFFFFFECLL), 0x300000003)), v41), v20), 0), v52)));
          _D0.i16[0] = *(v25 + 2 * _D0.u32[0]);
          __asm { FCVT            S21, H0 }

          _D0.i16[0] = *(v25 + 2 * _D0.u32[1]);
          __asm { FCVT            S22, H0 }

          _D0.i32[0] = v49.i32[0];
          _D0.i32[1] = v49.i32[1] >> 20;
          v59 = vcvt_s32_f32(vrnda_f32(vminnm_f32(vmaxnm_f32(vmul_n_f32(vsub_f32(vcvt_f32_u32(vand_s8(_D0, 0x300000003)), v41), v20), 0), v52)));
          _H3 = *(v25 + 2 * v59.u32[0]);
          __asm { FCVT            S5, H3 }

          v62 = (((v29 * _S22) + (v28 * _S21)) + (v30 * _S5)) + (v31 * fmaxf(_S21, fmaxf(_S22, _S5)));
          v63 = 8191.0;
          if (v62 <= 8191.0)
          {
            v63 = v62;
            if (v62 < 0.0)
            {
              v63 = 0.0;
            }
          }

          _H0 = *(v25 + 2 * v59.u32[1]);
          __asm { FCVT            S14, H0 }

          v66.i32[1] = v50.i32[1];
          v66.i32[0] = v51 >> 10;
          _D0 = vcvt_s32_f32(vrnda_f32(vminnm_f32(vmaxnm_f32(vmul_n_f32(vsub_f32(vcvt_f32_u32(vand_s8(v66, 0x300000003)), v41), v20), 0), v52)));
          _D0.i16[0] = *(v25 + 2 * _D0.u32[0]);
          __asm { FCVT            S15, H0 }

          _D0.i16[0] = *(v25 + 2 * _D0.u32[1]);
          __asm { FCVT            S7, H0 }

          v70 = fmaxf(_S14, fmaxf(_S15, _S7));
          v71 = (((v29 * _S15) + (v28 * _S14)) + (v30 * _S7)) + (v31 * v70);
          v72 = 8191.0;
          if (v71 <= 8191.0)
          {
            v72 = (((v29 * _S15) + (v28 * _S14)) + (v30 * _S7)) + (v31 * v70);
            if (v71 < 0.0)
            {
              v72 = 0.0;
            }
          }

          v73 = *v48++;
          *v74.i8 = v73;
          v75 = v73.u32[1];
          _D0 = vcvt_s32_f32(vrnda_f32(vminnm_f32(vmaxnm_f32(vmul_n_f32(vsub_f32(vcvt_f32_u32(vand_s8(vshl_u32(vdup_lane_s32(v73, 0), 0xFFFFFFF6FFFFFFECLL), 0x300000003)), v41), v20), 0), v52)));
          _D0.i16[0] = *(v25 + 2 * _D0.u32[0]);
          __asm { FCVT            S16, H0 }

          _D0.i16[0] = *(v25 + 2 * _D0.u32[1]);
          __asm { FCVT            S6, H0 }

          _D0.i32[0] = v73.i32[0];
          _D0.i32[1] = v73.i32[1] >> 20;
          v79 = vcvt_s32_f32(vrnda_f32(vminnm_f32(vmaxnm_f32(vmul_n_f32(vsub_f32(vcvt_f32_u32(vand_s8(_D0, 0x300000003)), v41), v20), 0), v52)));
          _D0.i16[0] = *(v25 + 2 * v79.u32[0]);
          __asm { FCVT            S23, H0 }

          v81 = (((v29 * _S6) + (v28 * _S16)) + (v30 * _S23)) + (v31 * fmaxf(_S16, fmaxf(_S6, _S23)));
          v82 = 8191.0;
          if (v81 <= 8191.0)
          {
            v82 = v81;
            if (v81 < 0.0)
            {
              v82 = 0.0;
            }
          }

          _H25 = *(v25 + 2 * v79.u32[1]);
          __asm { FCVT            S25, H25 }

          v85.i32[1] = v74.i32[1];
          v85.i32[0] = v75 >> 10;
          _D24 = vcvt_s32_f32(vrnda_f32(vminnm_f32(vmaxnm_f32(vmul_n_f32(vsub_f32(vcvt_f32_u32(vand_s8(v85, 0x300000003)), v41), v20), 0), v52)));
          _D24.i16[0] = *(v25 + 2 * _D24.u32[0]);
          __asm { FCVT            S28, H24 }

          _D24.i16[0] = *(v25 + 2 * _D24.u32[1]);
          __asm { FCVT            S29, H24 }

          _H3 = *(v26 + 2 * llroundf(v63));
          __asm { FCVT            S3, H3 }

          v91 = _S21 * _S3;
          v92 = _S22 * _S3;
          v93 = _S5 * _S3;
          LOWORD(_S3) = *(v26 + 2 * llroundf(v72));
          __asm { FCVT            S3, H3 }

          v95 = _S14 * _S3;
          v96 = _S15 * _S3;
          v97 = _S7 * _S3;
          _H0 = *(v26 + 2 * llroundf(v82));
          __asm { FCVT            S0, H0 }

          v100 = _S16 * _S0;
          v101 = _S6 * _S0;
          v102 = _S23 * _S0;
          v103 = (((v29 * _S28) + (v28 * _S25)) + (v30 * _S29)) + (v31 * fmaxf(_S25, fmaxf(_S28, _S29)));
          v104 = 8191.0;
          if (v103 <= 8191.0)
          {
            v104 = v103;
            if (v103 < 0.0)
            {
              v104 = 0.0;
            }
          }

          _H0 = *(v26 + 2 * llroundf(v104));
          __asm { FCVT            S0, H0 }

          v107 = _S25 * _S0;
          _S23 = _S28 * _S0;
          v109 = _S29 * _S0;
          v110 = ((v175 * v92) + (v91 * v177)) + (v93 * v174);
          v111 = ((v172 * v92) + (v91 * v173)) + (v93 * v171);
          _S22 = ((v169 * v92) + (v91 * v170)) + (v93 * v167);
          v113 = ((v175 * v96) + (v95 * v177)) + (v97 * v174);
          v114 = ((v172 * v96) + (v95 * v173)) + (v97 * v171);
          _S17 = ((v169 * v96) + (v95 * v170)) + (v97 * v167);
          v116 = ((v175 * v101) + (v100 * v177)) + (v102 * v174);
          v117 = ((v172 * v101) + (v100 * v173)) + (v102 * v171);
          v118 = ((v169 * v101) + (v100 * v170)) + (v102 * v167);
          v119 = ((v175 * _S23) + (v107 * v177)) + (v109 * v174);
          v120 = ((v172 * _S23) + (v107 * v173)) + (v109 * v171);
          _S0 = ((v169 * _S23) + (v107 * v170)) + (v109 * v167);
          _H3 = *(v27 + 2 * llroundf(fminf(fmaxf(v110, 0.0), 8191.0)));
          __asm { FCVT            S7, H3 }

          _H3 = *(v27 + 2 * llroundf(fminf(fmaxf(v111, 0.0), 8191.0)));
          __asm { FCVT            S3, H3 }

          _H5 = *(v27 + 2 * llroundf(fminf(fmaxf(_S22, 0.0), 8191.0)));
          __asm { FCVT            S5, H5 }

          _H6 = *(v27 + 2 * llroundf(fminf(fmaxf(v113, 0.0), 8191.0)));
          __asm { FCVT            S16, H6 }

          _H6 = *(v27 + 2 * llroundf(fminf(fmaxf(v114, 0.0), 8191.0)));
          LOWORD(_S17) = *(v27 + 2 * llroundf(fminf(fmaxf(_S17, 0.0), 8191.0)));
          __asm
          {
            FCVT            S21, H6
            FCVT            S17, H17
          }

          _H6 = *(v27 + 2 * llroundf(fminf(fmaxf(v116, 0.0), 8191.0)));
          __asm { FCVT            S6, H6 }

          LOWORD(_S22) = *(v27 + 2 * llroundf(fminf(fmaxf(v117, 0.0), 8191.0)));
          __asm { FCVT            S24, H22 }

          LOWORD(_S22) = *(v27 + 2 * llroundf(fminf(fmaxf(v118, 0.0), 8191.0)));
          __asm { FCVT            S22, H22 }

          LOWORD(_S23) = *(v27 + 2 * llroundf(fminf(fmaxf(v119, 0.0), 8191.0)));
          __asm { FCVT            S15, H23 }

          LOWORD(_S23) = *(v27 + 2 * llroundf(fminf(fmaxf(v120, 0.0), 8191.0)));
          LOWORD(_S0) = *(v27 + 2 * llroundf(fminf(fmaxf(_S0, 0.0), 8191.0)));
          __asm
          {
            FCVT            S23, H23
            FCVT            S14, H0
          }

          v140 = (((v184 * _S3) + (v185 * _S7)) + (v183 * _S5)) + v21;
          if (v140 < v21)
          {
            v141 = v21;
          }

          else
          {
            v141 = (((v184 * _S3) + (v185 * _S7)) + (v183 * _S5)) + v21;
          }

          v142 = v140 <= v23;
          v143 = (((v184 * _S21) + (v185 * _S16)) + (v183 * _S17)) + v21;
          if (!v142)
          {
            v141 = v23;
          }

          v144 = llroundf(v141);
          if (v143 < v21)
          {
            v145 = v21;
          }

          else
          {
            v145 = (((v184 * _S21) + (v185 * _S16)) + (v183 * _S17)) + v21;
          }

          v142 = v143 <= v23;
          v146 = (((v184 * _S24) + (v185 * _S6)) + (v183 * _S22)) + v21;
          if (!v142)
          {
            v145 = v23;
          }

          v147 = llroundf(v145);
          if (v146 < v21)
          {
            v148 = v21;
          }

          else
          {
            v148 = (((v184 * _S24) + (v185 * _S6)) + (v183 * _S22)) + v21;
          }

          v142 = v146 <= v23;
          v149 = (((v184 * _S23) + (v185 * _S15)) + (v183 * _S14)) + v21;
          if (!v142)
          {
            v148 = v23;
          }

          v150 = llroundf(v148);
          if (v149 < v21)
          {
            v151 = v21;
          }

          else
          {
            v151 = (((v184 * _S23) + (v185 * _S15)) + (v183 * _S14)) + v21;
          }

          if (v149 <= v23)
          {
            v152 = v151;
          }

          else
          {
            v152 = v23;
          }

          v153 = llroundf(v152);
          v154 = ((_S7 + _S16) + _S6) + _S15;
          v155 = ((_S3 + _S21) + _S24) + _S23;
          *v38 = v144;
          v38[1] = v147;
          *v47 = v150;
          v47[1] = v153;
          v156 = ((_S5 + _S17) + _S22) + _S14;
          v157 = ((v187 + (v154 * v182)) + (v155 * v181)) + (v156 * v180);
          v158 = v186;
          if (v157 <= v186)
          {
            v158 = ((v187 + (v154 * v182)) + (v155 * v181)) + (v156 * v180);
            if (v157 < v188)
            {
              v158 = v188;
            }
          }

          v159 = ((v187 + (v154 * v179)) + (v155 * v178)) + (v156 * v176);
          *(v40 + v45) = llroundf(v158);
          v160 = v186;
          v41 = v162;
          if (v159 <= v186)
          {
            v160 = v159;
            if (v159 < v188)
            {
              v160 = v188;
            }
          }

          *(v40 + v45 + 1) = llroundf(v160);
          v20 = v168;
          v29 = v165;
          v28 = v166;
          v31 = v163;
          v30 = v164;
          if (v37)
          {
            v74.u64[1] = v50;
            v161 = vbic_s8(vmul_s16(vmovn_s32(vshrq_n_u32(v74, 0x1EuLL)), 0x55005500550055), vceqd_s64(v37, 0));
            *v37 = v161.i8[4];
            v37[1] = v161.i8[6];
            v37 += 2;
            *v46 = v161.i8[0];
            v46[1] = v161.i8[2];
            v46 += 2;
          }

          v38 += 2;
          v47 += 2;
          v45 += 2;
        }

        while (v45 < v12);
      }

      v39 = &v42[v13];
      v38 = &v43[v16];
      v40 += v17;
      v37 = &v44[v18];
      v10 += 2;
    }

    while (v10 < v9);
  }

  *&result[4 * a2 + 160] = 0;
  return result;
}